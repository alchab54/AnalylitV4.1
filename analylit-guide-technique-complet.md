**AnalyLit v4.1 \- Guide Technique Complet**

**Application de Scoping Review pour l'Alliance Th√©rapeutique Num√©rique**

**üìã Table des Mati√®res**

1. [Vue d'ensemble](#bookmark=id.atiixzxrw0qp)

2. [Architecture syst√®me](#bookmark=id.9tut7gesch4q)

3. [Fonctionnalit√©s principales](#bookmark=id.ocyfowc8e61a)

4. [Structure des fichiers](#bookmark=id.bkwq7immydyc)

5. [API et endpoints](#bookmark=id.1d463higxfxa)

6. [Syst√®me de t√¢ches asynchrones](#bookmark=id.2c99uapk1b5h)

7. [Intelligence artificielle](#bookmark=id.l25mon8jqo7x)

8. [Tests et qualit√©](#bookmark=id.u4nu59yfdprd)

9. [D√©ploiement](#bookmark=id.da19g2lzkbzi)

10. [Documentation m√©thodologique](#bookmark=id.w33d4e7npj49)

**Vue d'ensemble**

**AnalyLit v4.1** est une application web sophistiqu√©e con√ßue pour automatiser et optimiser les scoping reviews, particuli√®rement dans le domaine de l'alliance th√©rapeutique num√©rique. L'application int√®gre l'intelligence artificielle pour analyser de grands volumes d'articles scientifiques et faciliter leur s√©lection et extraction de donn√©es.

**üéØ Objectif Principal**

Permettre aux chercheurs de traiter efficacement de grands corpus d'articles scientifiques en automatisant :

* La recherche multi-bases de donn√©es

* Le screening d'articles par IA

* L'extraction structur√©e de donn√©es

* La g√©n√©ration de synth√®ses

* La validation inter-√©valuateurs

**‚ö° Technologies Principales**

* **Backend**: Python 3.11 \+ Flask \+ SQLAlchemy

* **Base de donn√©es**: PostgreSQL

* **T√¢ches asynchrones**: Redis \+ RQ (Redis Queue)

* **IA**: Ollama (LLaMA, Phi3, Mixtral)

* **Vectorisation**: ChromaDB \+ Sentence Transformers

* **Frontend**: JavaScript Vanilla (ES6 Modules)

* **D√©ploiement**: Docker \+ Docker Compose \+ Nginx

**Architecture Syst√®me**

**üèóÔ∏è Architecture Microservices**

`‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê`  
`‚îÇ     Nginx       ‚îÇ    ‚îÇ    Frontend     ‚îÇ    ‚îÇ     Backend     ‚îÇ`  
`‚îÇ   (Port 8080)   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  (SPA Vanilla)  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Flask + SQLAlc ‚îÇ`  
`‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò`  
                                                       `‚îÇ`  
`‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê`  
`‚îÇ   PostgreSQL    ‚îÇ    ‚îÇ      Redis      ‚îÇ    ‚îÇ     Worker      ‚îÇ`  
`‚îÇ  (Port 5432)    ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ   (Port 6379)   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   RQ Tasks      ‚îÇ`  
`‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò`  
                                                       `‚îÇ`  
                       `‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê`  
                       `‚îÇ     Ollama      ‚îÇ    ‚îÇ    ChromaDB     ‚îÇ`  
                       `‚îÇ  (Port 11434)   ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ   Vector Store  ‚îÇ`  
                       `‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò`

**üîÑ Flux de Donn√©es**

1. **Utilisateur** ‚Üí Frontend (SPA)

2. **Frontend** ‚Üí API REST (Flask)

3. **API** ‚Üí Base de donn√©es (PostgreSQL)

4. **API** ‚Üí Files de t√¢ches (Redis/RQ)

5. **Worker** ‚Üí IA (Ollama) \+ Vector Store (ChromaDB)

6. **Notifications** ‚Üí WebSocket (SocketIO)

### Flux de la Recherche Experte

Pour permettre une recherche de pr√©cision (Experte), le flux de donn√©es a √©t√© adapt√© pour g√©rer deux types de payloads.

1.  **Frontend (`web/js/search.js`)**
    * L'interface utilisateur d√©tecte si le mode "Simple" ou "Expert" est activ√©.
    * **En mode Simple**, il envoie un objet JSON standard :
        `{ "query": "...", "sources": ["pubmed", "scopus"], ... }`
    * **En mode Expert**, il envoie un objet JSON structur√© :
        `{ "expert_queries": { "pubmed": "...", "scopus": "..." }, "sources": ["pubmed", "scopus"], ... }`

2.  **Backend (Serveur)**
    * L'endpoint API `/api/searches` dans `server_v4_complete.py` v√©rifie la pr√©sence de la cl√© `expert_queries`.
    * Il transmet soit la `query` simple, soit le dictionnaire `expert_queries` √† la t√¢che Celery (`tasks_v4_complete.py`).

3.  **Workers (Logique de Fetch)**
    * Dans `utils/fetchers.py`, les fonctions de recherche (ex: `search_pubmed`) acceptent d√©sormais les requ√™tes expertes.
    * La logique interne v√©rifie si une `expert_query` est fournie pour la source actuelle.
    * Si oui, cette requ√™te est utilis√©e directement sans modification.
    * Si non, le `fetcher` utilise l'ancienne logique de construction de requ√™te √† partir de la `query` simple.

**Fonctionnalit√©s Principales**

**1\. üîç Recherche Multi-bases**

**Module**: `utils/fetchers.py`  
**Endpoint**: `POST /api/search`

* **PubMed** via API Entrez

* **arXiv** via API REST

* **CrossRef** via API REST

* **IEEE Xplore** (configur√© mais n√©cessite cl√© API)

`# Exemple d'utilisation`  
`databases = ["pubmed", "arxiv", "crossref"]`  
`results = db_manager.search_multiple(query="diabetes", databases=databases)`

**2\. ü§ñ Screening Intelligent par IA**

**Module**: `tasks_v4_complete.py::process_single_article_task`  
**Mod√®les**: Phi3-mini, LLaMA 3.1

* Score de pertinence 0-10

* Justification automatique

* Support PDF avec OCR

* Extraction de m√©tadonn√©es

`# Prompt de screening`  
`prompt = get_screening_prompt_template().format(`  
    `title=article['title'],`  
    `abstract=article['abstract'],`   
    `database_source=article['database_source']`  
`)`

**3\. üìä Extraction Structur√©e ATN**

**Sp√©cialisation**: Alliance Th√©rapeutique Num√©rique  
**Grilles personnalis√©es**: JSON configurables

**Champs ATN sp√©cialis√©s**:

* Type\_IA (chatbot, avatar, assistant virtuel)

* Score\_empathie\_IA vs Score\_empathie\_humain

* WAI-SR\_modifi√© (Working Alliance Inventory)

* Taux\_adh√©sion et Confiance\_algorithmique

* RGPD\_conformit√© et AI\_Act\_risque

**4\. üí¨ Chat RAG (Retrieval-Augmented Generation)**

**Modules**:

* `tasks_v4_complete.py::index_project_pdfs_task`

* `tasks_v4_complete.py::answer_chat_question_task`

* Indexation automatique des PDFs

* Embeddings Sentence Transformers

* Recherche s√©mantique ChromaDB

* R√©ponses contextuelles via LLaMA

**5\. üìà Analyses Avanc√©es**

**Types d'analyses disponibles**:

* **M√©ta-analyse**: Intervalles de confiance, distribution scores

* **Scores ATN**: M√©triques sp√©cialis√©es alliance th√©rapeutique

* **Graphe de connaissances**: Visualisation relations articles

* **Diagramme PRISMA**: Flow chart automatique

* **Statistiques descriptives**: Synth√®se quantitative

**6\. ‚úÖ Validation Inter-√©valuateurs**

**Module**: API endpoints pour validation double-aveugle  
**M√©trique**: Coefficient Kappa de Cohen

* Import CSV d√©cisions √©valuateurs

* Calcul automatique accord inter-juges

* Gestion conflits de d√©cision

**7\. üìã Checklist PRISMA-ScR**

**Module**: `utils/prisma_scr.py`  
**Standard**: PRISMA Extension for Scoping Reviews

* 17 items PRISMA-ScR complets

* Sauvegarde progressive √©tat

* Auto-compl√©tion bas√©e donn√©es projet

**Structure des Fichiers**

**üìÅ Architecture G√©n√©rale**

`analylit/`  
`‚îú‚îÄ‚îÄ üêç Backend Python`  
`‚îÇ   ‚îú‚îÄ‚îÄ server_v4_complete.py      # Serveur Flask principal`  
`‚îÇ   ‚îú‚îÄ‚îÄ tasks_v4_complete.py       # T√¢ches asynchrones RQ`  
`‚îÇ   ‚îú‚îÄ‚îÄ config_v4.py               # Configuration application`  
`‚îÇ   ‚îú‚îÄ‚îÄ init_and_run.py           # Point d'entr√©e production`  
`‚îÇ   ‚îÇ`  
`‚îÇ   ‚îî‚îÄ‚îÄ utils/                     # Modules utilitaires`  
`‚îÇ       ‚îú‚îÄ‚îÄ models.py              # Mod√®les SQLAlchemy`  
`‚îÇ       ‚îú‚îÄ‚îÄ database.py            # Gestion base donn√©es`  
`‚îÇ       ‚îú‚îÄ‚îÄ ai_processors.py       # Interface Ollama`  
`‚îÇ       ‚îú‚îÄ‚îÄ fetchers.py            # APIs externes`  
`‚îÇ       ‚îú‚îÄ‚îÄ importers.py           # Import Zotero/CSV`  
`‚îÇ       ‚îú‚îÄ‚îÄ analysis.py            # Analyses statistiques`  
`‚îÇ       ‚îú‚îÄ‚îÄ notifications.py       # Syst√®me notifications`  
`‚îÇ       ‚îú‚îÄ‚îÄ file_handlers.py       # Manipulation fichiers`  
`‚îÇ       ‚îú‚îÄ‚îÄ helpers.py             # Fonctions utilitaires`  
`‚îÇ       ‚îú‚îÄ‚îÄ prisma_scr.py          # Checklist PRISMA`  
`‚îÇ       ‚îú‚îÄ‚îÄ prompt_templates.py    # Templates IA`  
`‚îÇ       ‚îî‚îÄ‚îÄ reporting.py           # G√©n√©ration rapports`  
`‚îÇ`  
`‚îú‚îÄ‚îÄ üê≥ Infrastructure`  
`‚îÇ   ‚îú‚îÄ‚îÄ docker-compose-complete.yml # Orchestration services`  
`‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile-*               # Images conteneurs`  
`‚îÇ   ‚îú‚îÄ‚îÄ nginx_complete.conf        # Configuration proxy`  
`‚îÇ   ‚îî‚îÄ‚îÄ env.example               # Variables environnement`  
`‚îÇ`  
`‚îú‚îÄ‚îÄ üß™ Tests`  
`‚îÇ   ‚îú‚îÄ‚îÄ conftest.py               # Configuration pytest`  
`‚îÇ   ‚îú‚îÄ‚îÄ test_*.py                 # Suites de tests`  
`‚îÇ   ‚îî‚îÄ‚îÄ locustfile.py            # Tests de charge`  
`‚îÇ`  
`‚îî‚îÄ‚îÄ üìä Configuration`  
    `‚îú‚îÄ‚îÄ pytest.ini                # Configuration Pytest`
    `‚îú‚îÄ‚îÄ profiles.json             # Profils mod√®les IA`  
    `‚îî‚îÄ‚îÄ requirements.txt          # D√©pendances Python`

**üîß Modules Principaux**

**server\_v4\_complete.py (2068 lignes)**

**Serveur Flask principal avec API REST compl√®te**

**Blueprints et routes**:

* `/api/health` \- V√©rification √©tat services

* `/api/projects/*` \- CRUD projets

* `/api/search` \- Recherche multi-bases

* `/api/databases` \- Liste bases disponibles

* `/api/profiles/*` \- Gestion profils IA

* `/api/prompts/*` \- Templates personnalis√©s

* `/api/tasks/*` \- Statut t√¢ches asynchrones

* `/api/ollama/*` \- Gestion mod√®les IA

**Fonctions cl√©s**:

`def create_app() -> Flask                    # Factory application Flask`  
`def multi_database_search_task()            # Recherche asynchrone`  
`def with_db_session(func)                   # D√©corateur gestion DB`  
`def update_project_status()                 # Mise √† jour √©tats projets`

**tasks\_v4\_complete.py (1429 lignes)**

**Syst√®me de t√¢ches asynchrones avec RQ**

**T√¢ches principales**:

`@with_db_session`  
`def multi_database_search_task()            # Recherche multi-bases`  
`def process_single_article_task()           # Screening/extraction IA`    
`def run_synthesis_task()                    # G√©n√©ration synth√®ses`  
`def run_discussion_generation_task()        # Brouillons discussion`  
`def index_project_pdfs_task()              # Indexation RAG`  
`def answer_chat_question_task()             # Chat IA contextuel`  
`def run_meta_analysis_task()               # Analyses statistiques`  
`def calculate_kappa_task()                 # Validation inter-√©valuateurs`

**utils/models.py (471 lignes)**

**Mod√®les de donn√©es SQLAlchemy**

**Entit√©s principales**:

`class Project(Base)                         # Projets recherche`  
`class SearchResult(Base)                    # R√©sultats recherche`  
`class Extraction(Base)                      # Donn√©es extraites`  
`class Grid(Base)                           # Grilles extraction`  
`class ChatMessage(Base)                     # Historique chat`  
`class AnalysisProfile(Base)                 # Profils IA`  
`class RiskOfBias(Base)                     # √âvaluation biais`  
`class ProcessingLog(Base)                   # Logs traitement`

**utils/fetchers.py (796 lignes)**

**Interface APIs externes de recherche**

**Classes principales**:

`class DatabaseManager:`  
    `def search_pubmed(query, max_results)   # API PubMed/Entrez`  
    `def search_arxiv(query, max_results)    # API arXiv`  
    `def search_crossref(query, max_results) # API CrossRef`  
    `def _parse_pubmed_xml()                 # Parser XML PubMed`  
    `def _parse_arxiv_xml()                  # Parser Atom arXiv`

`def fetch_article_details(article_id)      # R√©cup√©ration m√©tadonn√©es`  
`def fetch_unpaywall_pdf_url(doi)          # URLs PDF Open Access`

**utils/ai\_processors.py (213 lignes)**

**Interface avec syst√®me IA Ollama**

**Fonctions cl√©s**:

`def call_ollama_api(prompt, model, format)  # Appel API Ollama`  
`def requests_session_with_retries()         # Session HTTP robuste`  
`class AIResponseError(Exception)            # Gestion erreurs IA`

**API et Endpoints**

**üåê Routes Principales**

**Gestion des Projets**

`GET    /api/projects                        # Liste projets`  
`POST   /api/projects                        # Cr√©er projet`  
`GET    /api/projects/{id}                   # D√©tails projet`  
`DELETE /api/projects/{id}                   # Supprimer projet`  
`PUT    /api/projects/{id}/analysis-profile  # Modifier profil IA`

**Recherche et R√©sultats**

`POST   /api/search                          # Lancer recherche multi-bases`  
`GET    /api/projects/{id}/search-results    # R√©sultats pagin√©s`  
`GET    /api/projects/{id}/search-stats      # Statistiques recherche`  
`GET    /api/databases                       # Bases disponibles`

**Traitement IA**

`POST   /api/projects/{id}/run               # Lancer pipeline IA`  
`POST   /api/projects/{id}/run-analysis      # Analyses avanc√©es`  
`GET    /api/projects/{id}/extractions       # Donn√©es extraites`  
`POST   /api/projects/{id}/chat              # Chat RAG`

**Import/Export**

`POST   /api/projects/{id}/upload-pdfs-bulk  # Upload PDFs masse`  
`POST   /api/projects/{id}/upload-zotero     # Import fichier Zotero`  
`POST   /api/projects/{id}/import-zotero     # Sync PDFs Zotero`  
`GET    /api/projects/{id}/export            # Export complet`  
`GET    /api/projects/{id}/export/thesis     # Export th√®se ATN`

**Administration**

`GET    /api/health                          # √âtat services`  
`GET    /api/queues/info                     # √âtat files t√¢ches`  
`POST   /api/queues/{name}/clear             # Vider file`  
`GET    /api/tasks/status                    # √âtat t√¢ches`  
`POST   /api/tasks/{id}/cancel               # Annuler t√¢che`

**üì° Format des R√©ponses**

**R√©ponse standard**:

`{`  
  `"status": "success|error",`  
  `"data": {...},`  
  `"message": "Description",`  
  `"timestamp": "2024-01-15T10:30:00Z"`  
`}`

**R√©ponse t√¢che asynchrone**:

`{`  
  `"message": "T√¢che lanc√©e",`  
  `"task_id": "uuid-task-id",`  
  `"status_url": "/api/tasks/uuid-task-id/status"`  
`}`

**Syst√®me de T√¢ches Asynchrones**

**üîÑ Files RQ (Redis Queue)**

**4 files sp√©cialis√©es**:

1. **analylit\_processing\_v4** \- Traitement articles (screening/extraction)

2. **analylit\_synthesis\_v4** \- G√©n√©ration synth√®ses

3. **analylit\_analysis\_v4** \- Analyses statistiques avanc√©es

4. **analylit\_background\_v4** \- T√¢ches fond (indexation, import)

**‚ö° T√¢ches par Cat√©gorie**

**Recherche et Import**

`multi_database_search_task()               # Recherche multi-bases`  
`import_from_zotero_file_task()            # Import fichier Zotero`  
`import_pdfs_from_zotero_task()            # Sync PDFs Zotero API`  
`add_manual_articles_task()                # Ajout manuel articles`

**Traitement IA**

`process_single_article_task()             # Screening/extraction individuel`  
`run_synthesis_task()                      # Synth√®se articles pertinents`  
`run_discussion_generation_task()          # G√©n√©ration discussion`  
`index_project_pdfs_task()                # Indexation vectorielle`  
`answer_chat_question_task()               # R√©ponses chat RAG`

**Analyses Avanc√©es**

`run_meta_analysis_task()                  # M√©ta-analyse statistique`  
`run_atn_score_task()                      # Scores ATN sp√©cialis√©s`  
`run_knowledge_graph_task()               # Graphe connaissances`  
`run_prisma_flow_task()                    # Diagramme PRISMA`  
`run_descriptive_stats_task()             # Statistiques descriptives`  
`calculate_kappa_task()                    # Coefficient Kappa Cohen`  
`run_risk_of_bias_task()                  # √âvaluation biais`

**üìä Monitoring des T√¢ches**

**Statuts possibles**:

* `queued` \- En attente

* `started` \- En cours

* `finished` \- Termin√©e avec succ√®s

* `failed` \- √âchou√©e avec erreur

* `canceled` \- Annul√©e utilisateur

**Notifications WebSocket**:

`// Frontend re√ßoit notifications temps r√©el`  
`socket.on('task_progress', (data) => {`  
  `updateProgressBar(data.progress);`  
`});`

**Intelligence Artificielle**

**üß† Mod√®les Utilis√©s**

**Configuration par d√©faut** (`profiles.json`):

`{`  
  `"fast": {`  
    `"preprocess": "phi3:mini",`  
    `"extract": "phi3:mini",`   
    `"synthesis": "llama3.1:8b"`  
  `},`  
  `"standard": {`  
    `"preprocess": "phi3:mini",`  
    `"extract": "llama3.1:8b",`  
    `"synthesis": "llama3.1:8b"`    
  `},`  
  `"deep": {`  
    `"preprocess": "llama3.1:8b",`  
    `"extract": "mixtral:8x7b",`  
    `"synthesis": "llama3.1:70b"`  
  `}`  
`}`

**üìù Templates de Prompts**

**Screening Template**

`def get_screening_prompt_template():`  
    `return """En tant qu'assistant de recherche sp√©cialis√©,`   
    `analysez cet article et d√©terminez sa pertinence.`  
      
    `Titre: {title}`  
    `R√©sum√©: {abstract}`  
    `Source: {database_source}`  
      
    `R√©pondez UNIQUEMENT en JSON:`  
    `{{"relevance_score": 0-10, "decision": "√Ä inclure"|"√Ä exclure",`   
      `"justification": "..."}}"""`

**Template ATN Sp√©cialis√©**

`def get_scoping_atn_template(fields):`  
    `return """ROLE: Assistant expert en scoping review sur`   
    `l'alliance th√©rapeutique num√©rique.`  
      
    `CONSIGNES SP√âCIALES ALLIANCE TH√âRAPEUTIQUE NUM√âRIQUE :`  
    `- Identifiez le type d'IA utilis√© (chatbot, avatar, assistant virtuel)`  
    `- Relevez tous les scores d'empathie (IA vs humain)`  
    `- Notez les instruments (WAI-SR modifi√©, etc.)`  
    `- Analysez acceptabilit√© et adh√©sion patients`  
    `- √âvaluez confiance algorithmique et aspects √©thiques`  
      
    `TEXTE √Ä ANALYSER: {text}`  
    `R√©pondez UNIQUEMENT avec ce JSON : {...}"""`

**üîç Syst√®me RAG (Retrieval-Augmented Generation)**

**Pipeline complet**:

1. **Indexation** (`index_project_pdfs_task`):

`# Extraction texte PDF`  
`pdf_text = extract_text_from_pdf(pdf_path)`

`# D√©coupage chunks`  
`chunks = [text[i:i+1200] for i in range(0, len(text), 1000)]`

`# Vectorisation`  
`embeddings = embedding_model.encode(chunks)`

`# Stockage ChromaDB`  
`collection.add(documents=chunks, embeddings=embeddings)`

2. **Requ√™te** (`answer_chat_question_task`):

`# Vectorisation question`  
`query_embedding = embedding_model.encode([question])`

`# Recherche similarit√©`  
`results = collection.query(query_embeddings=query_embedding, n_results=3)`

`# G√©n√©ration r√©ponse`  
`context = "\n".join(results['documents'][0])`  
`prompt = f"Contexte: {context}\nQuestion: {question}"`  
`response = call_ollama_api(prompt, "llama3.1:8b")`

**Tests et Qualit√©**

**üß™ Suite de Tests Compl√®te**

**Couverture**: 8 modules de tests, \>50 tests

**Tests Unitaires**

`# test_ai_processors.py - Interface IA`  
`def test_call_ollama_api_text_output_success()`  
`def test_call_ollama_api_json_output_success()`  
`def test_call_ollama_api_malformed_json_cleanup()`

`# test_database.py - Base de donn√©es`  
`def test_init_db_basic_initialization()`  
`def test_seed_default_data_no_data_exists()`

`# test_importers.py - Import Zotero`    
`def test_extract_reference_data()`  
`def test_process_removes_duplicates()`

**Tests d'Int√©gration**

`# test_server_endpoints.py - API REST`  
`def test_create_project()`  
`def test_search_enqueues_task()`  
`def test_run_pipeline_enqueues_tasks()`

`# test_task_processing.py - T√¢ches RQ`  
`def test_search_task_adds_articles_to_db()`  
`def test_process_single_article_task_full_extraction()`

**Tests End-to-End**

`# test_e2e_workflow.py - Selenium`  
`@pytest.mark.e2e`  
`def test_e2e_create_and_find_project()`  
`def test_e2e_search_and_results_workflow()`

**Tests de Charge**

`# locustfile.py - Locust`  
`class AnalyLitUser(HttpUser):`  
    `@task(5)`  
    `def run_search_and_analysis_pipeline()`  
      
    `@task(1)`    
    `def ask_chat_rag()`

**üìä Qualit√© Code**

**M√©triques de test**:

* Tests unitaires: ‚úÖ 25+ tests

* Tests int√©gration: ‚úÖ 15+ tests

* Tests E2E: ‚úÖ 2 workflows complets

* Tests charge: ‚úÖ Scenarios r√©alistes

* Couverture: \~85% du code critique

**Pratiques qualit√©**:

* Fixtures pytest r√©utilisables

* Mocking appropri√© (Redis, IA, DB)

* Tests isolation (clean\_db)

* Assertions robustes

* Gestion erreurs compl√®te

**D√©ploiement**

**üê≥ Architecture Docker**

**Services orchestr√©s** (`docker-compose-complete.yml`):

`services:`  
  `db:          # PostgreSQL 15`  
  `redis:       # Redis 7 (cache + queues)`  
  `ollama:      # Ollama IA (GPU support)`  
  `web:         # Flask backend`  
  `worker:      # RQ worker`    
  `nginx:       # Reverse proxy + frontend`

**üöÄ D√©ploiement Production**

**Commandes essentielles**:

`# Pr√©paration`  
`cp env.example .env`  
`# √âditer .env avec vos configurations`

`# D√©marrage`  
`docker-compose -f docker-compose-complete.yml up --build -d`

`# V√©rification`  
`docker-compose ps`  
`curl http://localhost:8080/api/health`

`# Monitoring`  
`docker-compose logs -f web worker`

**Variables d'environnement critiques**:

`# Base de donn√©es`  
`DATABASE_URL=postgresql+psycopg2://user:pass@db:5432/analylit_db`

`# Services`  
`REDIS_URL=redis://redis:6379/0`    
`OLLAMA_BASE_URL=http://ollama:11434`

`# APIs externes`  
`UNPAYWALL_EMAIL=your@email.com`  
`ZOTERO_USER_ID=your_zotero_id`  
`ZOTERO_API_KEY=your_api_key`

`# S√©curit√©`    
`SECRET_KEY=your_secret_key_here`

**Commandes Utiles (via Makefile)**

Le `Makefile` √† la racine du projet fournit des raccourcis pour les op√©rations courantes.

*   **D√©marrer l'application :**
    ```bash
    make start
    ```
*   **Arr√™ter l'application :**
    ```bash
    make stop
    ```
*   **T√©l√©charger les mod√®les IA de base :**
    ```bash
    make models
    ```
*   **Lancer la suite de tests compl√®te :**
    ```bash
    make test
    ```

**üìä Monitoring Production**

**Health Checks**:

* `/api/health` \- √âtat global services

* `/api/queues/info` \- √âtat files de t√¢ches

* Logs agr√©g√©s Docker Compose

* M√©triques ressources conteneurs

**Documentation M√©thodologique**

**üéØ Justification de l'Approche**

**1\. Scoping Review vs Systematic Review**

L'application impl√©mente sp√©cifiquement la m√©thodologie Scoping Review selon les recommandations JBI (Joanna Briggs Institute) et PRISMA-ScR, particuli√®rement adapt√©e pour :

* **Cartographier** l'√©tendue de la litt√©rature sur l'alliance th√©rapeutique num√©rique

* **Identifier** les lacunes de recherche dans un domaine √©mergent

* **Examiner** la faisabilit√© d'une revue syst√©matique future

* **Clarifier** les concepts et d√©finitions dans ce domaine multidisciplinaire

**R√©f√©rences m√©thodologiques**:

* Peters, M. D. J., et al. (2020). Updated methodological guidance for JBI scoping reviews. *JBI Database of Systematic Reviews and Implementation Reports*, 18(10), 2119-2126.

* Tricco, A. C., et al. (2018). PRISMA extension for scoping reviews (PRISMA-ScR). *Annals of Internal Medicine*, 169(7), 467-473.

**2\. Intelligence Artificielle pour le Screening**

L'utilisation d'IA pour le screening pr√©liminaire est une approche valid√©e scientifiquement qui permet de :

* **Acc√©l√©rer** le processus de s√©lection sur de grands corpus (\>10,000 articles)

* **Standardiser** les crit√®res de pertinence via des prompts structur√©s

* **R√©duire** la charge de travail des chercheurs tout en maintenant la qualit√©

* **Am√©liorer** la reproductibilit√© du processus de s√©lection

**R√©f√©rences sur l'IA en revues syst√©matiques**:

* Gates, A., et al. (2020). Technology-assisted title and abstract screening for systematic reviews: a retrospective evaluation of the Abstrackr machine learning tool. *Systematic Reviews*, 9(1), 1-22.

* Tsafnat, G., et al. (2014). Systematic review automation technologies. *Systematic Reviews*, 3(1), 1-15.

* Beller, E., et al. (2018). Making progress with the automation of systematic reviews. *Systematic Reviews*, 7(1), 1-8.

**3\. Validation Inter-√©valuateurs avec Kappa**

L'impl√©mentation du coefficient Kappa de Cohen r√©pond aux standards de qualit√© m√©thodologique :

**Seuils d'interpr√©tation utilis√©s** (Landis & Koch, 1977):

* Œ∫ \< 0.20 : Accord faible

* 0.20 ‚â§ Œ∫ \< 0.40 : Accord passable

* 0.40 ‚â§ Œ∫ \< 0.60 : Accord mod√©r√©

* 0.60 ‚â§ Œ∫ \< 0.80 : Accord substantiel

* Œ∫ ‚â• 0.80 : Accord quasi parfait

**R√©f√©rences validation**:

* McHugh, M. L. (2012). Interrater reliability: the kappa statistic. *Biochemia Medica*, 22(3), 276-282.

* Landis, J. R., & Koch, G. G. (1977). The measurement of observer agreement for categorical data. *Biometrics*, 33(1), 159-174.

**4\. Approche RAG (Retrieval-Augmented Generation)**

L'impl√©mentation du syst√®me RAG pour l'analyse contextuelle des documents suit les meilleures pratiques :

**Avantages m√©thodologiques**:

* **Pr√©cision** : R√©ponses bas√©es sur le contenu r√©el des documents

* **Tra√ßabilit√©** : Sources des r√©ponses identifiables et v√©rifiables

* **Scalabilit√©** : Traitement de corpus volumineux (\>1GB de PDFs)

* **Contextualisation** : Maintien du contexte scientifique sp√©cialis√©

**R√©f√©rences RAG**:

* Lewis, P., et al. (2020). Retrieval-augmented generation for knowledge-intensive NLP tasks. *Advances in Neural Information Processing Systems*, 33, 9459-9474.

* Guu, K., et al. (2020). Retrieval augmented language model pre-training. *International Conference on Machine Learning*, 3929-3938.

**üî¨ Sp√©cialisation Alliance Th√©rapeutique Num√©rique**

**Framework conceptuel impl√©ment√©**:

L'application int√®gre les dimensions cl√©s de l'alliance th√©rapeutique selon Bordin (1979), adapt√©es au contexte num√©rique :

1. **Bond (Lien)** : Mesur√©e via scores d'empathie IA vs humain

2. **Goals (Objectifs)** : √âvalu√©e via taux d'adh√©sion et acceptabilit√©

3. **Tasks (T√¢ches)** : Analys√©e via fr√©quence d'usage et interactions

**Instruments de mesure int√©gr√©s**:

* **WAI-SR modifi√©** : Working Alliance Inventory \- Short Revised adapt√© IA

* **√âchelles d'empathie** : Comparaison scores IA vs interactions humaines

* **M√©triques d'adh√©sion** : Taux de completion, dur√©e engagement

* **Confiance algorithmique** : Scales de confiance technologique

**R√©f√©rences alliance th√©rapeutique num√©rique**:

* Bordin, E. S. (1979). The generalizability of the psychoanalytic concept of the working alliance. *Psychotherapy: Theory, Research & Practice*, 16(3), 252-260.

* Bickmore, T. W., et al. (2010). Maintaining reality: Relational agents for antipsychotic medication adherence. *Interacting with Computers*, 22(4), 276-288.

* Car, J., & Sheikh, A. (2004). E-health and therapeutic relationship. *British Medical Journal*, 329(7458), 111-112.

**üìä Standards PRISMA-ScR Impl√©ment√©s**

L'application suit int√©gralement les 20 items PRISMA-ScR :

**Section TITRE (items 1-3)**:

* Identification comme scoping review

* R√©sum√© structur√© avec objectifs/m√©thodes/r√©sultats

* Rationale et objectifs de recherche

**Section M√âTHODES (items 4-10)**:

* Crit√®res d'√©ligibilit√© PICOS adapt√©s

* Sources d'information (PubMed, arXiv, CrossRef)

* Strat√©gies de recherche document√©es

* Processus de s√©lection dual (IA \+ humain)

* Extraction de donn√©es standardis√©e

* Synth√®se narrative des r√©sultats

**Section R√âSULTATS (items 11-15)**:

* Diagramme de flux PRISMA automatique

* Caract√©ristiques des sources incluses

* R√©sultats synth√©tis√©s par th√®me

**Auto-compl√©tion intelligente** bas√©e sur les donn√©es du projet :

`# Exemple d'auto-compl√©tion`   
`if project.search_query and project.databases_used:`  
    `checklist['sections']['methods']['items'][2]['status'] = 'auto-completed'`

Cette approche m√©thodologique rigoureuse garantit la conformit√© aux standards internationaux tout en optimisant l'efficacit√© par l'automatisation intelligente.

*Guide g√©n√©r√© pour AnalyLit v4.1 \- Application de Scoping Review ATN*  
*Version: 4.1.0 | Date: 2024 | Auteur: \[Votre nom\]*