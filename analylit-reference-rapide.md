**AnalyLit v4.1 \- Guide de R√©f√©rence Rapide**

**Fonctions, API et Utilisation Pratique**

**üìö Table des Mati√®res**

1. [R√©f√©rence des Fonctions](#bookmark=id.ao9qz6yqerf8)

2. [Guide API REST](#bookmark=id.8p4u041o9zrs)

3. [Workflows d'utilisation](#bookmark=id.trfrj0m0gpym)

4. [Commandes utiles](#bookmark=id.vqhz3jcqqw8e)

5. [D√©pannage courant](#bookmark=id.22ve3k6cpjyc)

**R√©f√©rence des Fonctions**

**üîç Module fetchers.py \- Recherche Externe**

**Classe DatabaseManager**

`# Initialisation`  
`db_manager = DatabaseManager()`

`# Recherche PubMed`  
`results = db_manager.search_pubmed(`  
    `query="alliance th√©rapeutique num√©rique",`   
    `max_results=100`  
`)`

`# Recherche arXiv`    
`results = db_manager.search_arxiv(`  
    `query="therapeutic alliance AI chatbot",`  
    `max_results=50`  
`)`

`# Recherche CrossRef`  
`results = db_manager.search_crossref(`  
    `query="digital therapeutic relationship",`  
    `max_results=75`  
`)`

`# Bases disponibles`  
`databases = db_manager.get_available_databases()`  
`# Retourne: [{"id": "pubmed", "name": "PubMed", "enabled": True}, ...]`

**Fonctions utilitaires**

`# R√©cup√©ration d√©tails article`  
`details = fetch_article_details("12345678")  # PMID`  
`details = fetch_article_details("10.1000/123")  # DOI`  
`details = fetch_article_details("arxiv:2304.01234")  # arXiv`

`# URL PDF Open Access`  
`pdf_url = fetch_unpaywall_pdf_url("10.1000/journal.2024.123")`

**ü§ñ Module ai\_processors.py \- Interface IA**

`# Appel Ollama basique (texte)`  
`response = call_ollama_api(`  
    `prompt="Analysez ce r√©sum√© scientifique...",`  
    `model="llama3.1:8b",`  
    `output_format="text",`  
    `temperature=0.7`  
`)`

`# Appel Ollama structur√© (JSON)`  
`response = call_ollama_api(`  
    `prompt="Extrayez les donn√©es selon cette grille...",`  
    `model="mixtral:8x7b",`   
    `output_format="json",`  
    `temperature=0.2`  
`)`  
`# Retourne: {"population": "500 patients", "intervention": "chatbot", ...}`

`# Gestion des erreurs`  
`try:`  
    `result = call_ollama_api(prompt, model)`  
`except AIResponseError as e:`  
    `logger.error(f"Erreur IA: {e}")`

**üìä Module analysis.py \- Analyses Statistiques**

`# G√©n√©ration brouillon discussion`  
`draft = generate_discussion_draft(`  
    `df=extractions_dataframe,`  
    `call_ollama_func=call_ollama_api,`  
    `model="llama3.1:8b",`  
    `max_prompt_length=8000`  
`)`

`# Graphe de connaissances`  
`graph_data = generate_knowledge_graph_data(`  
    `df=articles_dataframe,`  
    `call_ollama_func=call_ollama_api,`  
    `model="mixtral:8x7b"`  
`)`  
`# Retourne: {"nodes": [...], "edges": [...]}`

`# Analyse th√©matique`  
`themes = analyze_themes(`  
    `abstracts=list_of_abstracts,`  
    `call_ollama_func=call_ollama_api,`  
    `model="llama3.1:8b"`  
`)`

**üíæ Module database.py \- Base de Donn√©es**

`# Initialisation base`  
`init_db()  # Utilise config par d√©faut`  
`init_db(db_url="sqlite:///test.db")  # Config custom`

`# Donn√©es par d√©faut`  
`seed_default_data(engine)`

`# Session context manager (d√©j√† g√©r√© par d√©corateurs)`  
`with db_session() as session:`  
    `project = session.get(Project, project_id)`

**üìÅ Module file\_handlers.py \- Fichiers**

`# Nettoyage nom fichier`  
`safe_name = sanitize_filename("Article: Test & Donn√©es (2024).pdf")`  
`# Retourne: "Article_Test_Donn√©es_2024.pdf"`

`# Extraction texte PDF`  
`text = extract_text_from_pdf("/path/to/article.pdf")`  
`if text:`  
    `print(f"Extrait {len(text)} caract√®res")`

`# V√©rifications`  
`if is_valid_pdf("/path/to/file.pdf"):`  
    `size = get_file_size("/path/to/file.pdf")`  
    `print(f"PDF valide, {size} bytes")`

`# Cr√©ation r√©pertoire`  
`if ensure_directory_exists("/app/projects/new_project"):`  
    `print("R√©pertoire cr√©√© avec succ√®s")`

**üì• Module importers.py \- Import Zotero**

`# Extraction donn√©es Zotero`  
`extractor = ZoteroAbstractExtractor("/path/to/zotero_export.json")`

`# Traitement complet`  
`records = extractor.process()`  
`print(f"Trait√© {len(records)} r√©f√©rences uniques")`

`# Statistiques d√©taill√©es`  
`stats = extractor.stats`  
`print(f"""`  
`Total: {stats['total']}`  
`Avec r√©sum√©: {stats['with_abstract']}`   
`Avec PMID: {stats['with_pmid']}`  
`Doublons supprim√©s: {stats['duplicates']}`  
`Erreurs: {stats['errors']}`  
`""")`

`# Acc√®s √† une r√©f√©rence`  
`for record in records:`  
    `print(f"ID: {record['article_id']}")`  
    `print(f"Titre: {record['title']}")`  
    `print(f"DOI: {record['doi']}")`

**üîî Module notifications.py \- Notifications**

`# Notification projet`  
`send_project_notification(`  
    `project_id="uuid-project-id",`  
    `notification_type="search_completed",`   
    `message="Recherche termin√©e: 150 articles trouv√©s",`  
    `data={"total_results": 150, "databases": ["pubmed", "arxiv"]}`  
`)`

`# Notification globale`  
`send_global_notification(`  
    `notification_type="system_maintenance",`  
    `message="Maintenance programm√©e dans 1h",`  
    `data={"scheduled_time": "2024-01-15T20:00:00Z"}`  
`)`

`# Gestion connexion Redis`  
`redis_conn = get_redis_connection()`  
`if redis_conn:`  
    `print("Redis connect√©")`

**Guide API REST**

**üåê Authentification et Headers**

`Content-Type: application/json`  
`Accept: application/json`

**üìã Gestion des Projets**

**Cr√©er un projet**

`POST /api/projects`  
`Content-Type: application/json`

`{`  
  `"name": "Alliance Th√©rapeutique Num√©rique 2024",`  
  `"description": "Scoping review sur l'ATN dans les soins de sant√© mentale",`  
  `"mode": "screening"`  
`}`

**R√©ponse** :

`{`  
  `"id": "550e8400-e29b-41d4-a716-446655440000",`  
  `"name": "Alliance Th√©rapeutique Num√©rique 2024",`  
  `"description": "Scoping review sur l'ATN...",`  
  `"analysis_mode": "screening",`  
  `"status": "pending",`  
  `"created_at": "2024-01-15T10:30:00Z",`  
  `"updated_at": "2024-01-15T10:30:00Z"`  
`}`

**Lister les projets**

`GET /api/projects`

**R√©cup√©rer un projet**

`GET /api/projects/550e8400-e29b-41d4-a716-446655440000`

**üîç Recherche Multi-bases**

`POST /api/search`  
`Content-Type: application/json`

`{`  
  `"project_id": "550e8400-e29b-41d4-a716-446655440000",`  
  `"query": "therapeutic alliance artificial intelligence",`  
  `"databases": ["pubmed", "arxiv", "crossref"],`  
  `"max_results_per_db": 100`  
`}`

**R√©ponse** :

`{`  
  `"message": "Recherche lanc√©e dans 3 base(s)",`  
  `"task_id": "task-uuid-12345",`  
  `"status": 202`  
`}`

**ü§ñ Pipeline IA**

**Lancer screening IA**

`POST /api/projects/{project_id}/run`  
`Content-Type: application/json`

`{`  
  `"articles": ["pmid1", "pmid2", "pmid3"],`  
  `"profile": "standard",`  
  `"analysis_mode": "screening",`  
  `"custom_grid_id": null`  
`}`

**Extraction compl√®te**

`POST /api/projects/{project_id}/run`  
`Content-Type: application/json`

`{`  
  `"articles": ["pmid1", "pmid2"],`  
  `"profile": "deep",`   
  `"analysis_mode": "full_extraction",`  
  `"custom_grid_id": "grid-uuid-789"`  
`}`

**üìä Analyses Avanc√©es**

**M√©ta-analyse**

`POST /api/projects/{project_id}/run-analysis`  
`Content-Type: application/json`

`{`  
  `"type": "meta_analysis"`  
`}`

**Scores ATN**

`POST /api/projects/{project_id}/run-analysis`  
`Content-Type: application/json`

`{`  
  `"type": "atn_scores"`  
`}`

**Graphe de connaissances**

`POST /api/projects/{project_id}/run-analysis`  
`Content-Type: application/json`

`{`  
  `"type": "knowledge_graph"`  
`}`

**üí¨ Chat RAG**

**Indexer les PDFs**

`POST /api/projects/{project_id}/index-pdfs`

**Poser une question**

`POST /api/projects/{project_id}/chat`  
`Content-Type: application/json`

`{`  
  `"question": "Quels sont les principaux types d'IA utilis√©s dans les √©tudes sur l'alliance th√©rapeutique?"`  
`}`

**R√©ponse** :

`{`  
  `"message": "Question soumise au syst√®me RAG",`  
  `"job_id": "chat-task-uuid"`  
`}`

**üì§ Export**

**Export complet**

`GET /api/projects/{project_id}/export`

**Export sp√©cialis√© th√®se**

`GET /api/projects/{project_id}/export/thesis`

**Workflows d'Utilisation**

**üéØ Workflow Scoping Review Complet**

**1\. Cr√©ation et Configuration**

`# Via API`  
`curl -X POST http://localhost:8080/api/projects \`  
  `-H "Content-Type: application/json" \`  
  `-d '{`  
    `"name": "ATN Scoping Review",`  
    `"description": "Alliance th√©rapeutique num√©rique",`    
    `"mode": "screening"`  
  `}'`

**2\. Recherche Multi-bases**

`# Lancer recherche`  
`curl -X POST http://localhost:8080/api/search \`  
  `-H "Content-Type: application/json" \`  
  `-d '{`  
    `"project_id": "PROJECT_ID",`  
    `"query": "therapeutic alliance AI chatbot",`  
    `"databases": ["pubmed", "arxiv"],`  
    `"max_results_per_db": 200`  
  `}'`

`# V√©rifier statut`  
`curl http://localhost:8080/api/tasks/TASK_ID/status`

**3\. Screening Automatis√©**

`# R√©cup√©rer articles trouv√©s`  
`curl http://localhost:8080/api/projects/PROJECT_ID/search-results`

`# Lancer screening IA`  
`curl -X POST http://localhost:8080/api/projects/PROJECT_ID/run \`  
  `-H "Content-Type: application/json" \`  
  `-d '{`  
    `"articles": ["pmid1", "pmid2", "pmid3"],`  
    `"profile": "standard",`  
    `"analysis_mode": "screening"`  
  `}'`

**4\. Extraction Structur√©e**

`# Articles pertinents (score ‚â• 7)`  
`curl http://localhost:8080/api/projects/PROJECT_ID/extractions`

`# Extraction d√©taill√©e avec grille ATN`  
`curl -X POST http://localhost:8080/api/projects/PROJECT_ID/run \`  
  `-H "Content-Type: application/json" \`  
  `-d '{`  
    `"articles": ["pmid_relevant_1", "pmid_relevant_2"],`  
    `"profile": "deep",`  
    `"analysis_mode": "full_extraction",`  
    `"custom_grid_id": "atn-grid-id"`  
  `}'`

**5\. Analyses et Synth√®ses**

`# G√©n√©ration discussion`  
`curl -X POST http://localhost:8080/api/projects/PROJECT_ID/run-discussion-draft`

`# Diagramme PRISMA`  
`curl -X POST http://localhost:8080/api/projects/PROJECT_ID/run-analysis \`  
  `-d '{"type": "prisma_flow"}'`

`# M√©ta-analyse`  
`curl -X POST http://localhost:8080/api/projects/PROJECT_ID/run-analysis \`  
  `-d '{"type": "meta_analysis"}'`

**6\. Export Final**

`# Export complet pour analyse`  
`curl -o export_complet.zip \`  
  `http://localhost:8080/api/projects/PROJECT_ID/export`

`# Export sp√©cialis√© th√®se ATN`  
`curl -o export_these.zip \`  
  `http://localhost:8080/api/projects/PROJECT_ID/export/thesis`

**üîç Workflow Chat RAG**

**1\. Upload et Indexation PDFs**

`# Upload PDFs en masse`  
`curl -X POST http://localhost:8080/api/projects/PROJECT_ID/upload-pdfs-bulk \`  
  `-F "files=@article1.pdf" \`  
  `-F "files=@article2.pdf" \`  
  `-F "files=@article3.pdf"`

`# Indexer pour RAG`  
`curl -X POST http://localhost:8080/api/projects/PROJECT_ID/index-pdfs`

**2\. Questions Interactives**

`# Poser questions contextuelles`  
`curl -X POST http://localhost:8080/api/projects/PROJECT_ID/chat \`  
  `-H "Content-Type: application/json" \`  
  `-d '{"question": "Quels instruments de mesure sont utilis√©s pour √©valuer l alliance th√©rapeutique avec l IA?"}'`

`# Historique conversation`  
`curl http://localhost:8080/api/projects/PROJECT_ID/chat-messages`

**Commandes Utiles**

**üê≥ Docker Management**

`# D√©marrage complet`  
`docker-compose -f docker-compose-complete.yml up --build -d`

`# V√©rification services`  
`docker-compose ps`  
`docker-compose logs -f web worker`

`# Red√©marrage service sp√©cifique`  
`docker-compose restart web`  
`docker-compose restart worker`

`# Nettoyage`  
`docker-compose down -v  # Supprime volumes`  
`docker system prune -a  # Nettoyage complet`

**üìä Monitoring**

`# √âtat g√©n√©ral`  
`curl http://localhost:8080/api/health`

`# Files de t√¢ches`  
`curl http://localhost:8080/api/queues/info`

`# Statut des t√¢ches actives`  
`curl http://localhost:8080/api/tasks/status`

`# Logs en temps r√©el`  
`docker-compose logs -f --tail=100 worker`

**üóÉÔ∏è Base de Donn√©es**

`# Connexion PostgreSQL`  
`docker exec -it analylit-db-v4 psql -U analylit_user -d analylit_db`

`# Commandes SQL utiles`  
`SELECT COUNT(*) FROM projects;`  
`SELECT COUNT(*) FROM search_results WHERE project_id = 'PROJECT_ID';`  
`SELECT status, COUNT(*) FROM extractions GROUP BY status;`

`# Sauvegarde`  
`docker exec analylit-db-v4 pg_dump -U analylit_user analylit_db > backup.sql`

`# Restauration`  
`docker exec -i analylit-db-v4 psql -U analylit_user analylit_db < backup.sql`

**ü§ñ Ollama Management**

`# Mod√®les disponibles`  
`curl http://localhost:11434/api/tags`

`# T√©l√©charger mod√®le`  
`curl -X POST http://localhost:11434/api/pull \`  
  `-d '{"name": "llama3.1:8b"}'`

`# Test direct Ollama`  
`curl -X POST http://localhost:11434/api/generate \`  
  `-d '{`  
    `"model": "phi3:mini",`  
    `"prompt": "Explain therapeutic alliance briefly",`  
    `"stream": false`  
  `}'`

**D√©pannage Courant**

**üö® Probl√®mes Fr√©quents**

**1\. Services ne d√©marrent pas**

`# V√©rifier ports`  
`netstat -tulpn | grep :8080`  
`netstat -tulpn | grep :5432`

`# Logs d√©taill√©s`  
`docker-compose logs web`  
`docker-compose logs db`

`# Recr√©er conteneurs`  
`docker-compose down`  
`docker-compose up --build --force-recreate`

**2\. T√¢ches RQ bloqu√©es**

`# V√©rifier worker`  
`docker-compose logs worker`

`# Vider files de t√¢ches`  
`curl -X POST http://localhost:8080/api/queues/processing/clear`  
`curl -X POST http://localhost:8080/api/queues/background/clear`

`# Red√©marrer worker`  
`docker-compose restart worker`

**3\. IA/Ollama inaccessible**

`# V√©rifier Ollama`  
`curl http://localhost:11434/api/tags`

`# Red√©marrer service`  
`docker-compose restart ollama`

`# V√©rifier GPU (si disponible)`  
`docker exec analylit-ollama-v4 nvidia-smi`

**4\. Base de donn√©es corrompue**

`# Recr√©er schema`  
`docker exec -it analylit-db-v4 psql -U analylit_user -d analylit_db`  
`DROP SCHEMA public CASCADE;`  
`CREATE SCHEMA public;`

`# Red√©marrer web pour migration`  
`docker-compose restart web`

**üìù Logs Debugging**

**Niveaux de logs**

`# Dans config_v4.py`  
`LOG_LEVEL = 'DEBUG'  # Pour d√©veloppement`  
`LOG_LEVEL = 'INFO'   # Pour production`    
`LOG_LEVEL = 'ERROR'  # Pour minimal`

**Logs sp√©cialis√©s**

`# T√¢ches RQ`  
`docker exec analylit-worker-v4 rq info`

`# Flask debugging`  
`docker exec analylit-web-v4 flask routes`

`# Base donn√©es queries`  
`# Ajouter √† config SQLAlchemy : echo=True`

**üîß Maintenance**

**Nettoyage p√©riodique**

`# Nettoyage Redis`  
`docker exec analylit-redis-v4 redis-cli FLUSHALL`

`# Nettoyage logs Docker`  
`docker system prune --volumes`

`# Nettoyage PDFs anciens`  
`find ./projects -name "*.pdf" -mtime +30 -delete`

**Mise √† jour**

`# Backup avant mise √† jour`  
`docker exec analylit-db-v4 pg_dump -U analylit_user analylit_db > backup.sql`

`# Pull nouvelles images`  
`docker-compose pull`

`# Red√©ploiement`  
`docker-compose up --build -d`

*Guide de r√©f√©rence AnalyLit v4.1 \- Pour utilisation quotidienne et d√©pannage*