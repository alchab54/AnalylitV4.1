**üöÄ AnalyLit v4.1 \- Guide de D√©marrage Express**

**De Z√©ro √† Premiers R√©sultats en 3 Jours**

**‚ö° Objectif : R√©sultats Concrets Rapides**

Vous avez d√©j√† une √©quation PubMed et des tests d'extraction. Ce guide vous m√®ne directement aux r√©sultats exploitables pour vos travaux.

**üìÖ Planning Express 3 Jours**

**JOUR 1 : Installation & Import (2-3h)**

* \[ \] D√©marrage application

* \[ \] Import √©quation PubMed existante

* \[ \] Configuration profil IA optimal

* \[ \] Test screening automatique

**JOUR 2 : Traitement & Extraction (4-6h)**

* \[ \] Screening complet corpus

* \[ \] Extraction articles pertinents

* \[ \] Upload PDFs disponibles

* \[ \] Chat RAG pour insights rapides

**JOUR 3 : Synth√®se & Export (2-4h)**

* \[ \] G√©n√©ration analyses automatiques

* \[ \] Export donn√©es pour r√©daction

* \[ \] Diagramme PRISMA

* \[ \] Premier draft discussion

**üèÅ JOUR 1 : D√©marrage Express**

**1Ô∏è‚É£ Installation Ultra-Rapide (15 min)**

`# Cloner et d√©marrer`  
`git clone [votre-repo] analylit-express`  
`cd analylit-express`

`# Configuration express`  
`cp env.example .env`  
`# √âditer rapidement les essentiels :`  
`echo "SECRET_KEY=votre_cl√©_secr√®te_ici" >> .env`  
`echo "UNPAYWALL_EMAIL=votre@email.com" >> .env`

`# D√©marrage complet`  
`docker-compose -f docker-compose-complete.yml up --build -d`

`# V√©rification (attendre ~2 min)`  
`curl http://localhost:8080/api/health`

**‚úÖ Succ√®s si** : `{"status": "ok"}` dans la r√©ponse

**2Ô∏è‚É£ Cr√©ation Projet Express (5 min)**

`# Cr√©er projet directement via API`  
`curl -X POST http://localhost:8080/api/projects \`  
  `-H "Content-Type: application/json" \`  
  `-d '{`  
    `"name": "ATN Th√®se - Sprint 1",`  
    `"description": "Alliance th√©rapeutique num√©rique - premiers r√©sultats",`  
    `"mode": "screening"`  
  `}' | jq .`

`# Sauvegarder l'ID retourn√©`  
`PROJECT_ID="[ID_RETOURN√â]"`

**3Ô∏è‚É£ Import √âquation PubMed Existante (30 min)**

**Option A \- Import Direct (Recommand√©)**

`# Lancer recherche avec votre √©quation existante`  
`curl -X POST http://localhost:8080/api/search \`  
  `-H "Content-Type: application/json" \`  
  `-d '{`  
    `"project_id": "'$PROJECT_ID'",`  
    `"query": "VOTRE_√âQUATION_PUBMED_ICI",`   
    `"databases": ["pubmed"],`  
    `"max_results_per_db": 500`  
  `}'`

`# V√©rifier progression (r√©p√©ter toutes les 30s)`  
`curl http://localhost:8080/api/projects/$PROJECT_ID/search-stats`

**Option B \- Import CSV Manuel (si vous avez d√©j√† les r√©sultats)**

`# Pr√©parer CSV avec colonnes : title, abstract, authors, pmid, doi`  
`# Upload via interface web √† http://localhost:8080`

**4Ô∏è‚É£ Configuration Profil IA Optimal (10 min)**

`# Cr√©er profil "express" pour vitesse`  
`curl -X POST http://localhost:8080/api/profiles \`  
  `-H "Content-Type: application/json" \`  
  `-d '{`  
    `"name": "Express ATN",`  
    `"description": "Profil optimis√© pour r√©sultats rapides ATN",`  
    `"preprocess_model": "phi3:mini",`  
    `"extract_model": "llama3.1:8b",`   
    `"synthesis_model": "llama3.1:8b",`  
    `"temperature": 0.3`  
  `}'`

`# T√©l√©charger mod√®les (en parall√®le pendant autres t√¢ches)`  
`curl -X POST http://localhost:8080/api/ollama/pull \`  
  `-d '{"model": "phi3:mini"}'`

`curl -X POST http://localhost:8080/api/ollama/pull \`  
  `-d '{"model": "llama3.1:8b"}'`

**5Ô∏è‚É£ Test Screening √âchantillon (30 min)**

`# R√©cup√©rer premiers articles`  
`curl http://localhost:8080/api/projects/$PROJECT_ID/search-results?per_page=10`

`# Tester screening sur 10 articles`  
`curl -X POST http://localhost:8080/api/projects/$PROJECT_ID/run \`  
  `-H "Content-Type: application/json" \`  
  `-d '{`  
    `"articles": ["pmid1", "pmid2", "pmid3", "pmid4", "pmid5"],`  
    `"profile": "Express ATN",`  
    `"analysis_mode": "screening"`  
  `}'`

`# V√©rifier r√©sultats test`  
`curl http://localhost:8080/api/projects/$PROJECT_ID/extractions | jq '.[] | {pmid: .pmid, score: .relevance_score, decision: .relevance_justification}'`

**‚úÖ Objectif Jour 1** : Syst√®me op√©rationnel, √©quation import√©e, test screening valid√©

**üéØ JOUR 2 : Production de Donn√©es**

**1Ô∏è‚É£ Screening Complet Express (1-2h)**

`# R√©cup√©rer tous les PMIDs trouv√©s`  
`curl http://localhost:8080/api/projects/$PROJECT_ID/search-results?per_page=1000 > all_results.json`

`# Extraire liste PMIDs (script Python rapide)`  
`python3 -c "`  
`import json`  
`with open('all_results.json') as f:`  
    `data = json.load(f)`  
`pmids = [r['article_id'] for r in data['results']]`  
`print(' '.join(f'\"{pmid}\"' for pmid in pmids[:100]))  # Batch de 100`  
`" > pmids_batch1.txt`

`# Lancer screening batch 1`  
`curl -X POST http://localhost:8080/api/projects/$PROJECT_ID/run \`  
  `-H "Content-Type: application/json" \`  
  `-d "{`  
    `\"articles\": [$(cat pmids_batch1.txt | tr ' ' ',')],`  
    `\"profile\": \"Express ATN\",`  
    `\"analysis_mode\": \"screening\"`  
  `}"`

**Monitoring Progress**

`# Script de monitoring (ex√©cuter en boucle)`  
`watch -n 30 "curl -s http://localhost:8080/api/projects/$PROJECT_ID | jq '.processed_count, .pmids_count'"`

**2Ô∏è‚É£ Identification Articles Pertinents (30 min)**

`# Articles avec score ‚â• 7 (seuil pertinence)`  
`curl "http://localhost:8080/api/projects/$PROJECT_ID/extractions" | \`  
  `jq '.[] | select(.relevance_score >= 7) | {pmid: .pmid, title: .title, score: .relevance_score}' > articles_pertinents.json`

`# Compter articles pertinents`  
`wc -l articles_pertinents.json`

**3Ô∏è‚É£ Cr√©ation Grille ATN Express (20 min)**

`# Cr√©er grille d'extraction ATN sp√©cialis√©e`  
`curl -X POST http://localhost:8080/api/projects/$PROJECT_ID/grids \`  
  `-H "Content-Type: application/json" \`  
  `-d '{`  
    `"name": "ATN Express",`  
    `"fields": [`  
      `{"name": "Type_IA", "description": "Type syst√®me IA (chatbot, avatar, assistant)"},`  
      `{"name": "Population", "description": "Population √©tudi√©e"},`  
      `{"name": "Score_empathie_IA", "description": "Score empathie IA si mentionn√©"},`  
      `{"name": "Score_empathie_humain", "description": "Score empathie humain comparatif"},`  
      `{"name": "WAI_SR_score", "description": "Score Working Alliance Inventory"},`  
      `{"name": "Taux_adh√©sion", "description": "Taux adh√©sion/engagement patients"},`  
      `{"name": "Acceptabilit√©", "description": "Acceptabilit√© patients"},`  
      `{"name": "Barri√®res", "description": "Barri√®res identifi√©es"},`  
      `{"name": "Facilitateurs", "description": "Facilitateurs identifi√©s"},`  
      `{"name": "Outcomes", "description": "R√©sultats principaux"}`  
    `]`  
  `}' | jq .id`

**4Ô∏è‚É£ Extraction D√©taill√©e Articles Cl√©s (2-3h)**

`# Extraire PMIDs des 20 articles les plus pertinents`  
`python3 -c "`  
`import json`  
`with open('articles_pertinents.json') as f:`  
    `articles = [json.loads(line) for line in f]`  
`top_articles = sorted(articles, key=lambda x: x['score'], reverse=True)[:20]`  
`pmids = [a['pmid'] for a in top_articles]`  
`print(' '.join(f'\"{pmid}\"' for pmid in pmids))`  
`" > top_pmids.txt`

`# Extraction compl√®te avec grille ATN`  
`curl -X POST http://localhost:8080/api/projects/$PROJECT_ID/run \`  
  `-H "Content-Type: application/json" \`  
  `-d "{`  
    `\"articles\": [$(cat top_pmids.txt | tr ' ' ',')],`  
    `\"profile\": \"Express ATN\",`   
    `\"analysis_mode\": \"full_extraction\",`  
    `\"custom_grid_id\": \"$GRID_ID\"`  
  `}"`

**5Ô∏è‚É£ Upload PDFs Disponibles (1h)**

`# Si vous avez des PDFs de vos tests pr√©c√©dents`  
`find /path/to/your/pdfs -name "*.pdf" -exec \`  
  `curl -X POST http://localhost:8080/api/projects/$PROJECT_ID/upload-pdfs-bulk \`  
  `-F "files=@{}" \;`

`# Indexer pour RAG`  
`curl -X POST http://localhost:8080/api/projects/$PROJECT_ID/index-pdfs`

**‚úÖ Objectif Jour 2** : Screening complet, articles pertinents identifi√©s, extractions d√©taill√©es lanc√©es

**üìä JOUR 3 : Synth√®se et Livrables**

**1Ô∏è‚É£ Analyses Automatiques Express (1h)**

`# Diagramme PRISMA automatique`  
`curl -X POST http://localhost:8080/api/projects/$PROJECT_ID/run-analysis \`  
  `-d '{"type": "prisma_flow"}'`

`# M√©ta-analyse scores`  
`curl -X POST http://localhost:8080/api/projects/$PROJECT_ID/run-analysis \`  
  `-d '{"type": "meta_analysis"}'`

`# Scores ATN sp√©cialis√©s`  
`curl -X POST http://localhost:8080/api/projects/$PROJECT_ID/run-analysis \`  
  `-d '{"type": "atn_scores"}'`

`# G√©n√©ration discussion automatique`  
`curl -X POST http://localhost:8080/api/projects/$PROJECT_ID/run-discussion-draft`

**2Ô∏è‚É£ Export Donn√©es Th√®se (30 min)**

`# Export sp√©cialis√© th√®se ATN (avec graphiques HD)`  
`curl -o export_these_atn.zip \`  
  `http://localhost:8080/api/projects/$PROJECT_ID/export/thesis`

`# Export complet pour analyse`  
`curl -o export_complet.zip \`  
  `http://localhost:8080/api/projects/$PROJECT_ID/export`

`# D√©compresser et organiser`  
`unzip export_these_atn.zip -d resultats_these/`  
`unzip export_complet.zip -d donnees_brutes/`

**3Ô∏è‚É£ Chat RAG pour Insights Rapides (1h)**

`# Questions cl√©s pour votre th√®se`  
`questions=(`  
  `"Quels sont les principaux types d'intelligence artificielle utilis√©s dans l'alliance th√©rapeutique?"`  
  `"Quels instruments de mesure sont utilis√©s pour √©valuer l'alliance th√©rapeutique num√©rique?"`  
  `"Quelles sont les principales barri√®res √† l'adoption de l'IA dans la relation th√©rapeutique?"`  
  `"Quels sont les scores d'empathie rapport√©s entre IA et humains?"`  
  `"Quelles populations ont √©t√© √©tudi√©es dans ces recherches?"`  
`)`

`# Poser questions automatiquement`  
`for question in "${questions[@]}"; do`  
  `echo "=== $question ==="`  
  `curl -X POST http://localhost:8080/api/projects/$PROJECT_ID/chat \`  
    `-H "Content-Type: application/json" \`  
    `-d "{\"question\": \"$question\"}"`  
  `sleep 10  # Attendre r√©ponse`  
`done`

`# R√©cup√©rer historique complet`  
`curl http://localhost:8080/api/projects/$PROJECT_ID/chat-messages > insights_rag.json`

**4Ô∏è‚É£ G√©n√©ration Outputs R√©daction (1-2h)**

**Tableau de Synth√®se Articles Cl√©s**

`# G√©n√©rer CSV pour tableau articles`  
`curl http://localhost:8080/api/projects/$PROJECT_ID/extractions | \`  
  `jq -r '.[] | select(.relevance_score >= 7 and .extracted_data != null) |`   
    `[.pmid, .title, .relevance_score, (.extracted_data | fromjson | .Type_IA // "N/A"), (.extracted_data | fromjson | .Population // "N/A")] |`   
    `@csv' > tableau_articles_cles.csv`

`# Ajouter header`  
`echo "PMID,Titre,Score_Pertinence,Type_IA,Population" | cat - tableau_articles_cles.csv > temp && mv temp tableau_articles_cles.csv`

**M√©triques ATN Agr√©g√©es**

`# Extraire m√©triques pour votre th√®se`  
`python3 -c "`  
`import json, statistics`  
`with open('donnees_brutes/extractions.json') as f:`  
    `extractions = json.load(f)`

`scores_empathie_ia = []`  
`scores_empathie_humain = []`  
`types_ia = []`

`for ext in extractions:`  
    `if ext.get('extracted_data'):`  
        `data = json.loads(ext['extracted_data'])`  
        `if data.get('Score_empathie_IA'):`  
            `try:`  
                `scores_empathie_ia.append(float(data['Score_empathie_IA']))`  
            `except: pass`  
        `if data.get('Score_empathie_humain'):`  
            `try:`  
                `scores_empathie_humain.append(float(data['Score_empathie_humain']))`  
            `except: pass`  
        `if data.get('Type_IA'):`  
            `types_ia.append(data['Type_IA'])`

`print('=== M√âTRIQUES ATN POUR TH√àSE ===')`  
`print(f'Articles avec donn√©es ATN: {len([e for e in extractions if e.get(\"extracted_data\")])}')`  
`print(f'Scores empathie IA (n={len(scores_empathie_ia)}): moyenne={statistics.mean(scores_empathie_ia) if scores_empathie_ia else \"N/A\"}')`  
`print(f'Scores empathie humain (n={len(scores_empathie_humain)}): moyenne={statistics.mean(scores_empathie_humain) if scores_empathie_humain else \"N/A\"}')`  
`print(f'Types IA les plus fr√©quents: {max(set(types_ia), key=types_ia.count) if types_ia else \"N/A\"}')`  
`" > metriques_atn_these.txt`

**‚úÖ Objectif Jour 3** : Analyses compl√®tes, exports pr√™ts, m√©triques pour r√©daction

**üìã Checklist Livrables Express**

**‚úÖ Fichiers Produits (Fin Jour 3\)**

**Donn√©es Brutes**

* \[ \] `donnees_brutes/extractions.json` \- Toutes extractions

* \[ \] `donnees_brutes/search_results.json` \- Articles trouv√©s

* \[ \] `donnees_brutes/processing_log.json` \- Log complet

**Analyses**

* \[ \] `resultats_these/prisma_flow.png` \- Diagramme PRISMA HD

* \[ \] `resultats_these/meta_analysis_plot.png` \- Graphiques m√©ta-analyse

* \[ \] `resultats_these/donnees_atn_these.xlsx` \- Donn√©es ATN structur√©es

**Synth√®ses**

* \[ \] `tableau_articles_cles.csv` \- Top articles avec m√©tadonn√©es

* \[ \] `metriques_atn_these.txt` \- M√©triques agr√©g√©es

* \[ \] `insights_rag.json` \- R√©ponses chat pour insights

**R√©daction**

* \[ \] Brouillon discussion automatique (dans export)

* \[ \] Checklist PRISMA-ScR compl√©t√©e

* \[ \] Statistiques descriptives

**üéØ Utilisation Imm√©diate**

**Pour R√©daction Th√®se**

1. **Diagramme PRISMA** ‚Üí Section M√©thodes

2. **Tableau articles cl√©s** ‚Üí Appendice/R√©sultats

3. **M√©triques ATN** ‚Üí Section R√©sultats quantitatifs

4. **Discussion automatique** ‚Üí Base section Discussion

5. **Insights RAG** ‚Üí Citations et arguments

**Pour Pr√©sentation**

1. **Graphiques m√©ta-analyse** ‚Üí Slides r√©sultats

2. **Checklist PRISMA** ‚Üí Validit√© m√©thodologique

3. **Stats descriptives** ‚Üí Vue d'ensemble corpus

**üö® R√©solution Probl√®mes Express**

**Probl√®me : T√¢ches RQ Bloqu√©es**

`# Diagnostic rapide`  
`curl http://localhost:8080/api/tasks/status`  
`curl http://localhost:8080/api/queues/info`

`# Solution rapide`  
`docker-compose restart worker`  
`curl -X POST http://localhost:8080/api/queues/processing/clear`

**Probl√®me : Ollama Mod√®les Manquants**

`# V√©rifier mod√®les`  
`curl http://localhost:11434/api/tags`

`# Force download`  
`docker exec analylit-ollama-v4 ollama pull phi3:mini`  
`docker exec analylit-ollama-v4 ollama pull llama3.1:8b`

**Probl√®me : M√©moire Insuffisante**

`# Monitoring ressources`  
`docker stats`

`# Solutions temporaires`  
`docker-compose restart ollama  # Lib√®re m√©moire GPU`  
`sudo sysctl vm.drop_caches=3   # Lib√®re RAM syst√®me`

**üìû Support Express**

**Logs Debugging Critiques**

`# Erreurs critique uniquement`  
`docker-compose logs --tail=50 web worker | grep -i error`

`# Statut services essentiels`  
`docker-compose ps | grep -v "Up"`

**Commandes de R√©cup√©ration**

`# Reset complet si n√©cessaire (ATTENTION: perte donn√©es)`  
`docker-compose down -v`  
`docker-compose up --build -d`  
`# Puis relancer import √©quation PubMed`

**üèÜ Objectif Final (72h)**

**Vous devriez avoir** :

* ‚úÖ **500-1000 articles** screen√©s automatiquement

* ‚úÖ **20-50 articles pertinents** avec extraction ATN compl√®te

* ‚úÖ **Diagramme PRISMA** publication-ready

* ‚úÖ **M√©triques quantitatives** pour r√©sultats th√®se

* ‚úÖ **Tableau synth√®se** articles cl√©s avec m√©tadonn√©es

* ‚úÖ **Draft discussion** bas√© sur corpus analys√©

* ‚úÖ **Insights RAG** pour argumentation th√®se

**Pr√™t pour** :

* R√©daction sections M√©thodes/R√©sultats

* Cr√©ation tableaux/figures th√®se

* Argumentation discussion bas√©e donn√©es

* Validation m√©thodologique PRISMA-ScR

*üöÄ Guide Express AnalyLit v4.1 \- De z√©ro √† r√©sultats exploitables en 72h*