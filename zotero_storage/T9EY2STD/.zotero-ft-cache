Research paper
Is digital alliance associated with engagement & outcomes in guided digital interventions? An analysis of data from two studies
Natalia Macrynikola , Sarah Chang , John Torous *
Division of Digital Psychiatry, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, USA
ARTICLE INFO
Keywords:
Digital interventions Digital alliance Therapeutic alliance mHealth Apps Smartphone Depression
ABSTRACT
Background: Digital interventions have the potential to increase access to care. Despite their demonstrated efficacy in clinical trials, however, they often suffer from low sustained engagement in real-world contexts. Digital alliance (i.e., therapeutic alliance between user and app) may enhance engagement and outcomes, but its role in guided digital interventions (i.e., those with human support) is little understood. Objective: Using data from two studies involving the mental health app mindLAMP, we examined digital alliance and its association with engagement and outcomes. Methods: In Study 1, mindLAMP was offered as a standalone app with several brief check-ins by a digital navigator (aka coach). In Study 2, mindLAMP was integrated into a brief teletherapy program supported by a clinician and a digital navigator. Digital alliance was assessed near study midpoint with a validated measure. Results: Digital alliance was associated with engagement in both studies. In Study 1, digital alliance predicted subsequent app engagement, b = 0.18, p < .01, adjusting for prior engagement, which remained significant, b = 0.62, p < .001. Similarly, in Study 2, digital alliance predicted subsequent engagement, b = 0.21, p < .01, adjusting for prior engagement, b = 0.22, p < .05. Digital alliance also predicted co-morbid anxiety and depressive symptoms at post-intervention, after adjusting for baseline symptoms, in Study 1, b = 0.27, p < .001, but not in Study 2. Limitations: Participant demographics were not representative of the general population. Conclusion: Findings underscore the potential of digital alliance in enhancing engagement and outcomes in digital interventions.
1. Introduction
Digital interventions are increasingly being adopted to increase access to care. Defined as interventions delivered via apps and/or Internetconnected devices, digital interventions can overcome treatment access barriers (e.g., cost, distance, stigma, provider shortage) and can be used to widely disseminate evidence-based therapeutic interventions. Their scalable nature offers a pathway toward greater access to intervention at a time when the global burden of mental illness far outpaces the availability of traditional support. Given this potential, interest in digital mental health interventions has grown dramatically over the past decade. Numerous RCTs have tested their efficacy, and meta-analytic evidence of the results of these investigations suggests that these interventions can augment care for common mental health problems, such as depression and anxiety (Goldberg et al., 2022a, b; Linardon et al., 2019). However, digital
interventions are not a panacea, and research has also revealed areas of concern. Results from high-quality research studies of digital mental health interventions suggest effects are often smaller than those of faceto-face therapeutic interventions (Goldberg et al., 2022a, b). Furthermore, real-world efficacy outside of clinical trials is tempered by low sustained user engagement (Baumel et al., 2019; Linardon et al., 2020). This is especially the case with self-help apps, where 90 % of users may stop using an app within 10 days (Baumel et al., 2019). It is thus imperative to understand the processes that impact both engagement and efficacy in digital interventions in order to optimize them to support engagement and outcomes. One well-studied process drawn from a long line of face-to-face therapy research is the therapeutic alliance (Horvath and Greenberg, 1989). Defined as agreement on treatment goals and tasks as well as the presence of an emotional bond between client and therapist, the therapeutic alliance is known to generally contribute to treatment
* Corresponding author at: Beth Israel Deaconess Medical Center, 330 Brookline Avenue, Boston, MA 02215, USA. E-mail addresses: nmacryni@bidmc.harvard.edu (N. Macrynikola), jtorous@bidmc.harvard.edu (J. Torous).
Contents lists available at ScienceDirect
Journal of Affective Disorders
journal homepage: www.elsevier.com/locate/jad
https://doi.org/10.1016/j.jad.2025.04.127 Received 13 May 2024; Received in revised form 31 December 2024; Accepted 21 April 2025
Journal of Aρective Disorders 383 (2025) 335–340
Available online 22 April 2025 0165-0327/© 2025 Elsevier B.V. All rights are reserved, including those for text and data mining, AI training, and similar technologies.


engagement and outcomes (Horvath and Greenberg, 1989). Given its importance in face-to-face therapy, it is reasonable to suspect that there may be a digital form of therapeutic alliance in the context of digital mental health interventions. If so, could this digital alliance contribute to engagement and outcomes? Moreover, digital interventions take various forms, as their digital components can be offered as standalone interventions (i.e., unguided) or in conjunction with various degrees of human support (i.e., guided). This human support component leads to a second and related question: Does digital alliance differentially contribute to outcomes in digital interventions offered alongside different levels of human support? The existing literature so far offers partial answers.
1.1. Digital alliance, engagement, & outcomes: brief overview of findings to date
Empirical investigation into the digital alliance and its contribution to engagement and outcomes is nascent but growing. To facilitate investigation, Henson and colleagues proposed a brief digital alliance measure, known as the Digital Working Alliance Inventory (DWAI; Henson et al., 2019). Based on the well-validated and accepted therapeutic alliance measure (WAI) used in face-to-face therapy research, the DWAI measure consists of WAI items that have been lightly adapted to become relevant to the digital component of interventions (e.g., “I trust this app to guide me toward my personal goals”). The DWAI measure is brief and easily deliverable via smartphones and retains the structure of the WAI measure, with the three aspects of alliance (i.e., goals, tasks, bond) assessed remaining present. A subsequent validation study of this measure found that DWAI has adequate psychometric properties (Goldberg et al., 2022a). Regarding DWAI and its relation to engagement and outcomes in unguided digital interventions (i.e., those offered as standalone interventions, without human support), little research has been conducted to date. Using data from an RCT evaluation of a standalone mindfulness app, Goldberg and colleagues found that digital alliance was positively associated with user engagement (days of app use), and midpoint DWAI predicted change in psychological distress (a composite measure of depression, anxiety, and stress) from baseline to the end of the intervention (Goldberg et al., 2022a). In another longitudinal analysis of the same RCT data, these researchers found bidirectional associations between digital alliance and distress such that increases in one were linked to increases in the other and vice versa (Goldberg et al., 2023). Taken together, these findings suggest that in unguided digital interventions, digital alliance may promote engagement and may complement change in outcomes. However, this is not always the case, as findings from another study of undergraduate students self-reporting high stress showed no association between DWAI and change in depression or anxiety scores (Currey and Torous, 2023). Still, given the differences in study populations and types of psychopathology in these studies, it is not possible to draw firm conclusions, based on the extant literature, around the impact of digital alliance on engagement or outcomes for unguided digital interventions. Regarding findings in the context of guided digital interventions (i.e., those that offer not just digital components but also incorporate human support), some research suggests that DWAI is associated with improved engagement and outcomes. In one recent study using data from an RCT of a digital cognitive behavioral (CBT) program offered in conjunction with face-to-face therapy, both digital alliance and therapeutic alliance (i.e., alliance with the clinician) were examined in relation to outcomes (Benitez et al., 2023). Results revealed that within-person increases in digital alliance and therapeutic alliance predicted modest decreases in the outcome of future alcohol use – and that both forms of alliance impacted future alcohol use to a similar extent (Benitez et al., 2023). These findings suggest that in digital interventions, the digital and human components of the intervention may both contribute to outcomes, potentially yielding a synergistic intervention effect. Another
RCT examined digital alliance in a sample of 193 depressed patients receiving a blended CBT intervention that offered 10 sessions, some of which were delivered in person with a clinician and some offered as online modules (Herrero et al., 2020). Linear regressions showed that digital alliance predicted change in depressive symptoms from baseline to post-intervention, with higher alliance scores predicting a greater decrease in depressive symptoms (Herrero et al., 2020). Taken together, these findings suggest that digital alliance may be an important marker of client satisfaction with a digital intervention and a contributor to outcomes. However, more research is needed to replicate findings on the link between digital alliance and engagement in guided digital interventions, which continues to be largely unexamined.
1.2. The present study
In the present analyses, we sought to address these aforementioned gaps by examining the association of digital alliance with engagement and outcomes in guided interventions with different degrees of human support. We used data from two studies of the mental health app mindLAMP: In the first, mindLAMP was offered with brief, virtual checkins with a digital navigator (or coach); in the second, it was offered in the context of hybrid care and was thus supported by weekly therapy sessions with a clinician and brief weekly check-ins with a digital navigator, all via telehealth. The therapeutic content of the app itself was similar in both studies, as further discussed below. Using this data, we sought to answer two primary research questions: First, was digital alliance associated with user engagement in both of these digital interventions featuring similar therapeutic content but different degrees of human support? Second, did digital alliance differentially impact outcomes in these interventions? Based on the prior reviewed literature, we made several hypotheses. First, regarding engagement, we hypothesized that digital alliance would be positively associated with user engagement metrics in both guided interventions. We also hypothesized that earlier digital alliance would predict subsequent engagement in both studies. However, regarding outcomes, we hypothesized that digital alliance would have a differential impact in each study. In Study 1, where human support was minimal, we expected a direct effect of digital alliance on outcomes. Conversely, in Study 2, where app use was supported by weekly therapy sessions, we hypothesized that there would be no direct effect. This hypothesis was based on recent findings suggesting that in this more heavily guided intervention, digital alliance does not impact outcomes directly but rather indirectly – to the degree that it engages the intervention's mechanism, which in this case was emotion regulation selfefficacy (Macrynikola et al., 2024a). Based on these recent findings, we anticipated that in the more heavily guided intervention in Study 2, digital alliance may have its impact on outcomes through other, more proximal mechanisms and thus not demonstrate a direct effect on comorbid anxiety and depressive symptoms.
2. Methods
Both digital intervention studies used mindLAMP, a highly customizable open-source mobile mental health app available in iOS and Android stores (Bilden and Torous, 2022). To be eligible for the study, participants were required to own a smartphone that is compatible with mindLAMP.
2.1. Study 1 participants & procedure
Study 1 sought to assess the potential efficacy of “minimally guided care” for individuals with anxiety and depressive symptoms. This approach involved ongoing app use, along with a few human support sessions by a trained coach called a “digital navigator.” The role of the digital navigator was to provide tech support and encourage app use in line with participant goals. A standardized digital navigator training
N. Macrynikola et al. Journal of Aρective Disorders 383 (2025) 335–340
336


guide (Wisniewski et al., 2020) and the study protocol (Camacho et al., 2023) have been published online. The average age of the 156 participants included in Study 1 was 35.4 (SD = 12.5). Approximately 77 % identified as female, 17 % as male, 4 % as nonbinary, and 2 % preferred not to describe their gender identity. Additionally, approximately 72 % identified as White, 9 % as African American, 6 % as Asian, 6 % as Latinx, 1 % as Native Hawaiian or Pacific Islander, and 6 % as another race/ethnicity not listed in the provided options. Participants were recruited from ResearchMatch.org and subsequently enrolled in this study between July 2021 and February 2022. Inclusion criteria were 1) minimum age 18, 2) ownership of a mindLAMP-compatible smartphone (iOS or Android), and 3) minimum score of 5 on the GAD-7 scale. At baseline, participants met virtually with the digital navigator, who explained study procedures and administered a baseline questionnaire. Then, for six weeks, participants used the app on their own to complete daily and weekly mood and symptom assessments, as well as therapeutic modules containing cognitive-behavioral and mindfulnessbased exercises (e.g., identifying thought patterns, practicing mindfulness, journaling, behavioral activation, strengths reflection). Participants met twice more with the digital navigator: once on week 2 to receive support around customizing app use for their needs and once again at the end of the six weeks to complete a post-intervention questionnaire. An Institutional Review Board (IRB) approved all study procedures.
2.2. Study 2 participants & procedure
The goal of Study 2 was to assess the feasibility and potential efficacy of the Digital Clinic, a model of brief, app-augmented emotion-focused CBT offered via telehealth by a clinician and supported by a digital navigator. Participation in this study was offered to adults with common mental health conditions, such as depression and anxiety, with the goal of clinical improvement through scalable and accessible means (Macrynikola et al., 2025). The mean age of the 115 participants in Study 2 was 40.1 (SD = 14.1). Approximately 66 % identified as cisgender women, 29 % as cisgender men, 1 % as transgender men, 4 % as non-binary, and 1 % preferred not to report gender. Additionally, roughly 75 % identified as White, 13 % as Asian, 7 % as African American, and 4 % as another race/ ethnicity not listed in the options provided. In Study 2, a member of the research team conducted informational meetings twice a year with primary care doctors at two public hospitals in the northeastern region of the U.S. The purpose of these meetings was to introduce the Digital Clinic and ask doctors to refer their eligible patients. As such, participants in Study 2 were primarily treatment-seeking adults referred by their primary care physician between late 2022 and early 2024 (Macrynikola et al., 2025). Inclusion criteria were a) minimum age 18, b) fluency in English, and c) ownership of an Android or Apple phone. Exclusion criteria included the following: significant intellectual or attentional impairments that could hinder participation in therapy, acute suicidality necessitating a higher level of care, or current enrollment in a more intensive treatment program, such as inpatient care or a rehabilitation program. A digital navigator met with participants in an initial virtual session to introduce them to clinic procedures and administer a baseline questionnaire. (A similar questionnaire was offered at midpoint and at the end of the intervention period.) Then, participants began seeing a trained clinician for weekly sessions of emotion-focused CBT. In between sessions, participants used the app to complete mood check-ins and practice adaptive skills they learned in sessions (e.g., reframing thoughts, mindfulness practice). Participants also met weekly with a digital navigator, whose role was to provide tech support, share app data, and encourage app use aligned with participant goals. This model of treatment has been described in more detail elsewhere (Macrynikola et al., 2023; Macrynikola et al., 2025). The Institutional Review Board
deemed the present project Quality Improvement.
2.3. Materials
2.3.1. mindLAMP
The mindLAMP app is an open-source app designed to be easily tailored by different research teams to meet the specific needs of different populations. The app was developed by the Division of Digital Psychiatry at Beth Israel Deaconess Medical Center, Harvard Medical School. mindLAMP was customized for each study to offer brief symptom assessments and CBT-based exercises. The app also has the capability to generate digestible visualizations of patient data, viewable by both clinicians and patients, as well as collect digital phenotyping data. The app interface comprises four main navigation tabs: Learn, Assess, Manage, and Portal. The Learn tab offers psychoeducational tips and resources. The Assess tab holds assessment surveys, including the PHQ-9, GAD-7, and DWAI. The Manage tab provides interactive modules with therapeutic intervention exercises, such as audio-guided mindfulness practice and CBT-based cognitive restructuring. The goal of this tab is to facilitate the regular practice of therapeutic skills outside therapy sessions. The Portal tab generates visualizations of the collected data so that patients and clinicians can monitor and discuss symptom change over time. mindLAMP has been used to deliver therapeutic activities to individuals with prevalent mental health conditions such as anxiety and depression, and it has demonstrated effectiveness in symptom reduction (Chang et al., 2023a; Chang et al., 2023b; Currey and Torous, 2023). More information on mindLAMP's development and multiple studies describing its use can be found elsewhere (Bilden and Torous, 2022). Data for the present analyses was extracted from mindLAMP using Cortex, a data analysis toolkit (Vaidyam et al., 2022).
2.4. Measures
2.4.1. Digital Working Alliance
The Digital Working Alliance Inventory (DWAI; Henson et al., 2019) consists of six questions assessing the alliance between a client and the therapeutic technology. The DWAI measure uses questions slightly modified from the Working Alliance Inventory - Short Revised (WAI-SR; Hatcher and Gillaspy, 2006) to fit the nuances of digital therapeutic interactions. Each of the six DWAI items are rated from 1 (strongly disagree) to 7 (strongly agree) and summed to yield a total score; however, due to staff error, DWAI was rated on a five-point scale in Study 1 (range 6 to 30), but on the proper seven-point scale in Study 2 (range 6 to 42). The DWAI score in the present analyses was measured on week 2 (near study midpoint) in Study 1 and taken from a survey completed closest to the midpoint (+ 10 days) in Study 2. DWAI has demonstrated good convergent validity and high internal consistency reliability (Cronbach's a = 0.88–0.92) in prior studies (Goldberg et al., 2022a, b). In Study 2, Cronbach's alpha was 0.94.
2.4.2. App engagement
Given disagreement in the field on what qualifies as the ideal engagement metric for digital interventions, we used several kinds of engagement metrics. For each participant, we obtained directly from mindLAMP the total number of app activities they completed during the intervention period, their activity count for each week, and the percentage of days they were active on the app throughout the intervention. App activities included both mood/symptom surveys and therapeutic interventions, such as cognitive restructuring. Averages of these metrics were calculated for each study sample. A composite variable with summed activity counts from weeks 3 to 6 in Study 1 and weeks 3 to 8 in Study 2 was also computed for use in linear regressions in each study.
2.4.3. Co-morbid anxiety and depressive symptoms
Co-morbid anxiety and depressive symptoms were assessed with the Patient Health Questionnaire Anxiety-Depression Scale (PHQ-ADS;
N. Macrynikola et al. Journal of Aρective Disorders 383 (2025) 335–340
337


Kroenke et al., 2016), a composite measure that combines the Patient Health Questionnaire-9 (PHQ-9; Kroenke et al., 2001), which assesses symptoms of major depressive disorder with nine items, and the Generalized Anxiety Disorder-7 (GAD-7; Spitzer et al., 2006), a sevenitem assessment of symptoms of anxiety disorders. On these scales, participants rate the extent to which each depressive or anxiety symptom bothered them in the past two weeks, from 0 (not at all) to 3 (nearly every day). Items are then summed to yield a total score on a range of 0 to 27 on the PHQ-9 and 0 to 21 on the GAD-7; the PHQ-ADS score is a sum of both of these scores. The PHQ-9 and GAD-7 have each demonstrated validity and reliability in assessing severity of depressive and anxiety symptoms, respectively (Kroenke et al., 2010). In addition, the PHQ-ADS has shown high internal consistency reliability (alpha 0.8–0.9) in multiple studies, as well as strong convergent and construct validity (Kroenke et al., 2016). For ease of interpreting results in the present study, PHQ-ADS cutoffs are as follows: below 10 indicates minimal symptoms, 10–19 mild, 20–29 moderate, and 30 and above severe (Kroenke et al., 2016).
2.5. Data analytic plan
Analyses were conducted in IBM SPSS Statistics, Version 29.0.1.0 (171). We first obtained descriptive statistics for demographic variables in each study. We then excluded participants who at baseline scored less than a 10 on the PHQ-ADS (i.e., minimal/no co-morbid symptoms), and we looked for demographic differences in the dependent variable (i.e., post-intervention co-morbid symptoms) via a t-test for race (minority versus majority), a one-way ANOVA for gender identity (female, male, non-binary or other), and a correlation with age, for each study separately. Because we found no significant differences or associations, we did not adjust for demographic variables in subsequent analyses. We then obtained descriptive statistics on key variables of interest and computed bivariate correlations to examine associations. Because some of our variables were not normal, we conducted Spearman's rho correlations. We also checked for zero-inflation in the distribution of our engagement metrics before averaging them, and a nominal percent of the sample (< 3 %) had engagement of <1 for the key metrics examined (weekly app activities, percent days active on the app). We then performed paired samples t-tests to investigate outcome change from baseline to the post-intervention timepoint, as well as linear regressions to examine whether digital alliance predicted subsequent engagement (adjusting for week 2 engagement) and postintervention co-morbid symptoms (adjusting for baseline co-morbid symptoms), in each study.
3. Results
In both studies, participants engaged regularly with the app: Study 1 participants completed, on average, roughly 99 activities (M = 98.94, SD = 71.94) across the intervention period, with a weekly average of approximately 16 (SD = 11.99). In Study 2, participants completed, on average, approximately 103 activities (SD = 46.56) across the intervention period, with a weekly average of approximately 13 (SD = 5.82). Paired samples t-tests revealed significant pre-post changes in outcomes in both studies. In Study 1, there was a significant decrease in co-morbid anxiety and depressive symptoms from baseline (M = 24.35, SD = 8.35) to the post-intervention time point (M = 20.14, SD = 9.76), t(139) = 4.20, p < .001, d = 0.53. In Study 2, there was also a significant decrease in co-morbid symptoms from baseline (M = 21.47, SD = 8.21) to postintervention (M = 14.12, SD = 8.19), t(104) = 8.79, p < .001, d = 0.86.
3.1. Digital alliance & engagement
Correlational analyses showed that digital alliance was significantly associated with several engagement metrics in both studies. In Study 1, digital alliance was associated with activities completed on the app, ρ =
0.22, p < .01, and there was a trend toward a significant association of digital alliance with percent of days active on the app, ρ = 0.15, p = .07. In the Digital Clinic, digital alliance was associated with app activities completed, ρ = 0.27, p < .01, and with percent of days active on the app, ρ = 0.29, p < .01. (See Table 1 & Table 2.) In addition, in Study 1, a linear regression indicated that week 2 digital alliance was a significant predictor of subsequent engagement (i. e., on weeks 3 to 6), b = 0.18, p < .01, adjusting for week 2 engagement, which was also significant, b = 0.62, p < .001. Similarly, in Study 2, a linear regression indicated that midpoint digital alliance was a significant predictor of subsequent engagement (i.e., on weeks 3 to 8), b = 0.21, p < .01, adjusting for week 2 engagement, which was also significant, b = 0.22, p < .05 (See Table 3.)
3.2. Digital alliance & outcomes
Correlational analyses showed that digital alliance was negatively associated with post-intervention timepoint co-morbid symptoms, ρ = 0.22, p < .01, in Study 1, but not in Study 2. Digital alliance was not associated with baseline co-morbid symptoms in either study and was strongly associated with therapeutic alliance, ρ = 0.67, p < .001, in Study 2. (See Table 1 and Table 2.) In Study 1, a linear regression showed that a higher DWAI predicted lower co-morbid symptoms at the post-intervention timepoint, b = 0.27, p < .001, adjusting for baseline co-morbid symptoms, which also remained significant, b = 0.64, p < .001. (See Table 3.) The same linear regression in Study 2 revealed no evidence of a direct effect of DWAI on outcomes (see Table 3).
4. Discussion
The goal of the present study was to improve our understanding of the role and function of digital alliance in guided digital interventions. Findings in the literature suggest that mobile apps offered with human coaching have higher effect sizes than those without human support (Lecomte et al., 2020). Thus, it was unsurprising that participants in both studies experienced significant pre-to-post symptom improvements, given that both interventions included some amount of human support. This study utilized mindLAMP, a mobile mental health application designed to deliver therapeutic interventions while simultaneously collecting digital biomarkers. The target population was individuals experiencing anxiety and depressive symptoms. Regarding the relation of digital alliance with engagement and with outcomes, there were several key findings. First, the data supported our first hypothesis (that digital alliance would be associated with engagement). In both studies, digital alliance was associated with app engagement metrics, consistent with findings from prior research showing a link between stronger digital alliance and greater app engagement (Goldberg et al., 2023). Importantly, early digital alliance predicted subsequent engagement in the intervention period, even after adjusting for early engagement. This effect emerged as early as week 2 in Study 1 (and near midpoint in Study 2), highlighting
Table 1
Study 1 correlations (N = 139).
M (SD) 1 2 3 4 5
1. %Active 57.13 (28.47) 2. WklyAct 16.49 (11.99) 0.80*** 3. DWAIwk2 21.75 (4.99) 0.15+ 0.22** 4. Comt1 24.35 (8.35) 0.04 0.07 0.10 5. Comt2 20.14 (9.76) 0.01 0.04 -0.22** 0.60*** 
Note. %Active = percent of total intervention days that a participant was active on the app; WklyAct = average weekly app activities completed; DWAI = digital alliance; wk2 = week 2; Com = co-morbid anxiety and depressive symptoms; t1 = baseline; t2 = post-intervention timepoint. Associations shown here are Spearman's rho correlations. ***p < .001 **p < .01 + p < .10.
N. Macrynikola et al. Journal of Aρective Disorders 383 (2025) 335–340
338


an opportunity to intervene with participants who have low early digital alliance to help sustain engagement and maximize intervention benefits over time. It is also notable that even in these two different implementations involving different populations and degrees of human support, digital alliance was associated with various engagement metrics. These results are in line with other findings demonstrating a link between digital alliance and engagement, suggesting the two may be related in important ways, even in guided interventions where therapeutic alliance with a human supporter likely also plays a role. Second, we also found support for our hypotheses on the impact of digital alliance on outcomes. As expected, in Study 1, where the app was offered to college students with minimal digital navigator support, digital alliance had a direct mitigating effect on post-intervention comorbid symptoms, and baseline co-morbid symptoms remained a significant predictor. This finding suggests that digital alliance may have its own unique protective effect on outcomes in digital interventions. Digital alliance may reflect the degree to which digital navigator support contextualizes the relevance of the app on the user's goals, for example, or the degree to which the app itself is clear and achieves the same purpose. These findings suggest that digital alliance is an important construct with potential relevance for improving both engagement and outcomes in minimally guided interventions delivered in real-world contexts. Third, as expected, in Study 2, there was no direct effect of digital alliance on post-intervention co-morbid symptoms. This is likely because the impact of digital alliance on outcomes in this guided intervention is indirect, operating through the intervention mechanism – emotion regulation self-efficacy – that the therapy and clinician were
concurrently targeting, as demonstrated in a recent study (Macrynikola et al., 2024a). Low self-efficacy in one's ability to tolerate and influence negative events, including one's own painful emotions, is believed to perpetuate emotional disorders (Barlow et al., 2021). Thus emotion regulation self-efficacy was a key clinical target in the emotion-focused CBT that was the basis of the Study 2 intervention. An important takeaway from these findings together is that even if the impact of digital alliance on outcomes in guided digital interventions is not direct, it still likely plays an important role in contributing to outcomes through other intermediary therapeutic factors. In fact, the impact of digital alliance on outcomes in guided digital interventions may depend on how well it encourages app use in a way that supports progress on the intervention mechanisms that the therapist is also working to shift with the patient. In summary, digital alliance is associated with engagement and differentially impacts outcomes in different types of guided digital interventions. The amount and type of human support is one characteristic that likely led to these differences. In Study 1, digital alliance was a proximal predictor of change; in the absence of regular human support, whether a participant improved was closely linked to digital alliance (i. e., how much one perceived the app as useful, enjoyable, and aligned with their goals). In contrast, in the virtual app-augmented therapy model where the app was one part of an entire digital intervention, there was no direct relationship between digital alliance and outcome change; even if a participant disliked the app, there was still a chance of improving based on other factors (e.g., in-session therapeutic work with the clinician). In addition, with weekly therapy sessions and digital navigator check-ins, there were likely many more opportunities for participants to see the relevance of the app toward their goals and receive guidance on using the app in ways that benefited their mental health. Thus, low digital alliance near the midpoint did not preclude eventual outcome change, and it influenced outcome change to the degree that it fostered app use that promoted the intervention mechanism targeted in therapy. Taken together, these findings suggest that prioritizing digital alliance may be crucial for achieving significant outcomes in minimally guided interventions, and that digital alliance remains important in more heavily guided interventions as it likely influences other key therapeutic processes that contribute to change.
4.1. Strengths & limitations
Strengths of the present research include use of data from two studies, the standardized intervention protocols used in these studies, and appropriate sample sizes for analyses. In terms of digital alliance, another primary strength is using a validated measure in both studies. The present research also has some limitations worth noting. First, both study samples skewed White. Future studies should broaden the pool of participants to mirror the demographics of the general population more closely. Second, we did not re-assess the internal consistency reliability for the DWAI scale in Study 1 but noted that it was high in Study 2 and prior studies. Additionally, both studies were pilot studies and thus lacked a control group. As a result, it may be premature to conclude that any outcome improvement was solely a result of using the digital intervention rather than other reasons. However, this should not
Table 2
Study 2 correlations (N = 105).
M (SD) 1 2 3 4 5 6
1. %Active 62.49 (19.83) 2. WklyAct 12.82 (5.82) 0.59*** 3. DWAImid 31.94 (7.43) 0.29** 0.27** 4. WAImid 49.32 (8.38) 0.28** 0.19+ 0.67*** 5. Comt1 21.47 (8.21) 0.02 0.02 0.19+ 0.10 6. Comt2 14.12 (8.19) 0.11 0.13 0.16 0.17+ 0.49*** 
Note. %Active = percent of total intervention days that a participant was active on the app; WklyAct = average weekly app activities completed; DWAI = digital alliance; WAI = therapeutic alliance; mid = midpoint; Com = co-morbid anxiety and depressive symptoms; t1 = baseline; t2 = post-intervention timepoint. Associations shown here are Spearman's rho correlations. ***p < .001 **p < .01 + p < .10.
Table 3
Linear regressions: digital alliance predicting subsequent engagement & outcomes in Study 1 (n = 139) & Study 2 (n = 100).
B SE beta 95 % CI p
LL UL
Study 1 (DV: Eng. on wks 3–6)
(Intercept) 14.08 12.96 39.71 11.55 0.28 Engwk2 2.22*** 0.23 0.62 1.76 2.68 <0.001 DWAIwk2 1.57** 0.57 0.18 0.44 2.70 0.007 Study 2 (DV: Eng. on wks 3–6)
(Intercept) 23.10 16.81 10.27 56.47 0.17 Engwk2 1.55* 0.67 0.22 0.21 2.88 0.02 DWAImid 1.08* 0.50 0.21 0.10 2.88 0.03 Study 1 (DV: Comt2)
(Intercept) 13.25*** 3.18 6.97 0.718 <0.001 Comt1 0.75*** 0.07 0.64 0.61 0.90 <0.001 DWAIwk2 0.53*** 0.12 0.27 0.77 0.28 <0.001 Study 2 (DV: Comt2)
(Intercept) 7.86 4.19 0.46 16.18 0.06 Comt1 0.45*** 0.09 0.44 0.27 0.63 <0.001 DWAImid -0.11 0.10 0.10 0.31 0.09 0.29
Note. DV = dependent variable; eng = engagement; wk. = week; DWAI = digital alliance; Com = co-morbid anxiety and depressive symptoms; t1 = baseline; t2 = post-intervention timepoint; wk2 = week 2; mid = midpoint. ***p < .001 **p < .01 *p < .05.
N. Macrynikola et al. Journal of Aρective Disorders 383 (2025) 335–340
339


affect findings related to DWAI and its link with engagement and outcomes. Future studies will make substantial contributions to the field if they examine the impact of DWAI on outcome change in digital interventions with established evidence of efficacy to understand how DWAI may influence outcomes.
5. Conclusion
As research on and implementation of digital interventions continues to grow, it is becoming clear that these interventions tend to be efficacious – yet their efficacy is tempered in the real world by low sustained user engagement. As such, an important step forward is to identify and better understand digitally relevant processes that may aid engagement and improve outcomes. Digital alliance is one such process, and the present research suggests that it is linked with engagement and influences outcomes, albeit via different means in digital interventions with different levels of human support.
CRediT authorship contribution statement
Natalia Macrynikola: Writing – review & editing, Writing – original draft, Visualization, Validation, Supervision, Project administration, Methodology, Investigation, Formal analysis, Conceptualization. Sarah Chang: Writing – review & editing, Writing – original draft, Project administration, Formal analysis, Conceptualization. John Torous: Writing – review & editing, Supervision, Methodology, Investigation, Conceptualization.
Funding
Study 1 work was supported by the Argosy Foundation.
Declaration of competing interest
None.
Acknowledgments
None.
References
Barlow, D.H., Curreri, A.J., Woodard, L.S., 2021. Neuroticism and disorders of emotion: a new synthesis. Curr. Dir. Psychol. Sci. 30 (5), 410–417. https://doi.org/10.1177/ 09637214211030253. Baumel, A., Muench, F., Edan, S., Kane, J.M., 2019. Objective user engagement with mental health apps: systematic search and panel-based usage analysis. J. Med. Internet Res. 21 (9). https://doi.org/10.2196/14567. Article 9. Benitez, B., Frankforter, T.L., Nich, C., Kiluk, B.D., 2023. The connection still matters: therapeutic alliance with digital treatment for alcohol use disorder. Alcohol. Clin. Exp. Res. 47 (11). https://doi.org/10.1111/acer.15199. Article 11. Bilden, R., Torous, J., 2022. Global collaboration around digital mental health: the LAMP consortium. Journal of Technology in Behavioral Science 7 (2). https://doi.org/ 10.1007/s41347-022-00240-y. Article 2. Camacho, E., Chang, S.M., Currey, D., Torous, J., 2023. The impact of guided versus supportive coaching on mental health app engagement and clinical outcomes. Health Informatics J. 29 (4). https://doi.org/10.1177/14604582231215872. Article 4. Chang, S., Alon, N., Torous, J., 2023a. An exploratory analysis of the effect size of the mobile mental health application, mindLAMP. DIGITAL HEALTH 9. https://doi.org/ 10.1177/20552076231187244. Chang, S., Gray, L., Torous, J., 2023b. Smartphone app engagement and clinical outcomes in a hybrid clinic. Psychiatry Res. 319, 115015. https://doi.org/10.1016/j. psychres.2022.115015. Currey, D., Torous, J., 2023. Digital phenotyping data to predict symptom improvement and mental health app personalization in college students: prospective validation of
a predictive model. J. Med. Internet Res. 25, e39258. https://doi.org/10.2196/ 39258. Goldberg, S.B., Baldwin, S.A., Riordan, K.M., Torous, J., Dahl, C.J., Davidson, R.J., Hirshberg, M.J., 2022a. Alliance with an unguided smartphone app: validation of the digital working alliance inventory. Assessment 29 (6). https://doi.org/10.1177/ 10731911211015310. Article 6. Goldberg, S.B., Lam, S.U., Simonsson, O., Torous, J., Sun, S., 2022b. Mobile phone-based interventions for mental health: a systematic meta-review of 14 meta-analyses of randomized controlled trials. PLOS Digital Health 1 (1). https://doi.org/10.1371/ journal.pdig.0000002. Article 1. Goldberg, S.B., Jiwani, Z., Bolt, D.M., Riordan, K.M., Davidson, R.J., Hirshberg, M.J., 2023. Evidence for bidirectional, cross-lagged associations between alliance and psychological distress in an unguided mobile-health intervention. Clin. Psychol. Sci. 21677026231184890. https://doi.org/10.1177/21677026231184890. Hatcher, R.L., Gillaspy, J.A., 2006. Development and validation of a revised short version of the working alliance inventory. Psychother. Res. 16 (1). https://doi.org/10.1080/ 10503300500352500. Article 1. Henson, P., Wisniewski, H., Hollis, C., Keshavan, M., Torous, J., 2019. Digital mental health apps and the therapeutic alliance: initial review. BJPsych Open 5 (1). https:// doi.org/10.1192/bjo.2018.86. Article 1. Herrero, R., Vara, M.D., Miragall, M., Botella, C., García-Palacios, A., Riper, H., Kleiboer, A., Ba ̃nos, R.M., 2020. Working Alliance Inventory for Online Interventions-Short Form (WAI-TECH-SF): the role of the therapeutic alliance between patient and online program in therapeutic outcomes. Int. J. Environ. Res. Public Health 17 (17). https://doi.org/10.3390/ijerph17176169. Article 17. Horvath, A.O., Greenberg, L.S., 1989. Development and validation of the Working Alliance Inventory. J. Couns. Psychol. 36 (2). https://doi.org/10.1037/00220167.36.2.223. Article 2. Kroenke, K., Spitzer, R.L., Williams, J.B.W., 2001. The PHQ-9: validity of a brief depression severity measure. J. Gen. Intern. Med. 16 (9). https://doi.org/10.1046/ j.1525-1497.2001.016009606.x. Article 9. Kroenke, K., Spitzer, R.L., Williams, J.B.W., Lo ̈we, B., 2010. The patient health questionnaire somatic, anxiety, and depressive symptom scales: a systematic review. Gen. Hosp. Psychiatry 32 (4). https://doi.org/10.1016/j. genhosppsych.2010.03.006. Article 4. Kroenke, K., Wu, J., Yu, Z., Bair, M.J., Kean, J., Stump, T., Monahan, P.O., 2016. Patient health questionnaire anxiety and depression scale: initial validation in three clinical trials. Psychosom. Med. 78 (6). https://doi.org/10.1097/PSY.0000000000000322. Article 6. Lecomte, T., Potvin, S., Corbie`re, M., Guay, S., Samson, C., Cloutier, B., Francoeur, A., Pennou, A., Khazaal, Y., 2020. Mobile apps for mental health issues: meta-review of meta-analyses. JMIR mHealth and uHealth 8 (5). https://doi.org/10.2196/17458. Article 5. Linardon, J., Cuijpers, P., Carlbring, P., Messer, M., Fuller-Tyszkiewicz, M., 2019. The efficacy of app-supported smartphone interventions for mental health problems: a meta-analysis of randomized controlled trials. World Psychiatry 18 (3), 325–336. https://doi.org/10.1002/wps.20673. Linardon, J., Shatte, A., Messer, M., Firth, J., Fuller-Tyszkiewicz, M., 2020. E-mental health interventions for the treatment and prevention of eating disorders: an updated systematic review and meta-analysis. J. Consult. Clin. Psychol. 88 (11). https://doi. org/10.1037/ccp0000575. Article 11. Macrynikola, N., Nguyen, N., Lane, E., Yen, S., Torous, J., 2023. The digital clinic: an innovative mental health care delivery model utilizing hybrid synchronous and asynchronous treatment. NEJM Catalyst 4 (9). https://doi.org/10.1056/ CAT.23.0100. Article 9. Macrynikola, N., Chang, S., Torous, J., 2024a. Emotion regulation self-efficacy as a mechanism of alliance and outcomes in a brief, transdiagnostic digital mental health intervention: L’auto-efficacit ́e de la r ́egulation des  ́emotions en tant que me ́canisme d’alliance et de r ́esultats dans une bre`ve intervention transdiagnostique nume ́rique en sante ́ mentale. Can. J. Psychiatr. 7067437241274201. https://doi.org/10.1177/ 07067437241274201. Macrynikola, N., Chen, K., Lane, E., Nguyen, N., Pinto, J., Yen, S., Torous, J., 2025. Testing the Feasibility, Acceptability, and Potential Efficacy of an Innovative Digital Mental Health Care Delivery Model Designed to Increase Access to Care: Open Trial of the Digital Clinic. JMIR Ment Health 12, e65222. https://doi.org/10.2196/65222. Spitzer, R.L., Kroenke, K., Williams, J.B.W., L ̈owe, B., 2006. A brief measure for assessing generalized anxiety disorder: the GAD-7. Arch. Intern. Med. 166 (10). https://doi. org/10.1001/archinte.166.10.1092. Article 10. Vaidyam, A., Halamka, J., Torous, J., 2022. Enabling research and clinical use of patientgenerated health data (the mindLAMP platform): digital phenotyping study. JMIR Mhealth Uhealth 10 (1). https://doi.org/10.2196/30557. Article 1. Wisniewski, H., Gorrindo, T., Rauseo-Ricupero, N., Hilty, D., Torous, J., 2020. The role of digital navigators in promoting clinical care and technology integration into practice. Digital Biomarkers 4 (Suppl. 1). https://doi.org/10.1159/000510144. Article Suppl. 1.
N. Macrynikola et al. Journal of Aρective Disorders 383 (2025) 335–340
340