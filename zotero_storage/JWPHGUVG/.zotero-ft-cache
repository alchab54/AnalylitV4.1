RESEARCH ARTICLE
Conceptualizing the digital therapeutic alliance in the context
of fully automated mental health apps: A thematic analysis
Fangziyun Tong 1,2 | Reeva Lederman 1 | Simon D'Alfonso 1 |
Katherine Berry 2,3 | Sandra Bucci 2,3
1School of Computing and Information Systems, University of Melbourne, Parkville, Victoria, USA
2Division of Psychology and Mental Health, School of Health Sciences, Manchester Academic Health Sciences Centre, University of Manchester, Manchester, UK
3Complex Trauma and Resilience Research Unit, Greater Manchester Mental Health NHS Foundation Trust, Manchester, UK
Correspondence
Fangziyun Tong, School of Computing and Information Systems, University of Melbourne, Melbourne Connect, Carlton, Victoria, Australia. Email: fangziyunt@student.unimelb.edu.au
Funding information
University of Melbourne; University of Manchester
Abstract
Fully automated mental health apps provide a promising opportunity for increasing
access to mental health care and resources. Given this opportunity, continued
research into the utility and effectiveness of mental health apps is crucial. Therapeu
tic alliance (TA) refers to the relationship between a client and a healthcare profes
sional, and has been shown to be an important predictor of clinical outcomes in face
to-face therapy. Given the significance of TA in traditional therapy, it is important to
explore whether the notion of a digital therapeutic alliance (DTA) in the context of
fully automated mental health apps also plays an important role in clinical outcomes.
Current evidence shows that the conceptualization of DTA in the context of fully
automated mental health apps can be potentially different to TA in face-to-face ther
apy. Thus, a new DTA conceptual model is necessary for comprehensively under
standing the mechanisms underpinning DTA for fully automated mental health apps.
To the best of our knowledge, this is the first study that qualitatively explored the
dimensions of a DTA in the context of fully automated mental health apps. We con
ducted interviews with 20 users of mental health apps to explore the key dimensions
comprising DTA in the context of fully automated mental health apps. We found that
although conceptualizations of DTA and TA have shared dimensions, flexibility and
emotional experiences are unique domains in DTA. On the other hand, although
agreement on goals between a therapist and a client is important in face to face ther
apy, we found that users can have an alliance with an app without a goal. The impor
tance of goal needs further investigations.
KEYWORDS
digital mental health, digital therapeutic alliance, human–computer interaction, mhealth, smartphone apps, therapeutic alliance
Received: 2 November 2022 Revised: 24 March 2023 Accepted: 27 March 2023
DOI: 10.1002/cpp.2851
This is an open access article under the terms of the Creative Commons Attribution-NonCommercial-NoDerivs License, which permits use and distribution in any medium, provided the original work is properly cited, the use is non-commercial and no modifications or adaptations are made. © 2023 The Authors. Clinical Psychology & Psychotherapy published by John Wiley & Sons Ltd.
998 wileyonlinelibrary.com/journal/cpp Clin Psychol Psychother. 2023;30:998–1012.


1 | BACKGROUND
Digital mental health interventions are viable solutions for increasing
access to mental health support (Australian Government, 2012;
United Nations, 2020). Mental health apps are one of the most com
monly used digital tools to deliver digitally-based mental health inter
ventions due to their availability, scalability, relative low price, and
potential efficacy (Bucci et al., 2018; Clarke et al., 2016; Ebert
et al., 2018; Firth et al., 2017; Torous et al., 2020). In particular, fully
automated mental health apps (apps without human support) can
potentially support healthcare professionals' workloads (Richards
et al., 2018). However, although some researchers suggested that
smartphone apps are efficient in managing mental health problems
(Ebert et al., 2018; Firth et al., 2017), other researchers pointed out
that the effect sizes are relatively moderate and there is no convincing
evidence of the efficacy of mental health apps related to the clinical
outcomes (Denecke et al., 2022; Goldberg et al., 2022). Consequently,
understanding how fully automated mental health apps can be
designed to bring better clinical outcomes is critical to improving ser
vice delivery, clinical workflows and patient care.
Therapeutic alliance (TA) refers typically to the relationship
between a client and a healthcare professional and has been shown to
be an important predictor of outcome in psychological therapy. There
are various scales to measure the TA, such as California Psychother
apy Alliance Scale (CALPAS; Marmar et al., 1986), Helping Alliance
Questionnaire (HAQ; Alexander & Luborsky, 1986) and Vanderbilt
Psychotherapy Process Scale (VPPS; Suh et al., 1986). The Working
Alliance Inventory (WAI; Horvath & Greenberg, 1989) is one of the
most well-known scales to measure TA. The WAI was developed
based on the conceptual model of TA proposed by Bordin (1979) and
comprises three subscales: bonds between healthcare professionals
and clients, agreement on therapy goals and agreement tasks that
need to be undertaken to achieve goals. The Agnew Relationship
Measure (ARM; Agnew-Davies et al., 1998) is another important scale
as it is commonly used in the digital context. The ARM comprises five
subscales: bond, partnership, confidence in therapy, client initiative and
openness (Agnew-Davies et al., 1998). Previous research has shown
that TA has moderate but reliable correlations with clinical outcomes
regardless of types of mental health problems and treatment
approaches in both young people and adults (Flückiger et al., 2018;
Karver et al., 2018; Mander et al., 2017).
According to Bordin (1979, p. 252), a TA ‘between a person seek
ing change and a change agent can occur in many places besides the
locale of psychotherapy’. If we are to interpret this statement in a suf
ficiently general way, it would imply that a digital therapeutic alliance
(DTA) may exist between users, who seek changes, and a mental
health app, which plays the role of a change agent. DTA in the context
of fully automated mental health apps is nascent and under
researched. Only a handful of studies have examined the DTA with
fully automated mental health apps using quantitative methods, and
most studies have used alliance measures such as the WAI (Darcy
et al., 2021; Prochaska et al., 2021) and the ARM (Clarke et al., 2016),
both developed for use with a human therapist, with minimal
adaptations. Two measures, the Mobile Agnew Relationship Measure
(mARM; Berry et al., 2018) and the Digital Working Alliance Inventory
(DWAI; Goldberg et al., 2021) have been specifically proposed to
measure the DTA in the context of fully automated mental health
apps. Both measurements were created by modifying face-to-face
scales, the ARM and WAI respectively. The mARM was developed by
changing the word ‘therapist’ to ‘app’, as well as adding, deleting and
changing the wording of items based on feedback provided by both
users and healthcare professionals. The DWAI was created by choos
ing two items from each subscale of the WAI, and then replacing the
word ‘therapist’ with ‘app’.
The mARM and DWAI assume that the conceptualization of DTA
in the context of fully automated mental health apps is similar to TA
in face-to-face therapy. However, there may be important differences
between alliance in these different contexts. For example, bond is an
important subscale of both the ARM and WAI and is considered cru
cial in face-to-face therapy, but whether a person can build a bond
with an app is still unclear (Darcy et al., 2021; Tong et al., 2022). In
addition, Clarke et al. (2016) suggest that flexibility in an app (in terms
of location, time, and duration), although not part of any existing DTA
scales, can potentially be important factors that influence the DTA in
the context of fully automated mental health apps.
In addition, only a handful of studies have examined the relation
ships between DTA and clinical outcomes in the context of fully auto
mated mental health apps, and their findings were mixed (Tong
et al., 2022). For example, Clarke et al. (2016) argued that there was
no significant correlation between ARM rating and clinical outcomes,
while Goldberg et al. (2021) reported that week 3 and week 4 DWAI
scores related to reductions in psychological distress. These mixed
findings were inconsistent with findings in face-to-face therapy, which
have found more consistent associations between TA and clinical out
comes. Tong et al. (2022) pointed out one possible explanation for
less consistent associations in the DTA literature is that the existing
DTA scales are not comprehensive enough for measuring DTA in the
context of fully automated mental health apps.
Given the association between traditional TA and positive ther
apy outcomes, it is important to explore further the concept of DTA,
and whether a digital analogue of the TA exists for mental health
apps. However, current evidence showed that (1) existing DTA scales
are not comprehensive enough for measuring DTA in the context of
Key Practitioner Message
• It is possible for users to build relationships with a fully
automated mental health app.
• Flexibility and emotional experiences are unique dimen
sions in digital therapeutic alliance.
• Interactive elements in apps might be important to pro
vide emotional support for users.
• Goal setting functions, such as a rewarding system, might
be important in an app to help users find a concrete goal.
TONG ET AL. 999
10990879, 2023, 5, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/cpp.2851 by Cochrane France, Wiley Online Library on [15/07/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License


fully automated mental health apps and (2) the conceptual model of
DTA may differ from the conceptualization of TA. Therefore, re
conceptualizing DTA is necessary to fully understand the DTA in fully
automated apps, and its relationship with clinical outcomes. Thus, the
objectives of this study are to (1) explore people's perceptions of the
DTA in the context of fully automated mental health apps and (2) iden
tify the key dimensions comprising DTA in the context of fully auto
mated mental health apps.
2 | METHODS
2.1 | Participants
Interviews were conducted with 20 participants who self-reported
using fully automated mental health apps. The inclusion criteria of par
ticipants were (1) aged 18 or over; (2) English speaking; (3) agreed to
the interview being audio-recorded (for transcription purposes); and
(4) currently using or had ever used at least one fully automated men
tal health app.
The inclusion criteria of fully automated mental health apps were
(1) could be used on smartphones; (2) mainly targeted helping with
mental health and wellbeing; (3) could be used without human
support.
Although all participants demonstrated English writing ability
before their interviews, it became apparent during the course of one
interview that one participant was not a proficient English speaker.
Therefore, we excluded this participant's data, leaving 19 interviews
available for analysis. Demographic information, provided by partici
pants in the pre-screen survey before the interview, is presented in
Table 1.
Nine participants had experiences with human therapists, and the
other 10 people never saw therapists.
Participants used various types of apps, including meditation
apps, chatbots, mood tracking apps, psychoeducation apps and apps
with gamified tasks. The detailed app information is presented in
Table 2. All apps in the table were used by at least one participant.
In addition, some participants also mentioned some non-mental
health focused apps, such as Forest and life sum. When analysing
data, we excluded data related to these apps.
2.2 | Procedure
Ethical approval was obtained from the Office of Research Ethics and
Integrity, the University of Melbourne (Ethics number 2057887.1).
The recruitment process involved posting advertisements for the
study on the research recruitment page of the University website, Lin
kedIn, Twitter, and Reddit. To assess eligibility, people who expressed
an interest in participating in this study were asked to complete an
online pre-screen form. Author FT contacted those who met the
inclusion criteria via email and sent them a consent form and a plain
language statement explaining the purpose of interview, and the data
and risk management strategies. Interviews were scheduled and con
ducted after receiving the signed consent form from participants.
Based on a literature review of previous TA and DTA studies, a
semi-structured interview guide (Appendix A) was developed to
explore users' experiences, interactions, and relationships with fully
automated mental health apps. The topic guide included three sec
tions. The first section explored basic information, such as the names
of the app/s participants have used, frequency of use, and the fea
tures and functions of the app/s. We also asked participants if they
had a goal when they started using the app/s, and whether the tasks
helped them to achieve their goals since some previous studies sug
gested that goal and task are also necessary for building DTA (Gomez
Penedo et al., 2020; Scherer et al., 2016). Section 2 of the topic guide
invited participants to recall the use and experience of the app/s in
detail. This section explored how helpful/unhelpful features and func
tions in the app/s were. Section 3 explored whether participants
experienced any relational qualities with the app/s. Specifically, to
help participants understand what is a relationship with an app, we
first asked participants to think about their relationship with a thera
pist or to imagine this if they had never had a therapist (10/19 partici
pants had never attended an in-person therapy or meditation session).
We then asked participants whether they felt that they had a similar
connection/relationship with the app/s. Finally, some questions in
Section 3 were modified from Bachelor's (1995) qualitative study on
TA (e.g., What is, according to you, a good client-therapist relationship?).
Interviews lasted between 26 to 61 min. Due to COVID-19 lock
down restrictions, all interviews were conducted via Zoom. Author FT
conducted all interviews. Participants received an AUD 30 gift card
upon completion of the interview.
T A B L E 1 Demographic information.
Demographics Numbers
n%
Gender
Female 10 52.6
Male 8 42.1
Non-binary 1 5.3
Age range
18–24 11 57.9
25–34 7 36.8
35–44 1 5.3
Occupation
Student 15 78.9
IT support officer 1 5.3
Software engineer 1 5.3
Social worker 1 5.3
Lecturer 1 5.3
1000 TONG ET AL.
10990879, 2023, 5, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/cpp.2851 by Cochrane France, Wiley Online Library on [15/07/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License


2.3 | Data analysis
NVivo 12 (Edhlund & McDougall, 2019) was used to support data
coding and analysis. All authors were involved in the data analysis pro
cess. A thematic analysis approach was used following the guidelines
of Braun and Clarke (2006, 2019) and Clarke and Braun (2013); both
inductive and deductive methods were used to identify themes. All
transcripts were initially coded by author FT. A small number of tran
scripts (n = 4) were independently coded by authors KB and SB (aca
demic clinical psychologists) as a means of facilitating discussion
about potential themes and to aid the reflexive process: this is consis
tent with a reflexive thematic analysis approach which stipulates that
dual-coding of select transcripts can be useful for ideas generation
(Clarke & Braun, 2013). Authors discussed and refined the organiza
tion of codes until a stable thematic structure was developed. All
authors contributed to developing the thematic structure to ensure:
(1) all themes were relevant to the research question; (2) meaning of
the codes in each theme were consistent; (3) all themes were distin
guishable; (4) names of the themes were appropriate and
understandable.
T A B L E 2 App information.
App name Type Main functions
Headspace A meditation and mindfulness app for stress, anxiety, mood disorders and sleep problems.
Meditations, visual meditations, tracking, reminders, inviting friends.
Calm A meditation and mindfulness app for stress, anxiety, mood disorders and sleep problems.
Meditations, music, sleep stories, customization programme, tracking, reminders.
Smiling Mind A meditation and mindfulness app for stress, anxiety, mood disorders and sleep problems.
Survey and customization, meditations
Waking up A meditation and mindfulness app for stress, anxiety and sleep problems.
Meditations, psychoeducation resources, reminder.
Insight timer A meditation and mindfulness app for stress, anxiety, and sleep problems.
Meditations, customization, tracking, connecting with friends, online courses and events, one-to-one mentoring for a fee.
What's up A Cognitive Behavioral Therapy (CBT) based app for mood disorders.
Psychoeducation, breathing and grounding exercises, diary/journaling, forum, tracking, quotes and articles.
Happify A multi-function app for PTSD, chronic pain, mood disorders, sleep problems, stress and anxiety.
Survey for providing customized programme, gamified tasks, AI-Coach, forum.
Moodfit A CBT based app for anxiety and stress, mood disorders and sleep.
Medications, journaling, goal-setting, survey, tracking, reminders.
myCompass A web and smartphone based for depression, stress and anxiety and sleep problems.
Psychoeducation activities, tracking, customized programme.
Mindshift A CBT-based app for anxiety in young adults. Quotes, meditations, tracking, mental health tips and information, customized coping plan.
Mentemia (changed the name to groov)
A workplace mental health and wellbeing app. Articles, psychoeducation courses, tracking, daily goal activities, meditations.
MoodPrism A mood tracking app. Tracking and feedback, notifications.
Woebot An AI-powered and CBT-based chatbot for mood disorders, anxiety and stress.
Chatbot, mental health tips, psychoeducation resources, tracking.
Wysa An AI-based chatbot for mood disorders, anxiety and stress and sleep problems.
Chatbot, self-care activities, breathing and meditation exercises, connecting to therapists for additional fee.
Replika An AI-based embodied chatbot for mood disorders, anxiety and stress.
Chatbot, tracking and monitoring, psychoeducation resources, goalsetting.
Habitica A behaviour change app for ADHD. Tracking, gamified activities, goal setting function (earning point to level-up the avatar by achieving goals), social group and online forum.
Intellect A CBT-informed app for stress and anxiety, emotion regulation and sleep problems.
Psychoeducation tasks and resources, tracking, journaling, customized plans, connecting to therapists.
eMoods A mood tracking app for bipolar. Tracking and recording.
Gratitude A mental health and wellbeing journaling app. Motivational content, journaling, music and voice, psychoeducation tips, visual board, life goal setting.
Curable A mental health wellbeing app for chronic pain. AI-based virtual coach, psychoeducation audios, customized plans, articles, breathing exercises and meditations, tracking.
TONG ET AL. 1001
10990879, 2023, 5, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/cpp.2851 by Cochrane France, Wiley Online Library on [15/07/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License


2.4 | Reflexivity
A phenomenological methodological approach to thematic analysis
was used, and the research was underpinned by a critical realist epis
temological position (Fletcher, 2017). This stance assumes that data
cannot directly represent the reality, but rather, data need to be inter
preted by researchers to reveal the underlying pattern and structure,
and the interpretation is also affected by the researchers' own knowl
edge (Willig, 2012). The author FT, who administered and led all inter
views, conducted this research as part of her PhD, and had 1 year of
research experience on the topic of DTA. KB and SB are academic
clinical psychologists with extensive experience both clinically and
theoretically in the TA. RL is an academic researcher in digital health
information systems. SD is a computing and information technology
researcher in digital mental health. All authors (KB, SB, RL, SD) had
extensive research experience in digital mental health and have previ
ously carried out early work on DTA (Berry et al., 2018; D'Alfonso
et al., 2020). It is critical to acknowledge that these experiences and
context may influence the interview and data analysis. For example,
research experiences in DTA led the authors to hold the idea that
users can build relationships with fully automated mental health apps.
Similarly, authors' knowledge about previous research in TA and DTA
also influenced data interpretation. A reflective diary was kept after
each interview and during the coding of interviews to document
reflections about the process of the interview and analysis, including
any reflections made about the potential influence of research bias/
experience on the data. The authors met regularly to discuss the
themes which emerged from the data and how information documen
ted in the reflective diary may have affected the data interpretation.
3 | RESULTS
After the seventeenth interview, information from subsequent inter
views did not add anything further to the research questions. Thus,
saturation was deemed to be achieved (three more interviews were
conducted to ensure that no new information was emerged). The fol
lowing five themes were identified: (1) valuing flexibility; (2) the role
of accountability; (3) the importance of emotional experiences for
connections; (4) enhanced openness; and (5) lack of agreement upon
goals. These themes and their relationships are represented in a the
matic map (Figure 1), which will be further discussed in Section 4.
Themes one to four are key components of building DTA.
3.1 | Valuing flexibility
Many participants described their relationships with apps as
convenient. Apps could help users to build this type of convenient
relationship in two ways. First, apps were available 24/7 and could be
easily accessed whenever and wherever they were needed and could
be easily fitted into a busy schedule. Participants felt these
flexible characteristics were important for them to build a relationship
with an app.
F I G U R E 1 Thematic map.
1002 TONG ET AL.
10990879, 2023, 5, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/cpp.2851 by Cochrane France, Wiley Online Library on [15/07/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License


...so it's always available. That mental health apps are
always available, so that is the relationship. Whenever I
need it, it's there, so I don't need to schedule an
appointment or anything with it. That's the relationship...
[Participant A1]
These flexible characteristics in apps allowed users to get immedi
ate solutions regardless of time and location, and thus, provided users
with a feeling of security. Participants viewed apps as assistants who
were always available for helping when there was nobody else for
them.
To me, over the time it's been, it's like a little security
blanket. So having a tool, having something like a support.
It sounds strange, but a plan B. So, if you can't access
that immediate psychology support, you've got something
else you can use. Convenient, reliable. It's always there.
It's also 24/7, you pretty much have access to these tools.
Unlike a psychologist, where it can take a long time to get
in to see someone, even if you are a client. And yeah, I
guess there's some more control that you might have over
an app in how you use it. [Participant H2]
On the other hand, although technically most apps were available
24/7, depending on the app design, not all apps could give immediate
solutions and provide the feeling of security.
Cause it (the app) doesn't tell you how... What exact solu
tions or things you can do to help improve your own men
tal health. So you're just putting your own mood in
everyday, but it doesn't help you to improve your mood.
[Participant J2]
Second, apps gave users the freedom to browse different content
and functions, and then allow users to choose the functions/activities
they felt helped the most. Thus, different people may use the same
app in different ways.
Like I'm using it for reading articles, someone else might
use it for meditation or for calmness or for maybe playing
the games, for some people, they may like the games only,
some people might just scroll in and see what the commu
nity is posting, just some random stuff. [Participant R1]
The flexibility in choosing functions/content provided users the
opportunities to get the support that they were seeking whenever
they needed, and can further enhance the relationship and the per
ception of convenience. For example, a meditation app can provide
users with different functions, and allow users to choose the most
helpful one based on their mood and situation.
(The helpful function) is a graphic (meditation function)
and it's around breathing and it's got a visual
representation that you can breathe in and then you
breathe out and you follow a visual graphic. And I really
like that. And I know my step son, who's eight, likes that
too. So sometimes it is nice, particularly if you're really
overwhelmed and you might not be able to go into that
meditation space, you've got a visual, you can just be like,
“Oh, okay. Let's take a few breaths and follow the
graphic.” So I did like that and that's not in the Insight
Timer. [Participant H2]
3.2 | The role of self-initiative and accountability
Clients and users needed to be self-motivated and have the willing
ness to start and maintain the connection with an app. Building rela
tionships with fully automated mental health apps required a high
level of self-initiative by users in the form of reading a lot of text, and
using the app functions. Moreover, when people experienced distress
or mental health problems, they tended to avoid using technology and
found it difficult to work through the app content (e.g. reading long
articles and instructions).
If you come to a stage where you're just at your deepest
low, you wouldn't even be motivated to click on
certain function that would be actually very useful for
you. [Participant R2]
In addition, since many fully automated mental health apps were
relatively unrestricted in terms of availability (mentioned in Theme 1)
and did not project expectations, users felt that there was no obliga
tion to continue using the apps (or to engage with a certain time win
dow), particularly when the apps lacked functions to provide
accountability. Thus, users might lose motivation in using/engaging
with fully automated mental health apps quickly and not stay con
nected with an app if they did not have enough self-determination
and self-accountability.
Unless say they have a therapy session booked weekly
and they'd have to go, then that's been helping them and
the digital apps, they don't have the will to actually click
ing and use. [Participant C1]
On the other hand, although users could lose interests in apps
quickly without enough self-determination, certain app functions,
such as notifications, tracking functions, rewarding system (getting
points by completing tasks) and social groups (an online space in an
app that allow users to communicate with each other) were reported
to encourage users take the initiative to engage with the app.
Let's say you're not a really social media type of person,
but if you have seven other people in that group who are
just chatting, providing advice, talking about their experi
ence, providing a source of accountability, you're more
TONG ET AL. 1003
10990879, 2023, 5, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/cpp.2851 by Cochrane France, Wiley Online Library on [15/07/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License


likely to also do that, because you're the only person in
the group who doesn't talk. [Participant A2]
However, it is worth noting that, although participants generally
felt that while app functions, such as notification and tracking, could
remind users to take their responsibility (for managing mental health
problems), the experience was still not comparable to the sense of
accountability (being accountable to another person) experienced
within the context of face-to-face therapy.
And the tracking is what would take place as a daily log,
when you log in your experience with that. It does force
you to be somewhat accountable, but it's not like there's
another person. [Participant A2]
3.3 | The importance of emotional experiences for building connections
Although meeting others' expectations can provide better account
ability than some app functions (mentioned in Theme 2), some partici
pants felt it could give them pressure (particularly when they have
anxiety). It could also induce participants' guilt of being a burden to
other people. On the other hand, participants thought apps were
more considerate since they would not bring this kind of pressure and
guilt.
Obviously, it's not a real human. But I think it can help
you. It's not rude. The app is very helpful. You can do it at
your own pace, it's very considerate... It's very helpful.
The language isn't rude or pressuring you to use the app...
It's just with real-life meditation movement, sometimes
it's a bit rude. Like, Oh, you should do meditation, it's so
good for your health ... I've never articulated this, but the
movements can be very pressuring. Do this for your
mental health. If you don't do this, you're not focusing...
[Participant J1]
The feeling of being cared for and understood could also help
users emotionally connect with apps. Many participants indicated that
apps could be friendly and provide emotional support, even though
they were aware that apps were not human. They used various words,
such as caring, understanding, listening, friendly, warmth, comforting,
thoughtful, compassionate, considerate and patient, to describe this
kind of emotional connection.
(The app) like a virtual friend. The way it was talking, just
gentle, friendly, care and show he's actually care about
you. [Participant A4]
People behind the apps, such as designers and developers, played
an important role in helping users build connections with the apps.
Several participants specifically referred to people who designed and
developed apps. They said that people behind apps showed their
empathy and care through the design and content in the app. As a
result, the feeling of being cared for and understood by an app (and
developers) facilitated a sense of connection with the app.
Both (an app name) and (an app name) are made by men
tal health professionals. You can really feel that it's (the
app) very scientific, but caring and they (mental health
professionals) know what they're doing. [Participant J1]
However, not all participants thought apps could provide enough
emotional support and they could not build a connection with the app
due to a lack of emotional factors. This kind of connection could be
harmed by a lack of perceived genuineness within the apps. For exam
ple, some participants said that apps which appeared to only want to
make money through regular push notifications to subscribe to ser
vices gave a sense that the developers/apps did not care about the
users' emotional well-being. In particular, when users could not per
sonally relate to the app content, they tend to feel easily annoyed by
advertisements.
Not (having a relationship) with [app name] because [app
name] makes me feel like they just want to earn money
from you because a lot of the features are not free and
they would promote the paid features. I get annoyed at
that and I just think that it's just a tool that I can't use.
[Participant C1]
A lack of interactivity was another reason that users failed to per
ceive emotional supports and develop a connection with a fully auto
mated mental health app. To connect with apps, participants said they
needed to have two-way communication, immediate responses, or
continuous conversations. They further argued that app features, such
as chatbots, video and voice responses, and customization would
increase interactivity, allow them to share their emotions (in-depth
feelings), and then further build relationships with apps.
The only reason why I say it's not relationship is only
because I don't think it's a two-way interaction. So it's
more like a consumption of something. I consume it rather
than it being both ways ... ... I feel like a lot of people,
when they're comparing apps and actual therapists and
stuff, it's that factor of reciprocating, there's a conversa
tion between two entities, two people or whatever. So if
there was a customized version for the apps where I can
go more in-depth with my feelings and then have advice
that's catered to my personal context, then yeah, I would
definitely go for the apps. [Participant J2]
Scepticism and fear of technology, including distrust of algorithms
and fear of phone addiction was also one of the reasons that users
were afraid of building a connection with an app. In particular, partici
pants with a technology background and understanding of algorithms
1004 TONG ET AL.
10990879, 2023, 5, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/cpp.2851 by Cochrane France, Wiley Online Library on [15/07/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License


showed less trust in apps and did not believe that an app can under
stand personal problems.
So it's like the chatbot is trained on pre-fed data and they
actually get a key keyword from the user and use the
solution that's being taught to that bot. So, if I have the
same keyword on two different scenarios, it will give the
same answer. [Participant N1]
Some other participants feared that using mental health apps has
the potential to lead to phone addiction, which could prevent them
from developing relationships or engaging in social activities with
others. The fear of phone addiction also stopped users from engaging
and connecting with apps.
I think it's a type of relationship, but I do think at the end
of the day, an app is still an app. And if you're becoming
addicted to an app or if you're becoming addicted to your
phone, then balance is important and you still need to see
people. You still need to interact with people. You still
need to socialize and even seeing a therapist is good in
that way, because at least you're talking to a real human,
for now. I don't think you should spend all your time on
mental health apps... [Participant H1]
3.4 | Enhanced openness
Apps were perceived as being able to hold a non-judgmental stance
seeing as they are inanimate objects. Participants said that openness,
which was permitted by the non-judgmental nature of apps, helped
users to build a relationship with an app.
So one of the benefits of using this app in terms of rela
tionship with the end indicated, maybe ... So you get a lit
tle confident that whatever you are doing is going to be...
it's taken as a different person. I think that's one of the
main advantage of using this app because I can express
anything I want. So I don't need to really think about
what other... [Participant N1]
Some participants said that compared with healthcare profes
sionals, they were more willing to share personal issues with apps.
They explained that due to social etiquette and respect towards
healthcare professionals in face-to-face therapy, they were cautious
about the information they provided and the language they used. On
the other hand, when dealing with an unpleasant situation or a diffi
cult person in their life, the non-judgmental nature of an app made it a
safe space for participants to freely express their feelings.
So I would type in, using any language, maybe it be abu
sive or anything not safe for work. So, I might write it on
there, which I can't really express to a person who I'm
dealing with. And I don't think any specialists will be
happy to hear such conversations. [Participant N1]
However, this type of openness needs to be balanced with peo
ple's distrust of technology (distrust in Theme 3), which could inhibit
people from being open and honest with their difficulties.
I didn't feel safe... it just looks like a chat box, like you're
messaging somebody. As soon as I figured out it wasn't a
real person, I didn't feel as though talking about my own
personal problems would help. I didn't think that they
would be able to help me. Well, even if they did, I proba
bly wouldn't want to make it open. Because it's digital. I
don't know. I'm always a bit skeptical about everything
that's online, that's digital. I don't want to be too open
about things, especially when it comes to my personal
problems. [Participant H1]
The distrust of apps was possibly caused by concerns of privacy
and data security. Some participants considered apps as being less an
invasion of privacy. They said that they chose to use the private mode
(a mode which allowed people to use the app on their own without
sharing information or joining an online community), even though the
apps had public mode which allowed users to anonymously communi
cate with others in the community. They further expressed their
worries about privacy and data security, such as tracking information
without permission, automatically linking accounts with other users,
asking for too much personal information, and automatically accessing
contacts' information. The worries of data security and privacy largely
came from participants' previous experiences with other types of apps.
Because I thought that they would track my activities, all
my activities on the app. Not just sharing my experiences
and stuff. But no, I just thought that it would be public to
anybody, and I didn't want my phone to automatically
link my account to people that also had [app name].
Phones often use... yeah, it just automatically uses your
contacts to suggest these people that are also using the
app. [Participant H1]
A lack of connections and emotional support could also stop users
being open to apps. When users did not feel understood by the app,
they had less willingness to share personal problems with the app.
However, on the other hand, there was no evidence to show that
more openness can lead to better connections.
So I still feel like, because it's (openness and relationship)
emotional thing, is really a human personal thing. So, for
the robot chats, they're kind of on the opposite side of
this emotional thing because they're not real person.
So, it's not what I want. What I want is really talking
to someone or to experience something more real.
[Participant L1]
TONG ET AL. 1005
10990879, 2023, 5, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/cpp.2851 by Cochrane France, Wiley Online Library on [15/07/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License


3.5 | Lack of agreement upon goals
Participants started using apps for various reasons. Multiple partici
pants mentioned that they started using the app only because their
friends or their workplace recommended it. A few participants used
apps as an alternative to getting help from a healthcare professional,
since they could not meet their therapists in person during the
COVID-19 pandemic. Several people said that they used apps
mainly for avoiding feelings of loneliness and boredom. Some
participants mentioned that they started using an app with the hope
of managing stress, anxiety, sleep problems and chronic pain.
However, regardless of the reasons, most participants did not have
or develop a concrete goal (a goal or change that can be measured)
when using the app.
It was recommended by one of my friends, and I just
tried to see what it can offer. Yeah, and also because I
was in a very anxious stage at that moment. Yeah. So, I
was thinking, why not?... I actually did not. Yeah.
Because when I use that app, it has a function button to
let me set a goal, but I did not really use that. I haven't.
[Participant L1]
Whether participants had an agreed upon goal in mind when
using the app may not influence their views on whether they could
build a relationship with the app. Participants who did not identify a
clear goal or purpose or reason for using the app still developed a rela
tionship with an app.
I just wanted to de-stress and stuff, but no specific
goals or things... I feel like the (relationship with an)
app is similar (to the relationship with therapists).
Obviously, it's not a real human. But I think it can
help you. It's not rude. The app is very helpful.
You can do it at your own pace, it's very considerate.
[Participant J1]
However, goal-setting functions, such as earning points to
achieve a certain goal, may help users to articulate and find a con
crete goal. One participant said that an ADHD behavioural change
app helped him to set a goal by rewarding points for his
achievements.
What it does is a sort of gamifies your achievements. So
say you have a goal of, I want to go to bed at 10:30 each
night, you get a certain amount of points every time you
do that and you can level up and it's a bit like an RPG sort
of thing.... There's a lot of things in your life that
often you might just forget about completely, and if you
don't have a plan, sometimes those things can get left
behind... It was more the app that sort of gave me those
goals. [Participant H1]
4 | DISCUSSION
Five themes were identified from the data: (1) valuing flexibility;
(2) the role of self-initiative accountability; (3) the importance of emo
tional experiences for building connections; (4) enhanced openness;
and (5) lack of agreement upon goals. Depending on a participant's
background and an app's functionality, participants held mixed ideas
towards DTA in the context of fully automated mental health apps. In
general, the degree of flexibility, accountability, openness and emo
tional experiences and connections were core components for build
ing and determining the quality of a DTA. The necessity of agreed
upon goals to forming DTA needs to be further studied. These themes
are interrelated and their relationships are displayed in the thematic
map in Figure 1.
The solid line refers to the suggested relationships. The dash line
means that the relationship needs further investigation. The squares
refer to the common factors between the themes. Emotional experi
ences and connections (Theme 3) may influence openness (Theme 4).
Trust (in the square) probably play a role in both openness (Theme 4)
and emotional experiences and connections (Theme 3). In addition,
since apps are flexible (Theme 1), it was hard to help users remain
accountable (in the square). Thus, using apps may require a high level
of self-initiative and accountability (Theme 2). A lack of accountability
may also influence emotional experiences and connections (Theme 3).
Although most participants did not build an agreed upon goal (Theme
5), goal may still be an important factor of DTA, and the role of goal
needs further investigation.
Previous studies suggested that flexibility (in terms of time, dura
tion, location and functions) could contribute to high engagement and
user satisfaction with smartphone health apps (Lancaster et al., 2020;
Stawarz et al., 2018; Werner-Seidler et al., 2017). Clarke et al. (2016)
argued that the flexible nature of apps could possibly influence how
DTA is built in the context of fully automated mental health apps. Our
study supports this idea. Many participants found that apps were
more flexible than face-to-face therapy, and thus, more accessible.
The flexibility helped them to build a relationship with an app which
was more convenient than the one that could be formed in face-to
face therapy. In addition, it is worth noting that although flexibility in
choosing functions could provide users with opportunities to get the
support they were seeking whenever they needed, more functions
might not always be better. Some researchers have found that too
many features in one product could be overwhelming and confusing
(Thompson et al., 2005). Thus, how to balance flexibility and user
experience requires further consideration and investigation.
To build a DTA, users needed to have self-initiative/
accountability (the willingness to actively start and maintain the rela
tionship). The theme accountability is also a subscale of the ARM
(where it is termed client-initiative) and is considered essential in
face-to-face therapy (Agnew-Davies et al., 1998). However, although
certain app functions, such as tracking and notifications, could help
users to take the initiative, users still felt that the experience was not
comparable to the sense of accountability. Therefore, more studies on
1006 TONG ET AL.
10990879, 2023, 5, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/cpp.2851 by Cochrane France, Wiley Online Library on [15/07/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License


encouraging users to take the initiative may need to be conducted in
the future.
Bond as a subscale of both WAI and ARM is critical in face-to
face therapy. Some researchers argued that bond could also be estab
lished in DTA in the context of fully automated mental health apps
since the rating of goal (in modified WAI scale) was comparable to
face-to-face therapy (Darcy et al., 2021). However, it was not a theme
that emerged in our study. Bond in face-to-face therapy refers to the
human relationship between clients and healthcare professionals, and
involves qualities such as friendliness, understanding, and acceptance,
which are created by mutual trust and respect (Agnew-Davies
et al., 1998; Bordin, 1979). This kind of bond is thought to be shaped
and influenced by the life experiences of both clients and healthcare
professionals, and requires bidirectional connections (Bordin, 1979).
However, in the context of fully automated mental health apps,
although users could have the feeling of being cared for and sup
ported by apps, apps cannot actually experience and express genuine
trust and respect to their users. Therefore, instead of using the word
‘bond’ in this study, we used the terms emotional experiences and
connection to describe users' feeling of relaxation and being com
forted and cared for.
It is worth noting that not all participants developed a connec
tion with an app. This kind of connection appeared to be influ
enced by an app's perceived lack of genuineness. Genuineness is
one of the core components in building TA in face-to-face therapy
(Rogers, 2007). It means that within relationships between clients
and healthcare professionals, the healthcare professionals truly rep
resent themselves (Rogers, 2007). This concept of genuineness,
transferred to the context of fully automated mental health apps,
could represent whether an app does what it claims to. For
example, some apps might make users feel that they only want to
earn money despite their claims to help users with their mental
health problems.
A lack of interactivity could also harm connections. Compared to
face-to-face therapy, most apps could not provide enough two-way
communication, continuous conversations (even with chatting
functions), voice and facial expressions. This might result in a lack of
interactivity between users and apps, and potentially became a barrier
for users to establish deep connections with apps. Clarke et al. (2016)
suggested that although interactivity is not part of any existing DTA
scales, interactive elements, such as providing feedback and using
graphs, in apps are important for building DTA. Kim and Baek (2018)
also reported that interactivity could influence users' relationships
with smartphone apps. Our study supports their idea. Interactivity
could have an impact not only on DTA, but also on engagement.
Cao et al. (2022) have built framework for digital health apps that
suggests that interactivity could influence engagement, which could
further impact effectiveness of the apps. However, it is important to
note that not all interactive elements could promote DTA and well
designed interactive features need to incorporate human-computer
interaction theories. Simon and colleagues (D'Alfonso et al., 2020)
pointed out that persuasive system design and positive psychology
needs to be incorporated to design responsive dialogue support
and conversional agents, which may provide emotional support to
users and foster trust.
Openness, the willingness of opening up to apps, was important
for building DTA with fully automated mental health apps. It is
another shared dimension between DTA and TA (Agnew-Davies
et al., 1998). However, although some participants were more willing
to share personal experiences with apps since apps were perceived to
be non-judgemental, this type of openness could be damaged by a
lack of trust. Privacy and data security were barriers which prevent
people from openly expressing themselves to an app. This finding is
consistent with a study of AI-driven health chatbot apps, which
showed that cybersecurity influenced trust and further damaged the
acceptability of the app (Nadarzynski et al., 2019).
It is worth noting that trust/distrust played an important role in
building both openness and connections in DTA. The distrust of tech
nology could be shaped by external information. For example, con
cerns around data security and confidentiality, which could influence
openness, largely came from peoples' previous experiences with other
types of apps. The distrust of technology (algorithms), which might
influence connections, partially came from the nature of people's
familiarity with technology. Previous research suggested that a lack of
accurate information (unknown) and transparency could create a
sense of fear around technology (Graham, 2020; Li & Huang, 2020;
Nestik et al., 2018; Thielsch et al., 2018). Thus, it is important that
users can trust mental health apps and that the public is provided with
reliable and accurate information regarding mental health apps. How
ever, many other factors, such as social-cultural background, personal
ity, political beliefs (Hsiao, 2003; Nimrod, 2018; Randall et al., 2021)
can influence trust in the technology. Therefore, understanding how
to promote trust in mental health apps would be vital.
Agreement on goals is a subscale of the WAI (Bordin, 1979). Pre
vious research suggested that agreed upon goals are also critical in
building DTA in the context of fully automated mental health apps
(Goldberg et al., 2021; Prochaska et al., 2021). However, our qualita
tive data showed that even if someone did not have an agreed upon
goal in mind when using an app, they could still feel connected with
the app. Moreover, while it is the case that in face-to-face therapy
establishing goals and tasks requires agreement from both clients and
healthcare professionals, apps may not be able to actively agree on
goals and tasks with users. However, this study finding might be lim
ited since most apps that the participants used did not have goal
building functions. If an app requires users to select a goal when the
app is being configured, then it is likely that users and the app can
build an agreement on goals. In addition, in face-to-face therapy,
healthcare professionals can help users to select a goal during the pro
cess of therapy. Therefore, functions in apps which help users to find
goals may also be useful. For example, earning points by completing
tasks may help users to find a goal during the process of using the
apps. It is worth noting that although participants did not feel it neces
sary to establish agreed upon goals to use a mental health app, this
does not necessarily mean that an app offering goal functionality is
not relevant to the formation of alliance. Even though users can build
an alliance with an app without a goal, it is may be possible for them
TONG ET AL. 1007
10990879, 2023, 5, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/cpp.2851 by Cochrane France, Wiley Online Library on [15/07/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License


to build a stronger alliance with a more concrete goal. On the other
hand, although most users did not explicitly state that they had a con
crete goal in mind when using the app, almost all users had reasons
for using them. This suggests that the definition of goal in the context
of fully automated mental health apps may need to be redefined.
Instead of defining goal as agreed upon goals, goals in the digital con
text may be more broadly considered as reasons/goals for using an
app. It is possible that users may loosely agree on goals when they
actively browse the content in a mental health app or when they
adopt an app feature However, we think the role of goals needs to be
further studied in the future. Finally, fortuitous match in goals, where
users' goals happen to fit well with what the app has to offer, may fos
ter a stronger alliance between users and a mental health app. There
fore, a mental health app guide, which assists users to select their best
fit app, may help users to develop a DTA with the app.
In conclusion, DTA and TA have both similarities and differences.
Self-initiative and openness play important roles in both DTA and
TA. On the other hand, although emotional factors are core compo
nents of both DTA and TA, app users are more likely to have a con
nection, rather than a bond, with fully automated mental health apps.
In addition, flexibility is a unique dimension that only exists in
the DTA.
In the end, our study revealed that certain functions might be able
to elicit some factors of DTA, and may further enhance the relation
ship of an app and an app user. First, real-time responses could pro
vide better flexibility and therefore enhance the DTA. This finding
aligns with Szameitat et al. (2009) which revealed that a delay in
response would harm emotional effects. Similarly, D'Alfonso et al.
(2020) also pointed out that affectively and effectively responsiveness
are essential for mental health apps to build an alliance with users.
Second, functionality, such as tracking, reminders, and a reward sys
tem can provide some accountability and encourage users to engage
with the app. Third, users may have a variety of emotional experi
ences which may influence their relationships with apps, and two-way
communication, immediate responses, and continuous conversations
are important for apps to provide these emotional experiences. There
fore, interactive elements, such as well-designed games, chatbots,
video and voice responses, and customization could increase emo
tional support and further help users build relationships with apps.
Fourth, clear statements and guidelines of data security would provide
users a sense of security and further help them to be more open to
apps and therefore have a better alliance. Fifth, goal setting functions,
such as a rewarding system, might be able to help users to articulate
and concretize their goal and further build a better alliance with
the app.
5 | LIMITATIONS
First, there are reportedly at least 10,000 mental health apps on the
market (Lagan et al., 2021) and each of them has a different design.
Our study was only able to cover a small number of apps available.
However, we interviewed people who had used a range of apps, such
as chatbots, tracking apps, meditation apps and apps with gamified
tasks. Second, since we posted our study advertisement on a univer
sity website, most participants were university students and the study
was fairly homogenous in terms of age. Therefore, future studies
could target other sectors or a broader spectrum of the community.
Third, all interviews were conducted during the COVID-19 pandemic
and participants' behaviour and views on mental health might be influ
enced by the lockdown and pandemic. In particular, it is worth noting
that the location in which the study was taken had one of the longest
lockdown in the world (Zandt, 2021). Since many in-person activities
were restricted during lockdown, digital mental health might become
more favourable, and this might have influenced our data. For exam
ple, people were social isolated during lockdown and thus may tend
to seek help from mental health apps more often. Fourth, this study
only represented the views of people with mild mental health prob
lems and might not account for the views of people with more severe
mental health difficulties. Fifth although participants with various cul
tural background were involved in this study, we did not record partic
ipants' ethnicity/nationality information and views of people from a
wide cultural background were not captured. Sixth, although authors
made efforts to ensure rigour of the data, we acknowledge that addi
tional steps, such as member checking the thematic structure of the
data, could also have been taken. However, due to time and funding
limitations, this method was not feasible or possible. Seventh, to help
participants better understand the meaning of a relationship with an
app, we first asked them about their relationships with therapists, but
many participants had not experienced in-person therapy. As such,
some participant's views on differences between digital and face-to
face therapies were hypothetical rather than views. Eighth, the infor
mation of the lengths of time seeing a therapist and using mental
health apps is not available.
6 | FUTURE DIRECTIONS
To further understand DTA in the context of fully automated mental
health apps, more qualitative studies can be conducted with people
with diverse backgrounds, such as people with serious mental health
problems, and people from more diverse cultural and ethnic back
grounds. Studies with a broader range of apps can also be carried out
in the future to explore the concept further. In addition, although we
found that it was not necessary to establish agreed upon goals to use
a mental health app, this does not necessarily mean that an app offer
ing goal functionality is not relevant to the formation of DTA. Thus,
the role of goals and tasks requires further investigation. For example,
studies with users who have used apps with goal setting functions can
be conducted to explore whether building a goal can lead to better
clinical outcomes. Further mixed-methods studies may also need to
be carried out to redefine goal in the context of fully automated men
tal health apps. Moreover, how to build an app to provide better DTA
needs to be further studied. For example, how should user guidelines
be designed to provide users with a sense of security. Similarly, how
to balance is another area that needs to be further studied.
1008 TONG ET AL.
10990879, 2023, 5, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/cpp.2851 by Cochrane France, Wiley Online Library on [15/07/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License


Development and psychometric evaluation and validation of a
DTA scale that is easy to use and incorporates themes identified
through qualitative exploration of the TA concept in the context of
digital mental health is also warranted. Quantitative studies need to
be conducted to further investigate the associations between DTA,
engagement and clinical outcomes. Beyond establishing conceptuali
zations and corresponding measures of the DTA, further research
might examine app characteristics and functions that are conducive to
DTA formation. Questions related to this endeavour include the fol
lowing: (1) what kind of language and voice should be used to
enhance emotional experiences and connections? (2) What functions
can be added to increase interactions? (3) How can users be moti
vated to take the lead? And (4) How can guidelines be designed to
help users trust the app?
7 | CONCLUSION
Understanding the DTA in the context of fully automated mental
health apps is an important research endeavour which may lead to
improvements in how to develop effective apps. However, DTA in the
context of fully automated mental health apps is under-researched.
Our study aimed to conceptualize DTA in the context of fully auto
mated mental health apps, and found DTA can be built through users'
accountability, openness to apps, emotional experiences and connec
tions with apps, and flexible interactions with apps. To the best of our
knowledge, this is the first study that qualitatively explored the
dimensions of a DTA in the context of fully automated mental
health apps.
ACKNOWLEDGEMENTS
Fangziyun Tong is supported by a University of Melbourne and Uni
versity of Manchester Graduate Research Group PhD Scholarship.
Open access publishing facilitated by The University of Melbourne, as
part of the Wiley - The University of Melbourne agreement via the
Council of Australian University Librarians.
CONFLICT OF INTEREST STATEMENT
SB is Director and shareholder of CareLoop Health Ltd, a University
of Manchester start-up to develop and market digital solutions for
mental health problems, currently schizophrenia and postnatal depres
sion. SB also reports research funding from the National Institute for
Health and Care Research (NIHR) and The Wellcome Trust.
DATA AVAILABILITY STATEMENT
The data that support the findings of this study are available on
request from the corresponding author. The data are not publicly
available due to privacy or ethical restrictions.
ORCID
Katherine Berry https://orcid.org/0000-0002-7399-5462
Sandra Bucci https://orcid.org/0000-0002-6197-5333
REFERENCES
Agnew-Davies, R., Stiles, W. B., Hardy, G. E., Barkham, M., & Shapiro, D. A. (1998). Alliance structure assessed by the Agnew relationship measure (ARM). British Journal of Clinical Psychology, 37(2), 155–172. https:// doi.org/10.1111/j.2044-8260.1998.tb01291.x Alexander, L. B., & Luborsky, L. (1986). The Penn helping alliance scales. Australian Government. (2012). E-mental health strategy for Australia (p. 22).
Bachelor, A. (1995). Clients' perception of the therapeutic alliance: A qualitative analysis. Journal of Counseling Psychology, 42(3), 323–337. https://doi.org/10.1037/0022-0167.42.3.323 Berry, K., Salter, A., Morris, R., James, S., & Bucci, S. (2018). Assessing therapeutic Alliance in the context of mHealth interventions for mental health problems: Development of the Mobile Agnew relationship measure (mARM) questionnaire. Journal of Medical Internet Research, 20(4), e90. https://doi.org/10.2196/jmir.8252 Bordin, E. S. (1979). The generalizability of the psychoanalytic concept of the working alliance. Psychotherapy: Theory, Research & Practice, 16(3), 252–260. https://doi.org/10.1037/h0085885 Braun, V., & Clarke, V. (2006). Using thematic analysis in psychology. Qualitative Research in Psychology, 3(2), 77–101. https://doi.org/10.1191/ 1478088706qp063oa Braun, V., & Clarke, V. (2019). Reflecting on reflexive thematic analysis. Qualitative Research in Sport, Exercise and Health, 11(4), 589–597. https://doi.org/10.1080/2159676X.2019.1628806 Bucci, S., Barrowclough, C., Ainsworth, J., Machin, M., Morris, R., Berry, K., Emsley, R., Lewis, S., Edge, D., Buchan, I., & Haddock, G. (2018). Actissist: Proof-of-concept trial of a theory-driven digital intervention for psychosis. Schizophrenia Bulletin, 44(5), 1070–1080. https://doi.org/ 10.1093/schbul/sby032 Cao, W., Milks, M. W., Liu, X., Gregory, M. E., Addison, D., Zhang, P., & Li, L. (2022). mHealth interventions for self-management of hypertension: Framework and systematic review on engagement, interactivity, and tailoring. JMIR mHealth and uHealth, 10(3), e29415. https://doi. org/10.2196/29415 Clarke, J., Proudfoot, J., Whitton, A., Birch, M.-R., Boyd, M., Parker, G., Manicavasagar, V., Hadzi-Pavlovic, D., & Fogarty, A. (2016). Therapeutic alliance with a fully automated mobile phone and web-based intervention: Secondary analysis of a randomized controlled trial. JMIR Mental Health, 3(1), e10. https://doi.org/10.2196/mental.4656 Clarke, V., & Braun, V. (2013). Teaching thematic analysis: Overcoming challenges and developing strategies for effective learning. The Psychologist, 26(2).
D'Alfonso, S., Lederman, R., Bucci, S., & Berry, K. (2020). The digital therapeutic Alliance and human-computer interaction. JMIR Mental Health, 7(12), e21895. https://doi.org/10.2196/21895 Darcy, A., Daniels, J., Salinger, D., Wicks, P., & Robinson, A. (2021). Evidence of human-level bonds established with a digital conversational agent: Cross-sectional, retrospective observational study. JMIR Formative Research, 5(5), e27868. https://doi.org/10.2196/27868 Denecke, K., Schmid, N., & Nüssli, S. (2022). Implementation of cognitive behavioral therapy in e–mental health apps: Literature review. Journal of Medical Internet Research, 24(3), e27791. https://doi.org/10.2196/ 27791 Ebert, D. D., Van Daele, T., Nordgreen, T., Karekla, M., Compare, A., Zarbo, C., Brugnera, A., Øverland, S., Trebbi, G., Jensen, K. L., Kaehlke, F., & Baumeister, H. (2018). Internet- and Mobile-based psychological interventions: Applications, efficacy, and potential for improving mental health. European Psychologist, 23(2), 167–187. https://doi.org/10.1027/1016-9040/a000318 Edhlund, B., & McDougall, A. (2019). NVivo 12 essentials. Lulu.com. Firth, J., Torous, J., Nicholas, J., Carney, R., Rosenbaum, S., & Sarris, J. (2017). Can smartphone mental health interventions reduce symptoms of anxiety? A meta-analysis of randomized controlled trials. Journal of
TONG ET AL. 1009
10990879, 2023, 5, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/cpp.2851 by Cochrane France, Wiley Online Library on [15/07/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License


Affective Disorders, 218, 15–22. https://doi.org/10.1016/j.jad.2017. 04.046 Fletcher, A. J. (2017). Applying critical realism in qualitative research: Methodology meets method. International Journal of Social Research Methodology, 20(2), 181–194. https://doi.org/10.1080/13645579. 2016.1144401 Flückiger, C., Del Re, A. C., Wampold, B. E., & Horvath, A. O. (2018). The alliance in adult psychotherapy: A meta-analytic synthesis. Psychotherapy, 55(4), 316–340. https://doi.org/10.1037/pst0000172 Goldberg, S. B., Baldwin, S. A., Riordan, K. M., Torous, J., Dahl, C. J., Davidson, R. J., & Hirshberg, M. J. (2021). Alliance with an unguided smartphone app: Validation of the digital working Alliance inventory. Assessment, 10731911211015310. Goldberg, S. B., Lam, S. U., Simonsson, O., Torous, J., & Sun, S. (2022). Mobile phone-based interventions for mental health: A systematic meta-review of 14 meta-analyses of randomized controlled trials. PLOS Digital Health, 1(1), e0000002. https://doi.org/10.1371/journal. pdig.0000002 Gomez Penedo, J. M., Babl, A. M., Holtforth, M., Grosse, Hohagen, F., Krieger, T., Lutz, W., Meyer, B., Moritz, S., Klein, J. P., & Berger, T. (2020). The Association of Therapeutic Alliance with Long-Term Outcome in a guided internet intervention for depression: Secondary analysis from a randomized control trial. Journal of Medical Internet Research, 22(3), e15824. https://doi.org/10.2196/15824 Graham, C. (2020). Fear of the unknown with healthcare IoT devices: An exploratory study. Information Security Journal: A Global Perspective, 30, 1–11. https://doi.org/10.1080/19393555.2020.1810369 Horvath, A. O., & Greenberg, L. S. (1989). Development and validation of the working Alliance inventory. Journal of Counseling Psychology, 36(2), 223–233. https://doi.org/10.1037/0022-0167.36.2.223 Hsiao, R. (2003). Technology fears: Distrust and cultural persistence in electronic marketplace adoption. The Journal of Strategic Information Systems, 12, 169–199. https://doi.org/10.1016/S0963-8687(03)00034-9 Karver, M. S., De Nadai, A. S., Monahan, M., & Shirk, S. R. (2018). Metaanalysis of the prospective relation between alliance and outcome in child and adolescent psychotherapy. Psychotherapy, 55(4), 341–355. https://doi.org/10.1037/pst0000176 Kim, S., & Baek, T. H. (2018). Examining the antecedents and consequences of mobile app engagement. Telematics and Informatics, 35(1), 148–158. https://doi.org/10.1016/j.tele.2017.10.008 Lagan, S., D'Mello, R., Vaidyam, A., Bilden, R., & Torous, J. (2021). Assessing mental health apps marketplaces with objective metrics from 29,190 data points from 278 apps. Acta Psychiatrica Scandinavica, 144(2), 201–210. https://doi.org/10.1111/acps.13306 Lancaster, C., Koychev, I., Blane, J., Chinner, A., Wolters, L., & Hinds, C. (2020). Evaluating the feasibility of frequent cognitive assessment using the Mezurio smartphone app: Observational and interview study in adults with elevated dementia risk. JMIR mHealth and uHealth, 8(4), e16142. https://doi.org/10.2196/16142 Li, J., & Huang, J.-S. (2020). Dimensions of artificial intelligence anxiety based on the integrated fear acquisition theory. Technology in Society, 63, 101410. https://doi.org/10.1016/j.techsoc.2020.101410 Mander, J., Neubauer, A. B., Schlarb, A., Teufel, M., Bents, H., Hautzinger, M., Zipfel, S., Wittorf, A., & Sammet, I. (2017). The therapeutic alliance in different mental disorders: A comparison of patients with depression, somatoform, and eating disorders. Psychology and Psychotherapy: Theory, Research and Practice, 90(4), 649–667. https:// doi.org/10.1111/papt.12131 Marmar, C. R., Horowitz, M. J., Weiss, D. S., & Marziali, E. (1986). The development of the therapeutic Alliance rating system.
Nadarzynski, T., Miles, O., Cowie, A., & Ridge, D. (2019). Acceptability of artificial intelligence (AI)-led chatbot services in healthcare: A mixedmethods study. Digital Health, 5, 2055207619871808. https://doi. org/10.1177/2055207619871808
Nestik, T., Zhuravlev, A., Eduard, P., Marianna, S. C., Lioudmila, B., Piurcosky, F. P., & Ferreira, J. V. (2018). Technophobia as a cultural and psychological phenomenon: Theoretical analysis. Interaç ̃ao-Revista De Ensino, Pesquisa E Extens ̃ao, 20(1), 266–281.
Nimrod, G. (2018). Technophobia among older internet users. Educational Gerontology, 44(2–3), 148–162. https://doi.org/10.1080/03601277. 2018.1428145 Prochaska, J. J., Vogel, E. A., Chieng, A., Baiocchi, M., Maglalang, D. D., Pajarito, S., Weingardt, K. R., Darcy, A., & Robinson, A. (2021). A randomized controlled trial of a therapeutic relational agent for reducing substance misuse during the COVID-19 pandemic. Drug and Alcohol Dependence, 108986. https://doi.org/10.1016/j.drugalcdep.2021. 108986 Randall, J. G., Dalal, D., & Dowden, A. (2021). Improving contact tracing in minority communities by combating misinformation and distrust.
Richards, P., Simpson, S., Bastiampillai, T., Pietrabissa, G., & Castelnuovo, G. (2018). The impact of technology on therapeutic alliance and engagement in psychotherapy: The therapist's perspective. Clinical Psychologist, 22(2), 171–181. https://doi.org/10.1111/cp. 12102 Rogers, C. R. (2007). The necessary and sufficient conditions of therapeutic personality change. Psychotherapy: Theory, Research, Practice, Training, 44(3), 240–248. https://doi.org/10.1037/0033-3204.44.3.240 Scherer, S., Alder, J., Gaab, J., Berger, T., Ihde, K., & Urech, C. (2016). Patient satisfaction and psychological well-being after internet-based cognitive behavioral stress management (IB-CBSM) for women with preterm labor: A randomized controlled trial. Journal of Psychosomatic Research, 80, 37–43. https://doi.org/10.1016/j.jpsychores.2015.10.011 Stawarz, K., Preist, C., Tallon, D., Wiles, N., & Coyle, D. (2018). User experience of cognitive behavioral therapy apps for depression: An analysis of app functionality and user reviews. Journal of Medical Internet Research, 20(6), e10120. https://doi.org/10.2196/10120 Suh, C. S., Strupp, H. H., & O'Malley, S. S. (1986). The Vanderbilt process measures: The psychotherapy process scale (VPPS) and the negative indicators scale (VNIS).
Szameitat, A. J., Rummel, J., Szameitat, D. P., & Sterr, A. (2009). Behavioral and emotional consequences of brief delays in human–computer interaction. International Journal of Human-Computer Studies, 67(7), 561570. https://doi.org/10.1016/j.ijhcs.2009.02.004 Thielsch, M. T., Meeßen, S. M., & Hertel, G. (2018). Trust and distrust in information systems at the workplace. PeerJ, 6, e5483. https://doi. org/10.7717/peerj.5483 Thompson, D. V., Hamilton, R. W., & Rust, R. T. (2005). Feature fatigue: When product capabilities become too much of a good thing. Journal of Marketing Research, 42(4), 431–442. https://doi.org/10.1509/jmkr. 2005.42.4.431 Tong, F., Lederman, R., D'Alfonso, S., Berry, K., & Bucci, S. (2022). Digital therapeutic Alliance with fully automated mental health smartphone apps: A narrative review. Frontiers in Psychiatry, 13, 819623. https:// doi.org/10.3389/fpsyt.2022.819623 Torous, J., Myrick, K. J., Rauseo-Ricupero, N., & Firth, J. (2020). Digital mental health and COVID-19: Using technology today to accelerate the curve on access and quality tomorrow. JMIR Mental Health, 7(3), e18848. https://doi.org/10.2196/18848
United Nations. (2020). COVID-19 and the need for action on mental health. Werner-Seidler, A., O'Dea, B., Shand, F., Johnston, L., Frayne, A., Fogarty, A. S., & Christensen, H. (2017). A smartphone app for adolescents with sleep disturbance: Development of the sleep ninja. JMIR Mental Health, 4(3), e7614. https://doi.org/10.2196/mental.7614
Willig, C. (2012). Perspectives on the epistemological bases for qualitative research. https://doi.org/10.1037/13619-002
Zandt, F. (2021, October). Infographic: The lost months of the coronavirus pandemic. Statista Infographics. https://www.statista.com/chart/ 26023/areas-with-the-longest-cumulative-pandemic-lockdowns/
1010 TONG ET AL.
10990879, 2023, 5, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/cpp.2851 by Cochrane France, Wiley Online Library on [15/07/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License


How to cite this article: Tong, F., Lederman, R., D'Alfonso, S.,
Berry, K., & Bucci, S. (2023). Conceptualizing the digital
therapeutic alliance in the context of fully automated mental
health apps: A thematic analysis. Clinical Psychology &
Psychotherapy, 30(5), 998–1012. https://doi.org/10.1002/cpp.
2851
APP E NDIX A: TOPIC GUIDE
A1 | General experiences with mental health apps
First, I would like to ask a couple of questions about your general
experiences with mental health apps.
• Are you currently using any apps to help with your mental health
or well-being?
(If yes) Which apps are you currently using?
• Except for this one/these ones, have you ever used any other men
tal health apps?
(if no) then which apps have you used?
• (If have used/are using only one):
• How would you describe your experience with the app?
• (Goal) What were your goals in using the app?
• (Task) Do you think the tasks/modules/activities provided by the
app were meaningful and helped you to achieve your goals?
• What expectations did you have about using the app? Are you sat
isfied with the help the app gave you?
(If using or used more than one):
• Which app did you use most frequently?
Let us talk about this app then,
• Can you describe the app to me? (e.g., features and functions)
• (Goal) What were your goals in using the app?
• (Task) Do you think the tasks/modules/activities provided by the
app were meaningful and helped you to achieve your goals?
• What expectations did you have about using the app? Are you sat
isfied with the help the app gave you?
• Are you ok to share your experiences of other apps?
• (If yes) repeat previous questions (no more than three apps due to
time limitation)
• (If no) jump to the next section
A2 | Helpfulness of functions and features
Let us talk more about this app (if talked about more than one app in
the previous section, starting with the most frequent one. Deciding if
I need to discuss the others depends on time).
• How helpful have you found the app?
If people find the app helpful/somewhat helpful:
• What is helpful about the app? In what ways? (The answer could
be app features, activities, events, or anything else they think are
important)
• Why? Can you give me some examples?
• Asking if there is anything else helpful. For example, what about
app features/activities/tasks/modules/functions?
• Is there anything that you think is unhelpful about the app?
If people find the app unhelpful/somewhat unhelpful:
• What is unhelpful about the app? In what ways (The answer could
be app features, activities, events, or anything else they think are
important)
• Why? Can you give me some examples?
• Asking if there is something else unhelpful. For example, what
about app features/activities/tasks/modules/functions?
• Is there anything that you think is helpful about the app?
A3 | Exploring DTA
• Have you ever tried face-to-face therapy, such as cognitive ther
apy, behaviour therapy, family therapy, group counselling?
(If yes)
❏ How do you feel about face-to-face therapy?
❏ What do you think are the differences between face-to-face ther
apy and mental health apps?
❏ What do you think are the similarities between face-to-face ther
apy and mental health apps?
❏ Do you have a preference? If yes, apps or therapists? Why?
❏ Are you still seeing the therapist?
❏ (if yes) so you are doing face-to-face therapy and using the
mental health apps at the same time? How do you find this
combination?
❏ (if no) jump to the next question
(if no)
❏ Why did you choose mental health apps instead of seeing thera
pists? What do you think are the differences?
❏ Do you think you will try face-to-face therapy at some point in
the future? If yes, why? If no, why not?
Ideally the interviewees will bring up the connectedness topics when
answer the above questions. However, if the interviewees did not
bring up the topic, I will ask the below questions. How will you
describe your relationship with your therapists?
TONG ET AL. 1011
10990879, 2023, 5, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/cpp.2851 by Cochrane France, Wiley Online Library on [15/07/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License


❏ Do you think you have a similar relationship or connection with
the app?
(If yes)- In what ways? Can you give me some examples?
- If let you choose a word or a phrase to describe your connected
ness or interaction with the app, what would it be?
- What is according to you, a good user-mental health app
relationship?
- What does it consist of? What are its main characteristics?
- Have you ever experienced the good relationship you
described?
(If yes) Can you give me an example of the time that you experi
enced a good relationship. (What was the function/module/activity?
What you felt?)
(If no) Can you give me an example of the time that you found
the relationship to be unsuitable. (What was the function/module/
activity? What you felt?)
(If no) In what ways are they different? Can you give me some
examples?
• How will you describe your interactions with the mental health
apps?
• What is according to you, a good or effective or meaningful user
mental health app interaction?
• What does it consist of? What are its main characteristics?
• Have you ever experienced the good relationship you described?
(If yes) Can you give me an example of the time that you experienced
a good interaction? (What was the function/module/activity? What
you felt?)
(If no) Can you give me an example of the time that you found
the interaction to be unsuitable? (What was the function/module/
activity? What you felt?)
To everyone:
• In which ways do you think mental health apps can substitute for
face-to-face therapy?
Sum up
• Is there anything else that you think is important for us to know?
• Are there any questions you think I should ask in other interviews?
• How did you find this interview? What can I improve on for the
next one?
• Do you have any questions for me?
1012 TONG ET AL.
10990879, 2023, 5, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/cpp.2851 by Cochrane France, Wiley Online Library on [15/07/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License