https://doi.org/10.1177/03008916241299616
Tumori Journal 2025, Vol. 111(1) 6–10 © Fondazione IRCCS Istituto Nazionale dei Tumori 2024 Article reuse guidelines: sagepub.com/journals-permissions DOI: 10.1177/03008916241299616 journals.sagepub.com/home/tmj
Tj Tumori
journal
Introduction
In recent years, new technologies such as artificial intelligence (AI) systems have been increasingly influential in shaping information and guiding choices in daily, professional, and personal life, and thus also in health. Among these is ChatGPT, a chatbot—that is, a software program designed to simulate conversations with human users—launched by OpenAI in November 2022. Alongside other AI models, it immediately sparked great interest, reaching 100 million users in just the first two months after its launch. Shortly thereafter, Google released its Bard system to the market, and since then numerous AI applications usable on personal computers and smartphones have become available. While the Internet and social networks have for years had a significant impact on various aspects related to health, significantly influencing the doctor-patient relationship,1 it is important to reflect on the future impact of AI technologies in the healthcare sector as well as in the field of health pastoral care.2-4
Historical background of health pastoral care
Health pastoral care has ancient origins, closely linked to the idea of offering spiritual and moral support to individuals and communities during periods of illness or difficulty.
In Italy, spiritual assistance is provided for under the National Health System regulations, which ‘guarantees religious assistance in respect of the will and freedom of conscience of the citizen’ (Art. 38, Law No. 833 of 23 December 1978). Generally, spiritual assistance is offered by a Catholic priest who operates within the healthcare facility. However, there are specific training programmes designed to prepare Catholic chaplains to interact with diverse socio-religious contexts.5,6 The spiritual assistant must integrate into the multidisciplinary care team, collaborating with other professionals in the overall treatment of the patient.7 A well-known model is the assistance provided to young cancer patients within the Paediatric Oncology Unit of the Istituto Nazionale dei Tumori in Milan, where the Catholic priest is a member of the staff and is present daily in the ward.8-10
Evolving perspectives: Exploring the role of artificial intelligence between clinical practice and health pastoral care
Carlo Alfredo Clerici1,2, Andrea Ferrari1,2 and Tullio Proserpio3
Abstract
This article analyses the integration of artificial intelligence (AI) in health pastoral care, emphasizing the synergy between technology and spirituality. This paper discusses possible AI applications, highlighting the importance of ethical implementation that respects human interactions. Ethical issues like privacy and empathy are examined, as well as the potential of AI in facilitating collaboration between healthcare professionals and pastoral workers. Finally, it calls for a debate on the responsible use of AI in care contexts.
Keywords
Artificial intelligence, health pastoral care, ethics, technology, person-centred care
Date received: 7 October 2024; accepted: 26 October 2024
1Pediatric Oncology Unit, Fondazione IRCCS Istituto Nazionale dei Tumori, Milan, Italy 2Department of Oncology and Hemato-oncology, University of Milan, Milan, Italy 3Pastoral Care Unit, Fondazione IRCCS Istituto Nazionale dei Tumori, Milan, Italy
Corresponding author:
Andrea Ferrari, Fondazione IRCCS Istituto Nazionale dei Tumori, Via G. Venezian, 1, Milan, 20133, Italy. Email: andrea.ferrari@istitutotumori.mi.it
1 2 9 9 6 1 6 TMJ0010.1177/03008916241299616Tumori JournalClerici et al.
editorial2024
Editorial


Clerici et al. 7
Health pastoral care represents a collaboration between spiritual and medical realms. Its history is marked by moments of cooperation between healthcare professionals and religious figures, in response to socio-cultural changes, health emergencies, and also new technologies.11
The emergence of AI in the healthcare sector
The advent of AI has inaugurated a new era in the field of medicine as well: it has the potential to personalize healthcare, improve operational efficiency, and promote medical research.12-15 AI, for example, can perform heavy and repetitive tasks, such as analyzing large volumes of clinical data, thus freeing up resources with the aim of allowing healthcare personnel to focus on more patient-oriented activities. Furthermore, AI has opened new horizons to support people with disabilities, proposing solutions like augmented reality or sign language interpretation, improving the quality of life for these individuals. A new and little-discussed aspect is the potential role of AI in improving collaboration between clinical care and pastoral care, providing solutions that facilitate communication between healthcare professionals and pastoral workers.16 For the purposes of discussion, it may be useful to distinguish between: 1) short-term perspectives, linked to concretely useful and achievable applications in the present or immediate future; 2) long-term perspectives, concerning possible wide-ranging applications that could potentially operate autonomously from human control; the latter raise ethical, social, and psychological issues that merit in-depth analysis. However, it should be emphasized that the essence of human relationships, in their purest sense, can hardly be completely replaced.
Short-term perspectives
The introduction of AI with personal assistant functions has opened new frontiers in various sectors. Hospital spiritual care, fundamental for the emotional support of patients and their families, can also benefit from integration with AI. There are several possible applications of AI in this field:
- Information Management System: An AI-based system can provide routine support for information requests and email drafting, manage appointments and visit requests, and collect patients' spiritual preferences to optimize and personalize the service offered by chaplains.
- Text Drafting: Thanks to its linguistic capabilities, AI can assist in writing pastoral texts, such as homilies. However, it is essential to consider it as a support tool and not a substitute for the chaplain.
- Automatic Translation Tools: AI can facilitate communication with speakers of different languages, making spiritual support accessible to everyone.
- Virtual Response Systems: AI systems could provide preliminary information and support to patients or their families while they wait for a chaplain.
- Well-Being Monitoring Systems: AI can analyze patients' emotional well-being and alert chaplains to any need for intervention.
- Feedback Collection and Analysis: AI can automate the collection and analysis of feedback, providing useful data to improve the service.
- Education and Training: AI-powered learning platforms can offer courses on medical and spiritual topics and simulated scenarios to improve hospital chaplains' skills and promote effective collaboration between disciplines.
- Support for Teaching and Research: AI can assist in drafting article drafts or in data analysis.
The growing diffusion of AI requires a general reflection on its role in education, even at the university level. On the one hand, it should be remembered that GPT-4, the model behind ChatGPT+, is capable of correctly answering 90% of the questions presented in the United States Medical Licensing Examination (USMLE).12 On the other hand, there are risks related to improper use or plagiarism by students. In research, it is fundamental that researchers carefully verify the results obtained. Cautions are linked to the risk of generating incorrect content, risks of bias and discrimination, lack of transparency and reliability, safety concerns, ethical consequences, and social implications. A critical aspect of the results produced by AI is their lack of peer review and reliable bibliographies. It is essential to be cautious and critical in using the information provided by AI and always remember that the dissemination of incorrect information can have serious consequences in the medical field. However, we believe that the various possible applications of AI can represent an added value for hospital chaplaincy services, promoting efficiency, effectiveness, and the accessibility of the spiritual and emotional support provided. It is important to consider an ethical and respectful implementation of AI that takes into account the sensitivity and uniqueness of human interactions in the context of hospital chaplaincy.
Automatic systems for spiritual assistance?
AI is transforming the field of medical diagnosis and treatment through the use of advanced algorithms and the analysis of vast volumes of data. AI systems are being explored that could improve the understanding of patients' individual


8 Tumori Journal 111(1)
needs, promoting more targeted and effective patient-centred healthcare. A particular situation is offered by AI algorithms that provide immediate counselling services, serving as a first line of intervention when there is difficulty accessing medical professionals, or in situations where patients are reluctant to discuss their problems with a doctor (for example, in specific cases of individuals suffering from mental illnesses or living in situations of strong social isolation). AI could extend its role to provide (or attempt to provide) assistance in the spiritual realm. Virtual interaction platforms can offer patients responses for emotional and spiritual support. The adoption of chatbots for spiritual assistance is a growing sector, with various solutions already active or under development. Here are some examples:
- Replika: This platform was designed to provide a conversational experience, especially for those experiencing moments of isolation. Over time, it has been refined to assist individuals seeking digital interactions, ensuring 24/7 availability for conversations that simulate human dialogue.
- Text With Jesus: This is a chatbot app that allows users to ‘dialogue’ with biblical figures like Jesus, Mary, Joseph, and Peter, and is focused on Christian teachings drawn from the Bible. The app is free but offers a paid premium version and is compatible with iPhone, iPad, and Mac.
- Buddha Bot: This chatbot was created to represent and reflect the teachings of Buddhism, answering users' questions.
- Rabbi Anytime: Created to offer advice to members of the Jewish community, it operates 24/7 and can connect users with a consultant.
- Siwak: This Discord bot supports users during Ramadan, providing details about the religion and the fasting period.
We believe it is quite evident that the ‘dialogue’ referred to is generated by a language generator and is therefore distinctly different from the encounter and dialogue with the Transcendent that occurs in a logic of faith between the individual and God Himself. Another aspect is related to the ‘claims of eternity’. There are various websites, in fact, that offer the possibility to preserve and catalogue people's data to create a form of ‘digital immortality’ after their death.17 Enhanced by the advent of AI, they can allow the generation of new content related to the deceased person, simulating a sort of posthumous life in the digital world. If these representations can be of some potential use for relatives and friends to maintain a sort of special bond with the departed person, we believe it is important to remember that digital immortality, even the most advanced, cannot capture the true essence of the human being, which goes beyond data and information. In the face of these
innovations, the Christian faith emphasizes the importance of the spiritual dimension of existence and the intrinsic value of human life, which cannot be reduced to mere digital data. Technology, despite its promises, cannot guarantee true eternity, a concept that goes beyond human understanding and remains a mystery of faith.
Future perspectives: Closer than we think?
The future prospects of AI in the clinical field could potentially lead to healthcare systems where diagnoses and therapies are conducted by automatic programs. This is based on the assumption that decisions based on objective data, uninfluenced by the subjectivity of healthcare professionals, can improve diagnostic and treatment decisions.12,13 However, we believe that this is an extremely delicate area that requires extensive debate. Decision-making processes are exceedingly complex. In various sectors, systems are being developed that show aspects of efficiency but also critical issues. For example, questions are being raised about safety decision systems in autonomous vehicles, which in particular cases might be programmed to sacrifice the lives of the driver and passengers to avoid imminent road accidents. A healthcare system based exclusively on algorithms and AI could be efficient but present several serious ethical limitations. Below are some of the main points of concern:
- Empathy and human understanding: Algorithms and AI cannot comprehend or respond to patients' emotions, which can be particularly problematic in delicate or complex medical situations.
- Bias and discrimination: AI systems can inherit and perpetuate biases present in the data on which they have been trained, leading to discrimination or inequalities in access to care or its quality among different patient groups.
- Errors and supervision: Without human oversight, diagnostic or treatment errors generated by AI could go unnoticed, with potentially serious consequences for patients' health.
- Accountability (Responsibility): In a system managed exclusively by AI, it can be difficult to determine responsibility in the case of medical errors, complicating the resolution of legal and ethical disputes.
- Data privacy: Handling sensitive health data through AI systems can raise concerns about privacy and data security, increasing the risk of data breaches or misuse.
- Interpretability and transparency: Many AI algorithms are ‘black boxes’ that do not allow easy interpretation of the decision-making process, hindering the understanding and acceptance of proposed medical decisions.


Clerici et al. 9
- Patient autonomy: Patient autonomy could be compromised if medical decisions are made exclusively by algorithms, without the possibility of dialogue or discussion with healthcare professionals.
- Standardization vs individualization: Excessive standardization of care through algorithms may not take into account the individual specificities of patients, who may require a more personalized approach.
- Professional competence: Excessive reliance on AI could erode the competence and experience of healthcare professionals, making them less prepared to tackle unforeseen or new situations.
- Research and innovation: Medical innovation could be limited if algorithms become too rigid or conservative in their approach, or if they reduce the incentive for clinical research conducted by humans.
These limitations raise significant ethical questions—in real life and even more so in the medical field—that require careful consideration by policymakers, healthcare professionals, and society as a whole. AI platforms should be designed to ensure transparency, data security, and the ability for individuals to control how their information is used. Aspects related to patients' spirituality and health pastoral care are even more delicate, if possible. The search for the meaning of life influences the patient's expectations and attitude towards illness, suffering, the risk of death, and treatment. In past centuries, religion provided socially accepted answers to themes of life and death. Even today, for much of humanity, religions continue to address existential questions, albeit with significant changes compared to the past. It is clear today that pastoral care is not simply the provision of services and sacraments. It involves relationships, effort, and uncertainty that make the care pathway imperfect and, for this very reason, human. Algorithmic responses will not be able to solve the deeper issue of the meaning of existence, which remains entrusted to the uniqueness of individual journeys. We believe it is useful to highlight the Church's attention to these significant issues. As said by Monsignor Paglia, president of the Pontifical Academy for Life: In recent years, the Pontifical Academy for Life has shown a specific interest in new technologies and the ethical-anthropological questions connected to AI. It has done so primarily in response to the Pope's request, who has urged the Academy to enter the territories of science and technology and to traverse them with courage and discernment. Under this impetus, the RenAIssance Foundation was born—’a non-profit organisation with the objective of supporting the anthropological and ethical reflection of new technologies on human life’—and, in May 2023, the
Memorandum between the Pontifical Academy for Life and the Abu Dhabi Forum for Peace was established, aiming to promote a continuous dialogue that integrates the perspectives of technology, ethics, philosophy, and theology.
Conclusions
AI, since its inception, has evoked the human tendency to project intelligence onto communicating machines, despite their lack of true thinking capacity or empathy.18 This phenomenon is fuelled by human vulnerability to illusion. Interacting with voice assistants and chatbots stimulates the projection of human dynamics onto these technologies. It is therefore essential to maintain a critical approach to the ethical and social implications of AI. If AI is seen not as a divisive issue but as a subject whose pros and cons are to be evaluated, it can act as a bridge between technology and medical science, and thus between medical science and spirituality. It is important not to replace but to integrate human interaction with AI, valuing empathy and human support in care. AI shows promise in improving healthcare, but it is essential to consider ethical challenges, such as privacy and the humanization of technology. This requires investments in research, ethical guidelines, joint training of healthcare professionals and pastoral workers, and continuous evaluation of AI implementations.19 A multidisciplinary and ethics-centred approach can promote effective integration of this technology in care. Finally, in hospital pastoral care, AI can identify intersections between science and spirituality and quantify the impact of spiritual practices on health. Collecting experiences from professionals, pastoral workers, and patients is important to assess successes and areas for improvement, and to integrate AI ethically and effectively into personal care.
Declaration of conflicting interests
The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.
Funding
The author(s) received no financial support for the research, authorship, and/or publication of this article.
ORCID iD
Andrea Ferrari https://orcid.org/0000-0002-4724-0517
Note
For the preparation of this article, artificial intelligence systems ChatGPT-4o and Google Bard were used as aids for research and text revision. However, the responsibility for the text in every aspect, from drafting to publication, rests exclusively with the authors.


10 Tumori Journal 111(1)
References
1. Clerici CA, Quarello P, Bergadano A, et al. Proper use of social media by health operators in the pediatric oncohematological setting: Consensus statement from the Italian Pediatric Hematology and Oncology Association (AIEOP). Pediatr Blood Cancer 2018; 65: e26958.
2. Clerici CA. Ferrari A and Albasi C. Prime considerazioni sulle applicazioni cliniche dell'intelligenza artificiale di ChatGPT. Psichiatria e Psicoterapia 2023; 42: 53-64.
3. Stoddart E. Artificial pastoral care: Abdication, delegation or collaboration? Studies Christian Ethics 2023; 36: 660-674. 4. Young W. Virtual pastor: Virtualization, AI, and pastoral care. Theol Sci 2022; 20: 6-22. 5. Proserpio T, Piccinelli C and Clerici CA. Pastoral care in hospitals: a literature review. Tumori 2011; 97: 666-671. 6. Proserpio T, Ferrari A, Lo Vullo S, et al. Hope in cancer patients: the relational domain as a crucial factor. Tumori 2015; 101: 447-454. 7. Koenig HG. Role of the chaplain on the medical-surgical team. AORN J 2012; 96: 330–332. 8. Ferrari A, Clerici CA, Casanova M, et al. The Youth Project at the Istituto Nazionale Tumori in Milan. Tumori 2012; 98: 399–407. 9. Proserpio T, Ferrari A, Veneroni L, et al. Spiritual aspects of care for adolescents with cancer. Tumori 2014; 100: 130e-5e. 10. Proserpio T, Pagani Bagliacca E, Sironi G, et al. Spirituality and sustaining hope in adolescents with cancer: the patients' view. J Adolesc Young Adult Oncol 2020; 9: 36-40.
11. Proserpio T, Ferrari A, Veneroni L, et al. Cooperation between in-hospital psychological support and pastoral care providers: obstacles and opportunities for a modern approach. Tumori 2018; 104: 243-251. 12. Lee P, Bubeck S and Petro J. Benefits, limits, and risks of GPT-4 as an AI chatbot for medicine. N Engl J Med 2023; 388: 1233–1239. 13. Aung YYM, Wong DCS and Ting DSW. The promise of artificial intelligence: a review of the opportunities and challenges of artificial intelligence in healthcare. Br Med Bull 2021; 139: 4-15. 14. Clerici CA, Chopard S and Levi G. Ammalarsi di una patologia rara in tempi di intelligenza artificiale [Rare disease in the age of artificial intelligence.]. Recenti Prog Med 2024; 115: 67-75. 15. Clerici CA, Bernasconi A, Lasalvia P, et al. Being diagnosed with a rhabdomyosarcoma in the era of artificial intelligence: Whom can we trust? Pediatr Blood Cancer 2024: e31256. 16. Clerici CA and Proserpio T. Prospettive in evoluzione: il ruolo dell'intelligenza artificiale tra clinica e pastorale sanitaria. Tredimensioni 2024; 2: 125-136. 17. Ciucci A. Digitale, illusione di vita eterna Immagini e suoni, non persone. Avvenire, 2 November 2023, p.29.
18. Natale S. Macchine Ingannevoli: Comunicazione, Tecnologia, Intelligenza Artificiale. Giulio Einaudi editore. 19. Benanti P. Human in the Loop: Decisioni Umane e Intelligenze Artificiali. Mondadori Università, Milano 2022.