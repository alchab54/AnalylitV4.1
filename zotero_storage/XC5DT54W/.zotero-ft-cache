Journal of Electronics, Electromedical Engineering, and Medical Informatics Multidisciplinary: Rapid Review : Open Access Journal e-ISSN: 2656-8632
Homepage: jeeemi.org
Vol. 4, No. 1, January 2022, pp: 1-23 1
REVIEW ARTICLE OPEN ACCESS
Manuscript received December 21, 2021; revised January 5, 2022; accepted January 6, 2022; date of publication January 21, 2022 Digital Object Identifier (DOI): https://doi.org/10.35882/jeeemi.v4i1.1 This work is an open-access article and licensed under a Creative Commons Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0)
Artificial Intelligence: A Review of Progress and Prospects in Medicine and Healthcare
Saurav Mishra
Software Developer, Healthcare Domain
Corresponding author: Saurav Mishra (e-mail: Saurav.Mishra@live.com).
ABSTRACT Andrew NG, a leading philosopher in the field of Artificial Intelligence (AI) once quoted “AI is the new electricity” which has the potential to transform and drive every industry. The most important driving factor for the AI transformation will be data. Clive Humby, a data science entrepreneur was once quoted saying “data is the new oil” and data analytics being the “combustion engine” will drive the AI led innovations. The rapid rise of Artificial Intelligence technologies in the past decade, has inspired industries to invest in every opportunity for integrating AI solutions to their products. Research, development, and innovation in the field of AI are shaping various industries like automobile, manufacturing, finance, retail, supply chain management, and education among others. The healthcare industry has also been adopting the ways of AI into various workflows within the domain. With the evolution in computing and processing powers coupled with hardware modernizations, the adoption of AI looks more feasible than ever. Research and Innovations are happening in almost every field of healthcare and hospital workflows with the target of making healthcare processes more efficient & accessible, increase the overall state of healthcare, reduce physician stress levels, and increase the patient satisfaction levels. The conventional ways in which healthcare and clinical workflows have been operating are now starting to see the change with the integration of many data driven AI solutions. The digital innovations are making life easy for healthcare professionals allowing them to spend more time listening to the problems of patients and consequently increasing the patient satisfaction levels. However, there are limitations and concerns on security of Protected Health Information which have to be addressed for a seamless amalgamation of AI systems into the healthcare domain. Many papers have been published which mostly talk about one particular field/problem in the healthcare domain. No publications have covered the opportunities provided by AI technologies to the entire healthcare domain. This review paper discusses in detail about the progress AI has been able to make in the healthcare domain holistically and what the future of AI looks like. The paper also discusses about the implementation opportunities various AI technologies like Machine Learning, Deep Learning, Reinforcement Learning, Natural Language Processing, Computer Vision provide in different fields of healthcare and clinical workflows and how Artificial Intelligence systems will boost the capabilities of healthcare professionals in restoring the human touch in patient-physician encounters. A physician’s intuition and judgement will always remain better suited since each case, each health condition, and each person is unique in its own way, but AI methods can help enhance the accuracy of diagnosis, assist physicians in making improved and precise clinical decisions.
INDEX TERMS Artificial Intelligence, Digital Health, Medicine, Healthcare, Innovation, Electronic Health Records, Protected Health Information, Machine Learning, Deep Learning.
I. INTRODUCTION
Way back in 1976 Maxmen [1] in his study “The PostPhysician Era: Medicine in the Twenty-First Century” anticipated that physicians would become nonexistent and a number of mainstream workflows in healthcare will be taken
over by computers and machines [2]. Maxmen backed-up his words in another study [3] stating the change is very much possible and destined to happen centered around 3 fundamental factors – (a) memory, (b) objectivity, and (c)


Journal of Electronics, Electromedical Engineering, and Medical Informatics Multidisciplinary: Rapid Review : Open Access Journal e-ISSN: 2656-8632
Homepage: jeeemi.org
Vol. 4, No. 1, January 2022, pp: 1-23 2
probability at which computers are far from superior compared to humans. Those expectations appear to be gradually becoming a reality now. The healthcare domain has always implemented the innovations in the technology with a view to make the whole healthcare experience better, more accessible, and user-friendly to the public. General practices in the healthcare domain are slowly and steadily starting to shift gears towards adopting the techniques of Artificial Intelligence. In the recent times, fields within healthcare such as radiology, digital pathology, oncology are increasingly focusing on AI and computer vision to achieve the diagnosis of various health conditions and prognosis of certain short term expectancies. The successes of AI in various other industries and its ability to solve many challenging problems with human level performances, show that it could have a huge potential and opportunity to break into the healthcare domain and combined with its ability of achieve path-breaking innovations can achieve the human level performances for almost every clinical task at hand. Artificial Intelligence can prove to be far more efficient in performing time-dependent critical tasks effortlessly compared to humans owing its capacity to harness the innovations in computing hardware and computational powers. Given its success in various other industries, AI and its related technologies like Machine Learning (ML), Deep Learning (DL), Computer Vision, Natural Language Processing (NLP), and Reinforcement Learning (RL) will influence and play leading roles in driving the healthcare domain. As per a study from Markets and Markets research, the global AI in healthcare market size is expected to grow at a rate of 44.9% and reach $45.2 billion by 2026 [4]. A forecast study by Bhardwaj et al. [5] expect the total market value to grow up to $194.14 billion by 2030. Right at the start of the decade, AI and other healthcare technologies have shown their worth in reducing the effect of the pandemic globally. The Natural Language Processing segment will remain at the top of AI technologies and expected to grow at the rate of 36.9% through the decade. In terms of the application segment, the various application could be robot-assisted surgery, virtual nursing capabilities, clinical and administrative workflow assistance, medical imaging, diagnostic & prognostic applications, applications in the healthcare insurance and fraud detection, risk analysis, patient monitoring applications and other patient safety applications. Among these applications, robotic assisted surgery is expected to grow at the rate of 36.6% annually and reach a market of $50.98 billion by 2030 globally. A review of the end user segment in the healthcare AI domain reveals majority of the users would be one of primary healthcare professionals, pharma and biotech industries, patients, healthcare administrations and insurance portals. Out of these, the healthcare providers would see the maximum user base in the decade growing at the annual rate of 37.2%. The majority of work will be concentrated on improving the patient outcomes, prognostic and diagnostic activities and keeping Electronic Health Records is a much more
efficiently. Though the North American region has dominated the healthcare AI market until now, it is expected that the Asia-Pacific region will benefit the most through the decade growing at the rate of 44.5%. The major factors to contribute to this whooping growth and massive opportunities is the increasing amount of healthcare data generated everyday globally and given the complexity involved in dealing with unstructured healthcare data, calls for AI technologies to play a bigger role and potentially act as a seamless bridge between the physician and the patient. The enormous amount of data can help researchers across the globe to develop new applications aiming to improve the physician experience and patient care. AI technologies can also help in reducing the redundancy in various clinical workflows, assist healthcare practitioners in decision making and also provide an error free environment of patient care. Various AI technologies like machine learning, deep learning, computer vision, and natural language processing can be leveraged to make the best utilization of data in various fields of healthcare such as radiology, oncology, digital pathology, oncology, orthodontics. etc. for all diagnostics purposes, formulating the treatment plans, personalized medicines and health monitoring, drug discovery, and as well assisting the physicians in efficiently documenting the clinical notes by allowing to invest more in understanding the patient condition and outcomes. In the current healthcare situation globally under the influence of Covid-19 pandemic, it is seen that the healthcare infrastructure of almost every country has easily come under enormous stress. The use of AI could immensely help in reducing this infrastructural stress on the international community and stabilize the entire balance shift caused by pandemic. Consequently, this would lead to better outcomes by delivering accurate, timely diagnosis, and more precise treatment course and eventually save more and more lives.
A. IMPACT OF DATA IN HEALTHCARE
Data has turned out to be a game changer across industries with the deep vision it is able to provide which can easily get overlooked by humans. The amount of health data that is generated per day globally is breathtaking that quantifies in terms of petabytes to zettabytes on the data unit scale. Data is generated from almost every activity of a person’s daily routine. All the data that is generated from various sources is in one of the following forms - unstructured and structured clinical notes, transcription documents, electronic health records, biomedical images, videos from the radiology and pathology laboratories, electronic signals from the electrocardiogram and electroencephalogram devices, administrative data, data arising out the health surveys, data from clinical trials and clinical research., research and development activities from the pharmaceutical research and drug discoveries, medical prognosis and diagnostic activities, medical insurance claims, data generated from wearable devices, sensors and mobile applications, nutritional data, patient demographic data. Such is the bulk,


Journal of Electronics, Electromedical Engineering, and Medical Informatics Multidisciplinary: Rapid Review : Open Access Journal e-ISSN: 2656-8632
Homepage: jeeemi.org
Vol. 4, No. 1, January 2022, pp: 1-23 3
complexity, and diversity of healthcare data that it needs to be harnessed and dealt with utmost attention and clarity. This exponential growth of biological and healthcare data has given rise to the concept of advanced Precision Medicine [6]. Being able to understand how a person's genetics, environment, clinical phenotype, demographics, and lifestyle can help determine the best approach to prevent or treat disease is what precision medicine aims to achieve. The entire outcome and value AI systems are able to provide will entirely depend on how well these data are nurtured and maintained. Majority of the data generated is unstructured data in the form in the form of clinical notes, transcribed documents from physician’s dictation, emails between the patient and the physicians, data from social media. Digitization of healthcare data in the form of Electronic Health Records and Electronic Medical Records allows healthcare providers with a value-added access to the full medical history of the patient almost instantly. Electronic data opens a portal for seamless data communication and faster retrieval in all departments within a hospital network. This would eventually reduce the time required by the facilities on administrative, documenting work and spend more time on the patient care outcomes and satisfaction. Conversion of these enormous amount of big data in good data needs to be the most critical and focused aspect to transform healthcare into a data driven industry. To enable a smart efficient exchange of information, the patient related data needs to be shared in a secure channel. The Health Information Exchange (HIE) system enables exchange the electronic health/medical records securely and allows for a seamless coordination in the healthcare network. The HIE system enables physicians to have access to the most updated and complete information facilitating automated and machine-to-machine information exchange at lightning speed. This seamless communication and flow of information is all efficient because of the data standards developed for healthcare domain. As defined by Aspden et al., [7], “In the context of health care, the term data standards encompasses methods, protocols, terminologies, and specifications for the collection, exchange, storage, and retrieval of information associated with health care applications, including medical records, medications, radiological images, payment and reimbursement, medical devices and monitoring systems, and administrative processes”. Data standards are required for message format, clinical document architecture, template formats for clinical workflows, and patient data linkage. Some of the standard formats are the Health Level Seven (HL7) format for clinical messaging, Digital Imaging and Communications in Medicine (DICOM) for bio-medical images, Whole Slide Images (WSI) for digital pathology exchanges, National Council for Prescription Drug Programs (NCPDP) Script for retail pharmacy messaging, Institute of Electrical and Electronics Engineers (IEEE) standards for medical devices, and Logical Observation Identifiers, Names and Codes (LOINC) for reporting of laboratory results, ICD-10 Clinical Modification (ICD-10 CM) for diseases and diagnoses,
Clinical Document Architecture (CDA) for structured clinical documentation, RxNorm for clinical drugs. These standards will make it easier for a well-structured data analysis, unearth relevant information and hidden patterns, and derive good features that can be fed to the AI systems and algorithms. Good data features will make way for building an excellent AI system. Building a personalized healthcare system that revolves around the patient care, would need the valuable insights drawn from the data be made available to the patients such that they are completely aware of the underlying health condition and also recognize the various treatment options available to them with the view to play a role in determining a better care plan for themselves. With access to the patient’s system biological data, the realization of the P4 concept of medicine [8] will be very much achievable. The P4 concept envisions the predictive, preventive, personalized and participatory metrics. This will help is early prognosis and possibly prevent the occurrence of the disease. However, for healthcare facilities to become data driven organizations will need more time as this requires a major culture shift demanding the healthcare professionals to get trained on using data as a tool, understanding the data to extract any hidden insights, and take decisions by acting on this valuable information. These insights and understandings provided by data will have to be agreed by the healthcare professionals and also conveyed forward to the patients in a way that is easy for them to grasp and play a role in their health decisions. AI technologies have displayed they have the potential to become exceptional and irreplaceable, unveiling the complexity in medical data, analyzing, and drawing meaningful, detailed insights to help answer a few basic questions like “What causes infants develop cancerous conditions? or why do only a few people live over 100 years? or the short-term or long-term prediction for a person developing a particular health condition”, etc... Therefore, if harnessed and utilized with the precise methodology, data can help improve the state of healthcare and human health in general.
B. DATA PRIVACY - CONCERNS AND RISKS
Ensuring data privacy and security is crucial for the development and deployment of large-scale AI models in the healthcare domain. Integrating AI into the healthcare domain, would raise concerns on the data privacy and security for the patients Protected Health Information (PHI). AI systems require huge number of diverse types of data to train on. Such huge amount of digital data potentially leaves open gaps for data infringements. This is a challenge not only from the technological perspective but also in terms of the existing healthcare policies related to PHIs. AI algorithms are tightly dependent upon the quality and the quantity of data that are fed for training. To increase the amount of data in the pool, patient data is often shared between the clinical facilities [9]. A study by Aswani et al., [10] argue that advances in artificial intelligence technologies have already made the Health Insurance Portability and Accountability


Journal of Electronics, Electromedical Engineering, and Medical Informatics Multidisciplinary: Rapid Review : Open Access Journal e-ISSN: 2656-8632
Homepage: jeeemi.org
Vol. 4, No. 1, January 2022, pp: 1-23 4
Act of 1996 (HIPAA) obsolete. "HIPAA regulations make your health care private, but they don't cover as much as you think" [11]. The current policies do not ensure to completely safeguard individuals’ PHI with increased usage of AI systems. The increased risks ask for either updating the existing regulations or introduce new regulations to provide extra layer of protection to individuals health information in this era of artificial intelligence. Kaissis et al., [12] propose to develop smart systems in medical imaging using the “federated learning” technology and secure protocols that not only protects from data breach attacks but also secures the AI models through the techniques of encryption, secure aggregation, Anonymization, and Pseudonymization. The same authors is another related work [13] develop a secure and privacy preserving system that helps diagnose pneumonia conditions in children. The researchers point out the fact that clinics often share data by sending database copies to the facility where the AI systems are being developed. Kaissis et al., use the federated learning approach by sharing the AI algorithm instead of the asking for access to the data itself. They use a combination of multiple techniques like secure aggregation, encryptiondecryption, and differential privacy to prevent identification of the participating facilities. The models are securely aggregated in an encrypted format and are decrypted only after the training is complete at all the participating facilities. The central model is then updated with the securely aggregated models from each participating facility. During the inference phase, the Secure Multi-Party Computation protocol is utilized to provide Inference as a Service where both the data and the model are encrypted using secret sharing. Such secured and privacy preserving systems need to be encouraged and implemented more often if the healthcare system desires to be a completely data driven setup supported by smart AI solutions without compromising on the data privacy of the protected health information of patients.
C. AI IN HEALTHCARE INFRASTRUCTURE
Artificial Intelligence solutions, in today’s world, can be seen in various forms in all industrial domains and day-today life. Integrating AI technologies into the healthcare and clinical system is a challenging task given the amount of data that is being generated every day. Also, the heterogenous nature of healthcare data makes it even more difficult to incorporating AI with complete confidence. However, the industry is slowly and steadily starting to move towards being a data-driven system and apply artificial intelligence technologies to the clinical and administrative workflows. AI has the potential to change the patient experience, provider, or clinician experience, and transform the pharmaceutical industry, and clinical research operations. A number of research studies done in the field of disease diagnoses and using robots for machine assisted surgeries have shown promising results and suggests AI can perform at par or even better compared to humans, but it will for sure take more time before AI can be integrated to a broader range of clinical
workflows will full confidence. Given the heterogenic and diverse nature of healthcare data, it becomes a complex task to unearth the hidden patterns within the data and design good features that would enable the AI systems to deliver something meaningful. All of the AI applications in healthcare can be grouped into three major categories [14] 
• Patient-oriented AI • Physician-oriented AI • Administrative- and Operational-oriented AI
Patient-oriented AI revolves around the patient specific tasks and allows them to become a participant in their care plan. Patients can record their complaints and problem symptoms using smart applications and receive an in-depth personalized analysis of the underlying condition allowing them to play a part in deciding a better care plan for themselves. Wearable devices are now being used to collect vital data and provide real time analysis. Various smart watches are now able to record heartbeat rhythms and are able to generate an electrocardiogram reading allowing the users to monitor the heart condition and detect any irregularities. Such data analysis enables a person to stay up to date about their vital health parameters and take control of their well-being. Such applications paired with AI can help diagnose or prognose certain health conditions. Applications can also send personalized notifications reminding patients about their medications and respective dosages. Based on the physical activities of a person applications can recommend the users to get involved in certain physical exercise activities. Chatbots are other category of applications which start by collecting basic information from the patients about their condition, symptoms experienced and based on the input suggest the next possible course of action. With patient centric AI, humans are better equipped to take control of their health and also take part in deciding a better care plan for themselves. It also helps in crafting the concept of personalized healthcare and precision medicine a much likelihood. Physician-oriented AI revolves around the healthcare professionals and assisting them in various clinical workflows. Such applications could be assisting the lab clinicians to analyze bio-medical images, whole slide images in an efficient way, assisting physicians in documenting patient records by suggesting medical phrases and section of documents, assisting in nursing tasks with virtual nursing assistants, assisting physicians by providing a collective view of the patient health records. Many applications that assist physicians in various diagnosis/prognosis tasks, analysis of the patient history of illness and prior health conditions, designing the patient care plan, and assist in clinical decision making. Physicians would greatly benefit from AI applications since it would ease their tasks, avoid physician burnouts, and more importantly help them spend more time listening/interacting to the patients. Administrative- and Operational-oriented AI would revolve around automating various healthcare administration


Journal of Electronics, Electromedical Engineering, and Medical Informatics Multidisciplinary: Rapid Review : Open Access Journal e-ISSN: 2656-8632
Homepage: jeeemi.org
Vol. 4, No. 1, January 2022, pp: 1-23 5
and increase the operational productivity around tasks like billing, revenue cycle management, insurance claim processing, bed allocation management, ambulatory management, patient discharge process, hospital supply chain & inventory control management, and optimizing the various administrative documentation tasks that cause clinician burnouts. Clinicians often complain about being overburdened with administrative tasks resulting in burnout and decreasing efficiency. Integrating AI and process automation in these areas can optimize the entire process. The aim of this study is to review the existing state of the art methodologies in the field of AI that are currently being researched to transform healthcare into an industry which is powered by data, driven by machines and humans. The rest of the paper is organized into different sections involving Literature review discussing about the various research that have happened in the various fields within healthcare in the recent past, followed by Discussions which talks about the progress and future prospects of AI technologies in general and finally concluding with the end notes.
II. LITERATURE REVIEW
This section touch bases on the major AI technologies like the machine learning, deep learning, computer vision, NLP, and reinforcement learning that are currently being explored and researched to transform healthcare domain into a data driven industry. All the major research activities that have been carried out in various fields of healthcare ranging from Cardiology, Radiology, Ophthalmology, etc. to drug discovery, pandemic predictions, genomics are also discussed.
A. MACHINE LEARNING
Machine Learning (ML) algorithms are being explored and applied for numerous tasks is the clinical workflows ranging from disease prognosis, diagnosis, medical treatment, defining a care plan for the patient, and many more. Traditional ML approaches are one of the most common techniques for incorporating AI into healthcare and move towards implementing Precision Medicine initiative. ML algorithms like the Support Vector Machine has been heavily applied to study genomic data to detect the different variants of a trait or phenotype. Romagnoni et al. [15] study the performance of classical ML models to identify and classify Crohn’s disease. Traditional classification algorithms like Logistic Regression, Decision Trees, Random Forests have been heavily applied in various medical prognosis, diagnosis, and measuring effectiveness of a treatment plan. Prognosis refers to predicting the risk of a future event such as death and other adverse events like a heart attack or a stroke, which might be risks for patients who have a specific medical condition or for the general population. Diagnosis refers to identifying a disease or medical condition from the observed signs and symptoms. However, traditional machine learning approaches demand to extract good features that should be supplied to the algorithms for processing. For extracting good features from healthcare data, one needs to have a detailed domain disease specific biological level
knowledge. Additionally, since the features are hand crafted by humans, there is a possibility of an error occurring during the feature extraction phase. Such errors could hamper the training of models and cause the AI systems to malfunction.
B. DEEP LEARNING
As discussed above traditional ML approaches need good data features to deliver good performance. This could possibly be a limitation with the traditional approach. With the evolution of deep learning, the feature engineering phase is eliminated since the deep learning algorithms are able to extract good features and develop their own representations by themselves. With the enormous amount of health data being generated worldwide, Hinton [16] says given the enormous power in detecting the hidden patterns deep learning has the potential to transform the current state of healthcare to a more digital state driven by machines and data. Naylor [17] in his study summarizes some key factors that have been driving the adoption of AI and deep learning into the healthcare industry. These factors involve the number of bio-medical images being generated, digitization of the health records form paper based to electronic health records, capability of deep learning systems to scale into diverse datasets extracted from numerous sources, its ability to streamline healthcare providers and patients thereby personalizing the overall medicine and healthcare workflows for a safer experience. Healthcare researchers across the globe have started to leverage the power of deep learning to automate the processes involved in disease detection, treatment recommendation, personalized medications, gene sequencing, drug development with a view to improve the quality, efficiency, accessibility of entire healthcare sector and increase the patient satisfaction levels. This will only magnify the abilities and efficacy of the healthcare providers by automating the repetitive tasks thereby reducing any possibilities of an error occurring. A recent study by Esteva et al., [18] about the usage of deep learning in healthcare state that the technology is now enjoying a good amount of success and have been able to achieve physician level performance in various healthcare workflows and patient level diagnostics. The application of deep learning has mostly been limited to bio-medical image processing in the fields of radiology, radiotherapy, pathology, ophthalmology, oncology, etc. Though there have been instances of successful application in the domain, the implementation of deep learning systems is still in the initial stages and the complete adoption of digitized systems will take more time. This is mainly because the factors involved in arriving at a decision by the deep learning systems are not explainable enough and the model are not transparent enough to be integrated into healthcare systems with full confidence. There is still lack of huge amount of labelled data in the domain which can very well act as a limitation for successful implementation of deep learning systems. Deep learning systems are known to perform well attaining human level performance when trained on enormous amount of data.


Journal of Electronics, Electromedical Engineering, and Medical Informatics Multidisciplinary: Rapid Review : Open Access Journal e-ISSN: 2656-8632
Homepage: jeeemi.org
Vol. 4, No. 1, January 2022, pp: 1-23 6
C. COMPUTER VISION
Computer Vision involves analysis of biomedical images and videos. The major tasks involved in the analysis are related to object detection, image segmentation, and image classification. Biomedical images are generated form internal body scans in the field of radiology, oncology, pathology, dermatology to name a few. Medical vision and imaging help to create a representation of the internal organs, tissues, and other microscopic components to enable a more accurate understanding and diagnosis of the health condition. The rise of deep learning around the Convolutional Neural Networks has immensely benefitted the application of computer vision. Today, computer vision is immensely utilized in segmenting tumor locations, identifying cancer affected regions of interest, localizing internal wounds, detection of various diseases using Whole Slide Images, analyzing internal body scans to detect anomalies and spot irregularities inside the human body, etc... Few medical techniques that help generating such images are X-ray, Ultrasound, Magnetic Resonance Imaging, Computed Tomography, Positron Emission Tomography, Endoscopy, Thermography. Thermal imaging is also being utilized for early detection of breast cancer. Computer Vision is also being utilized for designing simulation based surgical platforms as an effective medium to teach surgical training and assess surgical skills without any risk to the patients [19]. The advances in the medical vision models can now estimate the amount of blood loss during surgeries by estimating the amount of blood and Hemoglobin mass left in surgical sponges [20]. Video based CV models are incorporated into endoscopy for lesion detection and diagnosis [21], [22]. CV models are now able to identify the distinctive phases during a surgical procedure to enable development of context-aware computer assisted systems by analyzing visual and temporal features learned from surgical videos [23], [24]. In addition to these innovations, numerous other research studies are inprogress within the medical computer vision space. These methods of computer vision are mainly non-invasive procedures which stands out as a big advantage over the traditional methods in disease diagnosis and anomaly detection.
D. NATURAL LANGUAGE PROCESSING
The field of Natural Language Processing includes studies involved in human language understanding, speech recognition, text analysis, text generation and translation. Since there are loads of text based documents written in the healthcare domain, NLP can be much utilized to systematically analyze these unstructured clinical notes, transcription based documents of patients and unearth relevant hidden insights from the data. In the pre Electronic Health Record (EHR) era, physicians mostly used natural language and unstructured format with jargons and short forms for taking notes on patients on paper. However, post migration to an electronic platform, and studies on the impact of EHR systems on the time spent for clinical documentation suggest physicians now spend considerably more time (~ 40
55% increase) in documenting and reviewing notes [25][27]. This not only causes additional burden to the physicians but may result in EHR burnout and administrative burden on them [28]. For a physician to manually go through the loads of documents is time consuming and could even miss out on some vital insights. Physician burnouts can lead to early retirement due to higher job dissatisfaction which directly impacts patient care and satisfaction with treatment plans. However, machines are able to review the notes in no time compared to humans, give voice to these unstructured clinical notes, and extract all the relevant insights allowing physicians to spend more time on the patient outcomes and care. Not only analyzing the unstructured clinical notes, but NLP can also be utilized to analyze the structured document based on the Clinical Document Architecture. NLP based applications can also provide much needed insights required for developing the personalized medicine concept centered around patient oriented AI. NLP can also be utilized to reduce the time spent for documentation of notes. Medical base NLP applications can be developed to suggest medical text phrases at real time when composing clinical notes into the EHR systems. Such smart compose systems (like Gmail smart compose [29]) will enable improve the patient care and outcome by enabling physicians spend more time patients [30], [31]. NLP systems can also help to synthesize very long notes and extract the most relevant points which would otherwise take a very long time manually. The prospect of NLP in healthcare is huge. Efficient incorporation of such smart systems will ease the documentation burden on physicians and enable them to spend more time for face to face interaction with the patients. This will improve the patient care by designing better treatment, care plan and consequently reduce the hospital revisits and readmission count making it a win-win situation for all.
E. REINFORCEMENT LEARNING
Reinforcement Learning (RL) is a sub-domain of AI where the system (agent) aims to learn and grow in behavioral decision making abilities by interacting with the surrounding environment and evaluating the reward earned from the interaction. The single most important goal of the RL agent is to optimize the long-term reward and improve the state by maximizing the rewards earned with every interaction with the environment. “RL tackles with sequential decision making problems with sampled, evaluative, and delayed feedback simultaneously”. According to the study by Yu et al., [32] RL can also function with inherent time delays where the long term-future reward is weighed more than short-term goals which makes it an alluring solution for the healthcare domain. A medical treatment is usually involving a sequence of decisions to determine the course of treatment type, drug dosage, or re-examination timing at a time point depending on the current health status and treatment history, with a long-term goal of improving or maximizing the patient’s health benefits for the future. Also given the fact that RL systems can find the optimal solutions or policies using only prior experiences, without requiring prior


Journal of Electronics, Electromedical Engineering, and Medical Informatics Multidisciplinary: Rapid Review : Open Access Journal e-ISSN: 2656-8632
Homepage: jeeemi.org
Vol. 4, No. 1, January 2022, pp: 1-23 7
knowledge of the mathematical model of the biological systems makes RL a suitable candidate for the healthcare industry. The RL application domains in healthcare can be broadly categorized into three main categories - (1) Dynamic Treatment Regimes (DTRs) in chronic disease or critical care, (2) Automated Medical Diagnosis, and (3) general domains such as resources allocation and scheduling, optimal process control, drug discovery, etc... DTRs as defined by Chakraborty et al., [33] are a sequence of decision rules that determines the ways to individualize treatments based on evolving treatment and covariate history. Such dynamic strategies are useful in handling critical care (sepsis, anesthesia, etc.) and chronic diseases (cancer, diabetes, anemia, hypertension, depression, etc.). Chronic diseases are generally known to last over a period of time which demands multiple medical assessments and continuous care. Such continuous care regimes are made up of a sequence of medical interventions to record the continuous changing health condition of the patient. The current health state of the patient would depend on the treatment given on the previous encounter. This makes the current state a dynamic state which is not guaranteed to stay the same over the course of time. RL is implemented to automate the formulation of optimal DTRs as per the conventions defined in the Chronic Care Model proposed by Wagner et al., [34] to assist the decision making in chronic diseases over the treatment course. RL application has been researched for many chronic diseases like cancer [35]–[43], diabetes [44]–[48], anemia [49]–[52], sepsis management [53]–[56], mental diseases [57]–[59]. RL has also been studied for application of DTRs in managing critical and intensive care units, and anesthesia dosage control. Automated Medical Diagnosis refers to the process of mapping the current patient information and treatment history to the correct disease profile. This is a complex task in terms of the clinical context that requires intensive medical investigation causing mental burden on the clinicians and can even lead to diagnostic errors. Diagnostic errors may cause impairment to patients by either stopping or delaying correct treatment, providing unnecessary treatment, or causing unnecessary mental or economic burden [60]. The problem of diagnosis can be solved by supervised machine learning algorithms however, such methods require huge amount of labelled data for training. Various researchers now refer clinical diagnosis as a sequential decision making process which can be solved by RL methods using only a small amount of data [57]. Fakih et al., [61] proposed a RL based model to suggest appropriate diagnostic tests. Many Deep RL based methods have been proposed using Deep Q-Networks for segmentation, localization, and diagnosis of cancerous tumors, breast cancer surveillance, lung nodules classification on image data extracted from MRI and CT scans. Additionally, RL methods are also being applied in drug discovery [62], [63], health resource scheduling, and health management to promote physical activities [64], weight management [65]. With all the above literature and research done, RL seems to be a good choice for automating many healthcare workflows.
However, there remains many challenges in the real time adoption of RL like - (1) the heterogeneity of medical data is a major blockage for defining consistent State-Action pairs and define effective policies. (2) formulating a good reward function which not only balances the short-term improvements but also aligns the same with the long-term goal e.g., the long term reward of survival or death would be a very long sequence of events where the short-term goals may keep fluctuating with time. (3) RL requires its policies to be validated via the off-policy evaluation technique which is not feasible in the healthcare setting since it would require to test the policies by placing patients to go through empirical treatments which could pose a high risk. (4) Human body is a very complex system where not everything can be studied at the same time. This partial observability of healthcare data at time intervals is a problem complex enough to implement RL systems in a real time setting. (5) As seen in case of chronic disease that take a long time to cure where each treatment given may or may not improve the condition. This becomes a challenge for RL since the systems rely on credit assignment to decide if a particular action was good or bad in the perspective of the long-term goal. Since the long term goal in medicine could take much longer times, it becomes difficult to adding credits at each time step. However, with all these definite limitations, RL poses a bright future in optimizing healthcare workflows and decision making scenarios with the existing theoretical knowledge we have and practical research in progress.
F. MODEL INTERPRETABILITY & EXPLAINABILITY
Model Explainability should be a pre-requisite to designing trustworthy AI systems. Interpretability or Explainability is a concept that enables humans to understand the process and factors involved in computing the output of an AI model. Model Explainability basically helps to interpret the output in a way that makes sense to the users using the AI systems. AI models are often considered as black-box computing complex calculations to arrive at a decision which do not make sense to end users. This lack of transparency could have severe implications and may lead to losing end users trust if the decisions are not interpretable. In a healthcare environment ability to explain the physician’s decision or patient outcome is the most important factor that can make or break patient trust. A physician spending more time interacting with the patient, explaining them about their condition, educating them with the possible ways treating the condition and the pros and cons of the different treatment plans and as well making the patient play a part in deciding the next course of action and treatment. All these factors help in building a transparent relationship with the doctors and the patients become more confident with the care and care plans. With machines and AI systems, this kind of a transparent interaction is not possible. A machine on the other hand could compute highly complex calculations in a real quick time and correctly arrive at a decision, suggest a care plan, or diagnose a condition, but the decisions would not be explainable enough to


Journal of Electronics, Electromedical Engineering, and Medical Informatics Multidisciplinary: Rapid Review : Open Access Journal e-ISSN: 2656-8632
Homepage: jeeemi.org
Vol. 4, No. 1, January 2022, pp: 1-23 8
establish the physician/patient trust on the machine. Lack of transparency would be a major roadblock in the adoption of AI systems into the healthcare domain. To ensure that the best healthcare facilities implemented with the state-of-theart smart AI technologies are available to the patients, the models need to be explainable, trustworthy, their decisions are easily interpreted, and understood by the physicians as well as the patients. Additionally, the way the model explanations are conveyed to the end users must be designed with utmost care. Ahmad et al., [66] discuss that physicians are already overwhelmed with data generated for multiple patients and if the model interpretations are not conveyed in the correct manner which reduces their burden, it would just be another piece of data in addition to the existing data. The explanations should be easy to interpret, user-centric, and specific to the intended use case. For example, an AI system predicting the survival expectancy of a person will have more strict and detailed explanation requirements than an AI system for administrative tasks. According to Teredesai et al., [67] the foundation of designing explainable healthcare AI systems should be laid on the following pillars of (1) decision transparency, (2) domain sense - the explanations should be in perspective of the healthcare setting, (3) Consistency - the explanations should be consistent across various runs of the model, the explanations should be similar across different explainable algorithms (4) Parsimony - the explanations should be simple (5) Generalizability - model and explanations should be generalizable across problem (6) Trust/Performance - the model should be performing at a certain defined level. (7) Fidelity - the model and the corresponding explanation should get along well complementing each other. Linear models like decision trees and Generalized Additive Models support explainability by design. The outputs of all these models can be explained by understanding the variables and data features involved in the decision making. In addition, a few different techniques have been designed to interpret the factors involved in the decision making process for complex models - (1) Partial Dependence Plots generate a visual illustration of how each feature impact the final outcome with other features kept constant. (2) Individual Condition Expectations plots generate local representations of how a particular feature impacts the target feature. (3) Accumulated Local Effects [68] capture the relationship between the features variables with the target by partly isolating the effect of other features. (4) Local Interpretable Model-Agnostic Explanations [69] generate explanations monitoring the effect of input feature perturbations on the model output. (5) SHapley Additive exPlanations [70] assign a importance value to each feature based on the average marginal contribution it has on the model outcome. (6) DeepLIFT (Deep Learning Important FeaTures) [71] is an attempt to explain the behind the scenes work of deep learning systems via backpropagation to find neurons and weights that have major impact on the output. (7) Layer-wise relevance propagation [72] relies on a set of rules during backpropagation to identify the most impactful
neurons in the deep learning system. (8) GradCAM [73] and GradCAM++ [74] are techniques specific to convolutional networks that are able to generate visual explanations based on the gradients flowing into the final layer to generate a localization map highlighting important regions in the image that the model used to arrive at a decision. As more and more clinical workflows are on the path to adopt the AI way, these techniques will bring in a massive boost to the adoption of AI by making the machines more interpretable and trustworthy. The technique using which the machine would explain its decisions will depend on the nature of the clinical workflow and use case. Model explainability combined with the physician’s assessment of the patient condition will make the healthcare experience better and enable AI systems to become more trustworthy and safer for use in real time.
G. AI USE CASES IN HEALTHCARE INDUSTRY
Healthcare applications based on Artificial Intelligence are already proving to have a positive impact in various healthcare fields like radiology, pathology, ophthalmology, oncology, and cardiology. Most of these applications are designed to provide quick and accurate disease diagnosis, prognosis, bio-medical image analysis, clinical decision support system, drug discovery, personalized healthcare and medicine, smart medical devices, robotic surgery, and many more. In this section we look into a detailed aspect of such applications in various clinical settings and healthcare workflows.
1) RADIOLOGY
Radiology is that branch of medicine which utilizes biomedical images for detailed analysis to diagnose and treat various health conditions. The bio-medical images are extracted out of body scans such as X-rays, CT, MRI, PET. Radiology as a branch of medicine is divided into diagnostic radiology and interventional radiology. Diagnostic radiology involves non-invasive diagnostic techniques to locate and identify internal anomalies in human body. Interventional radiology uses minimally invasive techniques to diagnose and treat cancer and other health conditions. The images generated by radiology scans contain large number of complex images in the DICOM format which can take up a long time for humans to analyze and identify any anomalies. AI and Computer Vision methods can analyze these images accurately in a real quick time. This will not only save valuable time of the radiologists but also increase their efficacy in playing a part to provide better care and treatment plan in a timely manner. Geoffrey Hinton was once quoted saying “if you work as a radiologist, you're like the coyote that's already over the edge of the cliff but hasn't yet looked down so doesn't realize there's no ground underneath him. People should stop training radiologists now. It's just selfevident that within five years, deep learning is going to do better than radiologists; we've got plenty of radiologists already” [75]. Many researchers have applied deep learning


Journal of Electronics, Electromedical Engineering, and Medical Informatics Multidisciplinary: Rapid Review : Open Access Journal e-ISSN: 2656-8632
Homepage: jeeemi.org
Vol. 4, No. 1, January 2022, pp: 1-23 9
and vision methodologies to study radiology images for various diagnosis and treatment cases. Chiwome et al., [76] discuss the potential use cases and limitations of AI in radiology. Lugo-Fagundo et al., [77] argue the importance of the quality and quantity of the training data used to create state-of-the-art deep radiology models and the need to have a standard process and best practices guidelines in place for coming up with cleaner datasets. Lakhani et al., [78] use deep neural networks to learn the tuberculosis positive and negative images utilizing HIPAA compliant chest radiographs datasets achieving equivalent human level performance with 96% accuracy. Kooi et al., [79] study the performance of traditional CAD systems and CNNs for detection of mammograph lesions. Neural networks outperformed the conventional CAD systems reaching radiologist level performance. Pontabry et al., [80] analyze the fetal brain MRI images to study the process of cortical folding and brain maturation using techniques of Principal Component Analysis. Wang et al., [81] compare the performance of various CNNs for differentiating the malignancy risk of lung nodules. Researchers at Google McKinney et al., [82] develop a mammography screening system to detect breast cancer at very early stages which beat human radiologists by an absolute margin of 11.5%. With all the innovations happening with AI, this will help the radiologists perform in a more efficient manner and contributing their part in improving the state of overall healthcare.
2) PATHOLOGY
Pathology is that branch of medicine which studies the cause and nature of diseases by examining cells, tissue samples, body fluids in the laboratory for an accurate diagnosis. The traditional process involves examining the samples under the microscope. The time taken for the successful examination of the samples could vary depending on the skillset and experience of the pathologist. Given the various types and sub-types of a disease and with the criticality involved in studying and diagnosing the bio-specimens, required highly skilled pathologists who need to understand each and every aspect of these diseases. Additionally, the various different kinds of existing and new biomarkers, genomics, metabolomics information, and the set of specialties in biochemistry, microbiology, hematology, and histopathology causes a tsunami of knowledge and information to be processed by the pathologists. Jill [83] says all these demands a grueling amount of effort and may even cause burnout. There is also a decreasing trend seen in the pool of expert pathologists which affects the healthcare facilities in low and mid-level income countries and may even lead to failure of the entire healthcare infrastructure [84]. This is where digital pathology comes to rescue. As per the digital pathology association “Digital pathology is a dynamic, image-based environment that enables the acquisition, management and interpretation of pathology information generated from a digitized glass slide.” [85]. Digital pathology enables analysis of the digitized glass slide
using image analysis tools and the result could be confirmed by a pathologist. The DICOM standards have been upgraded to make Whole Slide Images compatible with the DICOM specifications and ensure pathologists are able to use the Picture Archiving and Communication System (PACS) software to view, display, store and share the WSI images as per Singh et al., [86]. Different researchers have explored the implementation of AI techniques to Whole Slide Images. Pantanowitz et al., [87] discuss about the potential contribution of deep learning in digital pathology and believe digital systems should be built in a way that the algorithm and data work in synchronization. The most path breaking development from the researchers at Google health [88] is the detection of metastatic breast cancer by analyzing the images from the lymph node tissue performing better than human pathologists. Mouiee et al., [89] explore the usage of CNN for categorizing retinal degeneration into three different classes using retinal histological images. Pantanowitz et al., [90] utilize deep learning methods to analyze prostate core needle biopsies to aid in prostate cancer diagnosis. Mishra [91] utilizes an efficient snapshot ensemble technique to detect the presence of malarial parasite from images of thin blood smears. Arrastia et al., [92] explore UNet based deep learning architectures to assist dermatopathologists in segmenting out and mark the critical regions that have a high probability of developing basal cell carcinoma. Lin et al., [93] use deep learning to diagnose thyroid cancer using cytological whole slide images. All these innovations and research activities happening in the digital pathology space, will eventually make the life of pathologists better and help to become more efficient.
3) OPHTHALMOLOGY
Ophthalmology is that branch of medicine which studies conditions relating to the eye. Various research activities are currently in-progress in the field of ophthalmology to diagnose conditions of diabetic retinopathy, macular degeneration, glaucoma, retinopathy of prematurity, agerelated or congenital cataract, and retinal vein occlusion. Diabetic Retinopathy (DR) is one of the major causes of permanent blindness. Yun et al., [94] use a 3-layer feed forward neural network to classify DR into normal retina, moderate non-proliferative diabetic retinopathy, severe nonproliferative diabetic retinopathy and proliferative diabetic retinopathy. Schlegl et al., [95] implement deep learning methods to detect and quantify intraretinal and sub-retinal fluid to improve accuracy and reliability of retinal diagnosis. Bhardwaj et al., [96] apply ensemble based deep learning methods to localize the optical disc and automate the process of DR grading for an early diagnosis. Bajwa et al., [97] apply region based CNN to extract the region of interest for optical discs and classify glaucoma. Alyoubi et al., [98] use twostaged deep learning system based on the YOLOv3 [99] architecture to detect, localize and classify DR lesions. Age related macular degeneration (AMD) is an irreversible condition majorly characterized by retinal pigment changes, choroidal neovascularization, hemorrhage


Journal of Electronics, Electromedical Engineering, and Medical Informatics Multidisciplinary: Rapid Review : Open Access Journal e-ISSN: 2656-8632
Homepage: jeeemi.org
Vol. 4, No. 1, January 2022, pp: 1-23 10
and is one of the major causes of vision loss with increasing age. Since AMD is asymptomatic, it may go undetected during the early stages. This calls for robust systems in place for pre-screening and early detection of the condition. Many works are being carried out to automate the diagnosis of AMD. Burlina et, al., [100] use deep CNN architectures and transfer learning to automate the analysis and detect the severity of AMD. The same researchers in another study [101] perform a 5-year risk estimation for progression to the advanced stages. Mookiah et al. [102] study the performance of several machine learning classifiers in diagnosing AMD. Retinal Vein Occlusion (RVO) is a condition where the blood flow to the retina in blocked leading to hemorrhage and fluid leakage from the blocked blood vessels leading to loss of vision. Zhao et al., [103] propose an image patch based voting method built using CNN to detect RVO. Chen et al., [104] extract the hierarchical local binary patterns and features from fundus images from RVO classification. Similar research works are being explored to assist ophthalmologists in other areas and conditions of the eye. AI assisted smart systems to explore the opportunities in ophthalmological image processing based on the fundus images to ease the work of ophthalmologists are widely being researched. Such systems can prove to be an assisting tool to the eye specialists during mass eye screening programs to diagnose various eye conditions.
4) CARDIOLOGY
Cardiology is that branch of medicine which studies the conditions and diseases related to the heart. Cardiology provides vast opportunities for applying AI techniques into the critical healthcare workflows. Cardiovascular workflows demand real quick data processing capabilities for delivering better and fast treatment outcomes especially during emergency scenarios. AI systems can play a huge role assisting in predicting the short/long term risk of developing heart disease, attacks, treating strokes faster, monitoring the functioning the heart and suggesting preventive measures in case any irregularity gets detected. Various research activities have been undertaken to explore the application of AI into cardiovascular workflows. Weng et al., [105] use machine learning to improve the prediction of developing a cardiovascular risk. Dawes et al., [106] explore supervised mechanisms to accurately predict ventricular failure and patient survival mechanisms by studying patterns of systolic cardiac motion. Attia et al., [107] develop an AI based electrocardiograph device implementing CNNs to identify the electrocardiograph (ECG) signatures that relate to atrial fibrillation during normal sinus rhythm. Atrial fibrillation is usually associated with stroke, and heart failure. Galloway et al., [108] develop a deep learning model to detect the condition of hyperkalemia from the ECG signatures. Hyperkalemia is the condition where the potassium levels are higher than normal in the blood. Krittanawong et al., [109] asses the overall predictive power of ML techniques in cardiovascular diseases and learn that SVM, boosting algorithms and CNNs show promising results. Kwon et al.,
[110] develop a deep learning enabled ECG devices that enable early detection and screening of anemia. AI has a huge potential in the branch of cardiology. A study by a group of researchers from UK [111] show that neural networks give correct predictions on 7.6% more events and raise 1.6% less false alarms compared to the current best practice guidelines. These results encourage to incorporate AI assisted devices into healthcare in general and will also help in dealing with emergency situations in a safer and risk free manner.
5) NEUROLOGY
Neurology is that branch of medicine which studies the nervous system and the various conditions related to the central nervous system comprising of the brain and the spinal cord. There are numerous characteristics of the human brain that still seem hazy and are not very well understood. The progresses made by the AI technologies can help unlock the hidden capabilities of the brain and enable neuroscientists and researchers to build better simulations of the human brain. AI can help study the hidden mysteries of the brain and its underlying mechanisms in a much deeper and time efficient way. Computer Vision can enable neuroscientists to recreate the actual neural linkages to establish their concept of working from a genomic perspective. AI can also help in the research of functional brain mapping. Researchers from Japan Gutierrez et al., [112] used machine intelligence based on CNN to accelerate and improve the correctness of an effective brain connection mapping technique. AI can assist in the branch of neuro-oncology for assessment and diagnosis of brain tumors. Kickingereder et al., [113] develop a tumor segmentation model based on neural networks that can assist in accurately localizing the tumor region of interest. Emblem et al., [114] implement support vector machine to predict the survival period for preoperative glioma and were correctly able to predict survival period between 6 months to 3 years. AI is also helping in analysis of neurodegenerative diseases like the Parkinson’s and Alzheimer’s. Karabayir et al., [115] compare several machine learning algorithms on Parkinson’s dataset and results showed that light gradient boosting outperformed every other approach. Xu et al., [116] use statistical modelling and machine learning for a rigorous quantitative analysis and layout a standard workflow for Parkinson’s diagnosis using brain MRIs. Bakkar et al., [117] utilize the AI based IBM Watson tool to analyze previously published studies related to binding proteins and Amyotrophic Lateral Sclerosis (ALS) to record the RNAbinding proteins that are altered in the event of an ALS condition. Chien et al., [118] propose a novel system built using feature sequencing and bidirectional Recurrent Neural Network for assessment of the Alzheimer’s disease. Cognitive Neurosciences at Cambridge University designed an AI based assessment test [119] to detect very early stages of cognitive deterioration and probability of developing Alzheimer’s. Researchers have applied AI for detecting neurovascular conditions. Nagamine et al., [120] implement


Journal of Electronics, Electromedical Engineering, and Medical Informatics Multidisciplinary: Rapid Review : Open Access Journal e-ISSN: 2656-8632
Homepage: jeeemi.org
Vol. 4, No. 1, January 2022, pp: 1-23 11
CNN based model to segment out the region of interest for Intracerebral Hemorrhage detection. Bentley et al., [121] develop a proof-of-concept using SVM to automate stroke prediction using brain CT images while Fernandez-Lozano et al., [122] implement a random forest based model to estimate the mortality/morbidity outcome over a time period. Researchers from the University of Cambridge say “Detailed assessment of a CT scan with annotations can take hours, especially in patients with more severe injuries,” and develop a multi-class classification tool based on neural networks [123] to segment the region of interest of multiple different types of lesions in the event of a Traumatic Brain Injury (TBI). Raj et al., [124] develop a logistic regression based system to predict the 30-day mortality following the event of a TBI. Spinal cord injuries are often very critical and have unpredictable consequences. Injury to any part of the spinal cord could lead to permanent or partial paralysis to either a part of the body or the entire body depending on the seriousness of the injury. Other symptoms could include decreased sensation, weakened control of the bladder, bed sores, and other mental health issues. AI is enabling paralyzed patients type out an email or play musical devices like the piano by decoding electrical pulses and signals using the brain-spine interfaces powered by artificial neural network which could learn over time, predict, and initiate the correct intended behaviors for the patient. Researchers from Intel and Brown University are using AI powered chips by recording sensory signals and pulse generated by the spinal cord and use these data to train a neural network to simulate body movements in a paralyzed patient and re-establish bladder control [125]. Thus, there are various use cases in which AI can help in the field of Neuroscience. AI has the potential to enable paralyzed patients perform movement and actions that were once deemed impossible. Based on the ongoing research in this field, AI can massively contribute towards mental wellbeing of humans. Additionally, Initiatives like the Neurodata Without Borders [126] help to generate invaluable sources brain data for neuroscientists to build smart analysis tools to analyze neuro data across multiple formats.
6) DENTAL SCIENCE
Dentistry is that branch of medicine which studies the diagnosis and treatment of diseases, and conditions of the oral cavity involving the development and arrangement of teeth, the oral mucosa, and other tissues surrounding the jaw area. AI has the capability to modernize the conventional facets of dentistry and can have various applications in the field ranging from diagnostic dentistry, orthodontics, periodontics, endodontics, to oral pathology. Orthodontics is the study of dentistry that treats malocclusion, which is the teeth not being correctly positioned when the mouth is closed. Accurate diagnosis and care plan are the most important factors influencing the success of an orthodontic treatment and AI can play a major player for a successful treatment plan. Periodontics is the study focusing on the inflammatory disease that destroys the gums and other
supporting structures around the teeth. Periodontal diseases are one of the major reasons for early tooth loss. Endodontics is the study of the inner part of the tooth or the dental pulp. Various research activities have been carried out to demonstrate the capabilities of AI in dental science. Saghiri et al., [127], [128] utilize artificial neural networks (ANN) to locate minor apical foramen using 36 morphological features extracted from teeth radiographs and conclude that ANN are more reliable and accurate compared to endodontists findings using stereomicroscope. Kilic et al., [129] develop a deep learning system to detect the number of deciduous teeth in children. Jung et al., [130] develop a smart system based on neural network for detailed diagnosis of tooth extractions for orthodontic treatments. Johari et al., [131] implement probabilistic neural network for diagnosis of vertical root fractures using CBCT radiograph images. Tobel et al., [132] use the transfer learning approach to estimate the dental age by analyzing the development of lower third molar utilizing panoramic radiographs. Aubreville et al., [133] use deep learning to diagnose Oral Squamous Cell Carcinoma & classify the cancerous tissues using Confocal Laser Endomicroscopy images. Imangaliyev et al., [134] apply CNN to diagnose and classify dental plaque using Quantitative Light-induced Fluorescence images. Lee et al., [135] design a CNN based system for diagnosis and prediction of teeth that are periodontally compromised. Calalegno et al., [136] perform a semantic segmentation task to mark out the region of interest in case of dental lesions using near-infrared transillumination images which have proved to be effective in early diagnosis of lesions. Hiraiwa et al., [137] utilize CBCT images to classify the root morphology of the distal roots of mandibular first molars using a 5-fold cross validation scheme on deep learning system. The automated system showed significantly improved performance compared to radiologists. Ariji et al., [138], [139] are one of the first researchers to contribute towards the diagnosis of cervical lymph node metastasis for oral cancer using deep learning systems. Krois et al., [140] implement CNN based system to identify the loss of periodontal bone that may lead to tooth loss using panoramic dental radiographs. The few studies highlighted above showcase the role of AI in the field of dental science in the recent years. In dentistry, accuracy and precision are very much necessary as the overall facial structure is affected by the dental alignment and AI is playing a major role in improving the diagnosis accuracy, predicting the treatment prognosis, and dental decision support system for laying out the best treatment and care plan for the patients.
7) OBSTETRICS AND GYNECOLOGY
Obstetrics is the branch of medicine that deals with pregnancy, childbirth, and the postpartum period. Gynecology is the branch of medicine that deals with the health of the female reproductive system. Obstetrics and gynecology are combinedly studied within the surgical field and commonly referred as OB/GYN. The domain of


Journal of Electronics, Electromedical Engineering, and Medical Informatics Multidisciplinary: Rapid Review : Open Access Journal e-ISSN: 2656-8632
Homepage: jeeemi.org
Vol. 4, No. 1, January 2022, pp: 1-23 12
OB/GYN directly relates to a woman’s physical and emotional wellness and the field itself goes through numerous challenges to not only improve the state of clinical care being provided but also improve the well-being of women in general. The complexities involved in gaining a complete understanding of the fetal functioning and physiology, fetal heart rate, intricacies in understanding the reproductive and gynecological cancer makes this a demanding field. All these factors enable AI to enter this field with an opportunity to provide the physicians with a detailed and accurate understanding of the complexities in this field. Several research activities have been conducted with a view to gain much in depth understanding of the various pathophysiological processes in the field and consequently contribute towards and improve women health and wellness. In the case of ovarian cancer, MicroRNAs are known to modify the message encoded in the genomes which makes diagnosis difficult in the early stages of cancer. Researchers from the Brigham and Women’s Hospital and Dana-Farber Cancer Institute, Boston use the predictive power of AI and neural networks [141] to analyze huge amount of microRNA sequence to study the composite relations differences between the tumors of ovarian cancer, benign tumors, non-invasive tumors, and healthy tissues. AI has been utilized for ovarian cancer diagnosis and prognosis by Enshaei et al., [142] by implementing an Artificial Neural Network. Their algorithm was correctly able to identify the complex interactions that are indicative of the early stages of ovarian cancer. Kawakami et al., [143] and Akazawa et al., [144] experiment with several machine learning algorithms to develop a framework specific to diagnose/prognose ovarian cancer. Holmstrom et al., [145] study the feasibility for Cervical cancer screening via a cloud based deep learning system and using whole slide images of Papanicolaou smear samples. Shanthi et al., [146] develop a multi-class classification system based on CNN to automate the pap smear cervical screening for cancer diagnosis. Araujo et al., [147] develop a cell-segmentation framework based on CNN that works on the probability of finding anomalies in the cellular image regions. The WSIs that have a higher number of anomalies detected are flagged for a detailed analysis by an expert cytopathologist. Wang et al., [148] design a deep learning system based on the VGG16 architecture to analyze the pap smear WSIs and quantify the presence of high-grade squamous intraepithelial lesion and invasive squamous cell carcinoma. AI is also assisting surgeons in performing gynecological surgeries. AI and computer vision supported systems provide surgeons with pre-operative 3D images of the areas in and around the surgical region [149]. Computer vision models based on augmented reality are now making their mark in gynecological surgeries by reducing the human limitations, increasing the spatial awareness, and providing hidden insights about internal organs by enabling the surgeons to reach places that are otherwise not possible and associated with risks. Such techniques not only reduce the time taken for the procedures but also reduce errors and improve patient safety [150].
In the field of Obstetrics, AI enables an efficient monitoring of the Fetal Heart Rate (FHR), screening for gestational diabetes mellitus, identify the cases of preterm labor in women of shortened cervix, and areas such as In Vitro Fertilization (IVF). FHR monitoring measures the heartbeat rhythm of the fetus and is a critical parameter from the baby’s perspective. It helps the doctor diagnose any risk related to gestational diabetes, high blood pressure, preterm labor, or the overall growth of the baby that could become a problem for the mother and the baby. Zhidong et al., [151] propose a CNN framework for FHR monitoring by analyzing 2D time-frequency images obtained from continuous wavelet transform of the heart rate signals. Jianqiang et al., [152] implement three different classification algorithm for FHR classification into normal, suspicious, and abnormal classes. Kazantsev et al., [153] develop a eHealth portal based on neural networks that would enable remote monitoring of the FHR, to ensure early detection of any risk that could develop during the term. The AI based doppler device is able to process, analyze the pulse signal and heartbeat pattern recognition. The device is also smart enough to discard unwanted signals (again using AI) that could arise due to the movement of the fetus. Gestational Diabetes (GD) is considered a high-risk event during the course of pregnancy. It could cause high blood pressure and preeclampsia. If not detected and controlled early, it could become adverse and critical consequences to both mother and the baby. Additionally, these complications could force the physicians to take the decision for cesarean birth. AI methods have been researched and utilized for the early detection of GD. Liu et al., [154] implement the gradient boosting algorithm for early prediction of GD using clinical parameters like body mass index, maternal age, fasting glucose, and alanine aminotransferase. Shen et al., [155] test 9 different machine learning algorithms on data featuring age and fasting blood glucose parameters. The model based on Support Vector Machine outperformed the other models. Wu et al., [156] crave out a 17-variable (17v) and 7-variable (7v) datasets from pregnancy data from the 1st trimester and experiment with 4 machine learning algorithms. The 7v models performed better compared to the 17v dataset with the 7v logistic regression turned out to be the best performing with respect to the real time clinical settings. These methods enable the accurate prediction of the onset of GD in early pregnancy and help to avert any associated risks. Preterm birth is defined as babies born alive before the completion of the full term (37 weeks) of pregnancy. As per the World Health Organization, approximately 15 million babies are born preterm. Preterm birth poses huge complications in babies and can be fatal if not properly cared for until the age of 5 years. AI has been used by many research groups and analyzed if preterm can be predicted early enough to assist the clinical staff and pregnant women to avoid the risk and complications of a preterm birth. Lee et, al., [157] analyze the effect 14 different clinical parameters by feeding them to various machine learning algorithms.


Journal of Electronics, Electromedical Engineering, and Medical Informatics Multidisciplinary: Rapid Review : Open Access Journal e-ISSN: 2656-8632
Homepage: jeeemi.org
Vol. 4, No. 1, January 2022, pp: 1-23 13
Artificial Neural Network turned out to be the best performing model while the top three important factors in predicting preterm were BMI, hypertension, and diabetes mellitus. Raja et al., [158] propose a novel feature selection and prediction framework to predict the risk of preterm birth where SVM turning out to be the best fit classifier. These results suggest that AI can help predict the risk of a preterm occurrence which would help the clinicians administer the preventive care and avert the associated risks to the mother and the baby. IVF and embryo-transfer techniques have been in existence for a long time now. However, the success rate still remains relatively low. AI technologies can improve the process of IVF by predicting how likely an embryo will grow into a healthy fetus by computing the probability of it developing into the stage of having a fetal heart. AI systems have shown a better performance in identifying embryos that will lead to successful implantation. Bormann et al., [159] use single timepoint images of embryos to train a CNN model to assess their implantation capability. Vermilyea et al., [160] design an ensemble comprising of 8 different models created using ResNet-152 and DenseNet-161 to predict the embryo viability during IVF using images of embryos extracted on Day 5 of culture. They trained four models on the image segmenting the zona region and four models considering the full embryo images. Khosravi et al., [161] develop a deep neural framework - STORK (based on the Google Inception architecture) to assess the quality of blastocysts and pick out the best embryo for transfer. In addition to STORK framework, the researchers design the CHAID framework based on decision trees which predicts the likelihood of a successful pregnancy by considering the age parameter along with the embryo quality. In addition to improving the IVF success rate, AI could also help understand in depth the difference between the traits of the embryos which makes one better than the others.
In addition to the fields discussed above, there are various other fields in the healthcare and human biology space. These are the fields related to human genomics, drugs discovery, etc... A few use cases on how AI is changing the state of these fields are discussed below.
8) GENOMICS
Genomics involves analysis of the genetic components, the genome of an organism involving the recombinant DNA, DNA sequencing methods, and bioinformatics to sequence, assemble, and analyze the structure and functioning of genomes. Techniques to gene analysis involve DNA isolation, cut, and paste of DNA, cloning and vectors, detecting the gene of interest, cloning, and sequencing. Genomic data analysis is one of the key factors towards the realization of the concept of an effective personalized treatment and medicine. Genomic data along with the clinical and lifestyle information of an individual can help the physicians to diagnose the cause of a disease, predict the early signs/risk of developing a condition or disease. The
gene specific root cause analysis can help design a more effective and personalized treatment and care plan. However, the genomic data are very large in size and a human genome could be as large as 100gb and with new data being generated, the analysis of such huge amount of data could take a very long time. The analysis of genomic data becomes more and more complex with rising volumes of data. Accuracy is also a very huge factor in the analysis since the results would directly impact clinical diagnosis and personalized medications for the individuals. This is where AI can help in the field of genomics. AI has the potential to enhance the analysis of genes and derive meaningful clinical information out of it in a very quick time. Given raw data, the turnaround time for obtaining actionable insights and analysis will be shortened with the capabilities of AI. The gene data analysis and the plethora of knowledge that can be extracted from the DNA parings would be invaluable for research activities, pharmaceutical companies, and drug discoveries. Researchers are utilizing AI to extract detailed insights about the cause and cures for diseases at the gene level, for variant calling to identify variants from sequence data, gene annotation and variant classification, phenotype to genotype mapping. Rodriguez et Al., [162] develop a machine learning framework experimenting with various machine learning techniques by analyzing the mRNA expression profiles from the brain to determine the ideal candidates for drug repurposing and screen the efficacy of the current available drugs for treating Alzheimer’s disease. The framework enables to pre-select a certain set of drugs that will have a higher probability of succeeding clinical trials. Various different researchers have applied CNN based learnings for classifying coding, and non-coding based variants. Poplin et al., [163] develop a deep learning framework known as “DeepVariant” based on the Inception architecture for the purpose of variant calling by interpreting the read alignment images to identify single nucleotide variants. Quang et Al., [164] extend the existing SVM based CADD framework [165] to train a deep learning based framework (DANN) with the same feature set and training data as the CADD for genetic variant annotations. Sundaram et al., [166] implement a deep learning system to identify pathogenic gene mutations in rare diseases. Kelley et al., [167] implement a CNN based system to predict the epigenetic and transcription based profiles from human cells using DNA sequences. Alipanahi et al., [168] use neural networks to design the DeepBind framework to analyze the sequence specificities of various DNA/RNA binding proteins and use it to show how variations affect bindings and gene expression in case of diseased conditions. AI is also enabling for an efficient genotype-phenotype mapping. These mappings are essential in the molecular diagnostics of a disease which not only requires identifying any pathogenic variants involved but also determining the correspondence between the individual’s phenotype and the identified pathogenic variant. Researchers have applied AI and deep learning techniques for tasks such as Image to genetic diagnosis, identification of genetic syndromes, EHR to


Journal of Electronics, Electromedical Engineering, and Medical Informatics Multidisciplinary: Rapid Review : Open Access Journal e-ISSN: 2656-8632
Homepage: jeeemi.org
Vol. 4, No. 1, January 2022, pp: 1-23 14
genetic diagnosis that involves analysis of pathological tests results and analysis documented in the EHR data to identify any emerging pattern and extract phenotypic descriptions of rare diseases to map with the existing pathogenic variants in the individual’s genome. With all the innovative research happening around the genomic science space, AI has the potential to analyse the most complex of data and unearth meaningful and actionable insights which would otherwise be very difficult at the human level. However, there are a certain limitations and challenges to the application in a real world genomic setting such as regulatory issues, ethical challenges since genomic data can reveal the entire medical history of not only an individual but across generations as well, data and performance bias of the machine based models is a very important factor that needs attention. With the proper operating standards and regulatory approvals, AI has the potential to usher genetic science to a completely new level uncovering the hidden patterns that will open up a new era of personalized, precision medicine and healthcare.
9) DRUG DISCOVERY
Drug discovery is a very lengthy and time consuming process involving multiple phases from the pre-laboratory research, drug discovery, clinical trial phases to the drug approval phase. The clinical trial alone involves three phases to test the safety and efficacy of the drug on larger population. Overall, it takes about 10-12 years for a new approved drug to hit the market The discovery phase in the laboratory could take up around 3 to 6 years to complete. Following the discovery, clinical trials can take up to 6 years on an average to complete. The average cost for each successful drug that makes it way to the market is projected to be around $2.6 billion [169]. The drugs that fail somewhere in phases of clinical trials, or the final approval phase have all the effort, time, and money lost which makes drug development a very expensive task from every perspective. This is where AI has the potential and all the resources to become a very important player in the field of pharmacy and drug development. KK et al., [170] discuss the feasibility of AI for a successful drug development. The chemical space is estimated to be huge collection of molecules in the order of 1060. Scanning through such a huge search space is a very time consuming and expensive task for humans. AI can enhance and optimize the processes of identification of a valid drug target molecule, valid drug targets, new drug design, drug repurposing, analysis of biomedical and molecular data, and optimize the process of clinical trials. Hessler et al., [171] discuss the application of deep neural network in the generation of novel biologically active molecules to develop automated drug discovery frameworks. An important phase in a new drug development process in Property Prediction that determines if the candidate molecule exhibits good physiochemical and ADMET properties which remains a multi-dimensional challenge. Various machine learning methods like the SVM, random forest, and Bayesian learning have been successfully tested for property prediction. Deep neural networks have
been applied for predicting the toxicity level, potential energies of a candidate and out-perform many existing machine learning techniques. De novo drug design, an iterative process aiming to develop new drug molecules taking the three-dimensional structure of the receptor as reference and requires a good knowledge of organic chemistry for in silico compound synthesis. AI is now revolutionizing the de novo approach and researchers have successfully applied auto-encoders [172] where the encoder network translates the chemical structures into vectors and the decoder network is able to translate these vectors to synthesize chemical compounds that improve the target properties. Kadurin et al. [173] implement generative adversarial network to develop new compounds that increase the anti-cancer properties of the target drug. Recursive neural networks and transfer learning strategies have also been successfully applied to automate the de novo framework. Once new molecules are developed, the next key step involves organic synthesis of these molecules to advance along the optimization path to identify molecules that resemble more with the target properties. Various machine learning techniques have been experimented for the forward synthesis planning to determine the best route to retrosynthetic analysis, protein folding, protein-protein structure prediction, and prediction of bio-activity to analyze the efficacy of a drug and its affinity towards the target receptor. Kayala et al., [174] apply machine learning to predict the top ranked productive chemical reactions. Segler et al., [175] implement neural networks to predict and prioritize the most efficient transformation rules for retrosynthesis. Encoder-Decoder, Sequence-to-Sequence, and Monte Carlo Tree search algorithm based Reinforcement Learning models have been successfully implemented to automate the forward synthesis planning of chemical reactions. Methods of AI have also been implemented to assist in the clinical trial phase, identifying more relevant human biomarkers, and in selection of target population. It is well known that only about 10% of the candidate drugs successfully cross the clinical trial phase and become approved drugs. AI can help to modernize the trial design by identifying the target bio-makers, population selection strategies by mining through the huge amount of EHR, imaging, or ‘omics’ data, target site selection, trial patient monitoring, and medical adherence. Bain et al., [176] design a platform AiCure to study the adherence levels of dosage in phase 2 clinical trial of Schizophrenia. The results show a 25% increase in the adherence levels by using the technology. AI enabled mobile and wearable devices will enable virtual monitoring and patient support to ensure medical adherence and effectively continue the progress of the trial. Though there remain various challenges to simulate and automate the processes in drug discovery using AI, the overall effect of AI will only improve with time in repurposing and streamlining the drug discovery processes.


Journal of Electronics, Electromedical Engineering, and Medical Informatics Multidisciplinary: Rapid Review : Open Access Journal e-ISSN: 2656-8632
Homepage: jeeemi.org
Vol. 4, No. 1, January 2022, pp: 1-23 15
10) PANDEMIC OUTBREAK PREDICTION
Early predictions of any global disease outbreak are very much important in reducing the severity of the disease spread and consequently reducing the mortality rate. AI systems were the first ones to trigger the flag for the corona-virus outbreak. On December 30th, 2019, the AI systems of Bluedot reported an unusual bump in pneumonia cases in the city of Wuhan. The AI service running at Boston Children’s hospital called HealthMap triggered a similar bump [177]. Such systems scan online news portals, social media reports, and government reports for disease outbreaks across the globe and raise alarms if any unusual rise in health activities are observed. These systems are majorly based on the Natural Language Processing techniques to scan through online documents, reports and raise alerts when a suspicion is found. These systems are also trained to analyze the airtravel data at the place of suspicion and assess the pathway of any possible spread of the outbreak to other places. Apart from NLP, Unsupervised algorithms can also be utilized to identify new patterns and behavior in the data. These patterns could be the cities or localities with related specific activities in the geographical region of interest where the outbreak has occurred. Forecasting is another area where AI can be leveraged to analyze datasets to reveal outbreak trends, patterns, reveal future predictions, and real time forecasts. Tamang et al., [178] trained artificial neural networks to forecast data up to one week based on the current trend of the covid outbreak in the particular region. The researchers utilized the improvement trends in China and South Korea to gain insights for forecasting in India, USA, France, and UK. Similarly, Chakraborty et al., [179] implement a hybrid timeseries forecasting technique to generate short-term forecasts for a 10 day window in Canada, France, India, South Korea, and the UK. The researchers additionally perform an analysis to derive the casual variables that drastically affect the fatality rates. Deng et al., [180] developed AI powered time series forecasting tool based on Graph Neural Network to predict long term influenza outbreaks. Utilizing graph based networks enables the researchers to encode location based features from geographical locations in addition to the time based features to unearth hidden patterns based on both space and time. Similar technologies and methods can also be used to predict future waves of Covid-19. The work of Bluedot and MetaBiota is early predictions of the Covid outbreak shows how AI systems can enable accurate predictions using data driven techniques. Such predictions are poised to become more precise and accurate in the future as more and more data is generated and is made accessible at the global level. These are some of the core use cases in healthcare and life sciences where AI research and its adoption is going on at a rapid pace. AI is helping healthcare is hospital administrative tasks in optimizing the billing and insurance claim cycles. AI can help reduce manual intervention by automating the filing of insurance claims, and filling forms with correct medical codes. Natural language processing can be leveraged to streamline the process by analyzing the EHR data and
translate language to medical billing codes and automate the process of insurance filing. This will help reduce human errors and consequently insurance claim denials. AI can deliver highly scalable, accurate solutions that need much lesser human intervention. This will also help to reduce the operations cost associated in performing redundant tasks manually and reduce the amount of disputes related to billing and other administrative errors.
III. MATERIALS AND METHODS
Various academic, scholastic, and research work done in the field of AI and Healthcare were surveyed and evaluated in the process of writing this review paper. Various journals in the field of healthcare and biomedical informatics such as PubMed, PeerJ, Arxiv, Springer, and various other subject specific scholar websites like Google Scholar, Research Gate, etc. were searched for relevant work and publications. The most used search filters for narrowing down the articles were artificial intelligence, machine learning, deep learning, reinforcement learning, natural language processing, computer vision, healthcare, radiology, cardiology, obstetrics & gynecology, pathology, ophthalmology, drug discovery, genomics, radiology, neurology, and dental science. A few prerequisites for the inclusion criteria of the research articles were – (1) the work done was directly related to the field of artificial intelligence in the healthcare domain, (2) both applications based, and review papers were searched, and (3) the research work was carried out in the past decade. All the references and citations were managed using the Mendeley Desktop tool.
IV. DISCUSSION
Researchers have published many literatures review based papers in various journals in the field of AI and medical sciences. Ahuja [181] discusses the impact AI has had in cardiology, radiology, pathology, ophthalmology, etc. and the role physicians will have to play in the future. Chao et. al., [32] discuss the opportunities provided by reinforcement learning within healthcare. Korot et. al., [182] argue about the possibility of AI replacing ophthalmologists. Karches et. al., [183] present a discussion on why AI systems should not replace the physicians intuition and judgements. Dara et. al., [184] discuss the opportunities provided by machine learning in the discovery of new drugs. These papers discuss one specific application area within the healthcare domain. This paper considers the implementation opportunities of AI in almost all the fields of healthcare and medicine. A detailed discussion is presented below. AI has revolutionized various field in healthcare in the last few years. The numerous amounts of research happening in adopting AI into the healthcare domain have shown promising results. The AI based applications developed so far have been delivering great results in the field of disease diagnosis and prognosis using bio-medical images extracted from radiological scans and pathological whole slide images. Various fields in healthcare discussed in the previous section


Journal of Electronics, Electromedical Engineering, and Medical Informatics Multidisciplinary: Rapid Review : Open Access Journal e-ISSN: 2656-8632
Homepage: jeeemi.org
Vol. 4, No. 1, January 2022, pp: 1-23 16
are adopting AI into the respective clinical workflows and reduce the burden on healthcare professionals. Assisting in the clinical decision support system to improve the overall patient care and outcome, preliminary analysis for disease prognosis and diagnosis, improving the overall physician experience in documenting the patient EHRs by suggesting phrases and sections of clinical notes to ease physician burnout, automated diagnosis of health conditions through a deep analysis of the whole slide pathology and radiology images, analysis of digital health data and perform a predictive analysis for early to very early prediction of mental health or cardio-vascular conditions, short-term to long-term prognosis of mortality, analysis of complex historical health data to uncover potential hidden causes of particular health conditions are some of the applications AI technologies could help in improving the overall healthcare experience. Apart from core healthcare applications, AI also has the potential to optimize and automate various administrative tasks in a healthcare facility like patient admission and discharge, virtual nursing assistants, revenue, and billing cycle. The rapid advancement in technology can improve various decision making process, reduce human intervention and consequently the possibility of any errors. With the increasing usage of wearable health devices, mobile applications related to health tracking and monitoring, huge amount of health data is being collected at an alarming pace. These data can contain smallest of details of an individual which when utilized in a secure way following all data safety protocols, would prove to be a game changer in adopting AI, IoT, and big data technologies. The wearable devices and sensors can package applications that can monitor and record various vital data such as oxygen saturation level, heartbeat rhythm, blood pressure, blood glucose levels, sleep patterns, brain activity, etc... Various smart applications can use these data and prognose a heart attack or stroke. Though Covid19 pandemic has been a menace and caused much grief to humanity, it has provided opportunities to make the overall healthcare more accessible and improve communication between patients and the healthcare facilities. With fast and reliable communication technology, IoT, and big data playing a vital role in revolutionizing the telemedicine it now possible for humans to access healthcare facilities from the remotest of places. Various smart phone based healthcare applications enable users to input their food, medication dosage, and various vitals measurements which are accessible to the healthcare professionals for review. Increased usage of virtual communication has opened an effective channel of patient-physician consultation via video meetings. The healthcare applications allow the patients to schedule appointments, upload present and past illness complaints, access lab test reports and medical prescriptions, order medications, and educate patients on various health conditions, their effect, and remedies. Smart telehealth services enable convenient and time effective access to healthcare facilities. AI is playing a massive role in easing the mental burden and physician burnout by optimizing the clinical decision
making for diagnosis/prognosis of various health conditions. Various application and research studies in recent past have proved that AI systems though not at par with the physician’s capability but have the power to improve the current state of clinical workflow by improving diagnostic/prognostic accuracy, assisting in clinical decision making to ease up a physician’s job and improve the quality of care designed for patients. AI enabled smart systems also provide physicians with an improved and cohesive patient health record by performing a data analysis on the past and present illness, medication history of the patient. This will enable the physicians spend more time interacting with the patient listening to their problems rather than concentrating on the computer systems to get insights. When the physician transcribes patient notes, AI systems could ease the burden of typing long sections by summarizing and suggesting sections of documents. This will not only increase patient satisfaction but also enable physicians design a better care plan and help in retaining the much needed human touch. As already observed in the case of covid19, an AI system was the first to flag off the panicking rise in the number of pneumonia cases in the Chinese city of Wuhan, such systems could very well trigger the possible future pandemics, identifying people and geographical regions at higher risk of infection and spread of the virus. Algorithms could be designed to forecast the rate of incidence and the mortality rate at the global and local levels. Such forecast would help in identifying a better preventive course of action and alleviate the sufferings that cause much grief to humanity. The learnings from the covid19 pandemic will also enable physicians and technologists to design better applications for better outcomes. In the drug discovery space AI has been contributing to optimize and speedup the process of drug development by boosting up the various phases like scanning the potentially huge chemical space, target identification, drug design and repurposing, biomedical and molecular data analysis, and optimize the process of clinical trials. In the genomics space too, AI is boosting up the processes of gene sequencing, variants identification from sequence data, gene annotation and variant classification, phenotype to genotype mapping, image to genetic diagnosis, EHR to genetic diagnosis, and genetic syndrome identification to name a few. Though the success guaranteed by AI is huge there have been questions raised regarding the interpretability of the results with many labelling the AI systems as a black box where the results obtained are not explainable enough. This leads to many medical experts arguing against implementing AI into healthcare citing the expertise, precise judgement, interpretability, and explanations provided by physicians will never be matched by a machine. A physician’s expertise in judging each patient’s case as per the requirement may never be achieved by a trained system. In addition, there have also been concerns raised to the privacy and security of the protected health information that will be used to train the AI systems. Given the criticality of the healthcare domain, the adoption of AI into healthcare needs to happen following


Journal of Electronics, Electromedical Engineering, and Medical Informatics Multidisciplinary: Rapid Review : Open Access Journal e-ISSN: 2656-8632
Homepage: jeeemi.org
Vol. 4, No. 1, January 2022, pp: 1-23 17
proper guidelines and standard protocols to ensure safe and secure processing of patient data which is the most essential aspect of the domain. The adoption of AI should be done in an ethical and lawful manner without any compromise on the privacy of the patient data. There have been instances where questions relating to the privacy concerns and security risks of AI systems have been raised. How secure is the patient data that is required for training AI systems? Since these applications require huge amount of data to train, there have been numerous concerns around the HIPAA act. As already discussed in the previous sections, current data policies do not ensure to fully safeguard PHI with increased usage of AI systems. The increased threats ask for either updating the existing regulations or introduce new regulations to offer an extra layer of defense to protected health information in this era of artificial intelligence. Techniques like the federated learning should be encouraged to be followed in training smart healthcare systems which not only protects the patient data privacy but also ensures that the AI models are not exposed to potential threats posed by cyber-attacks. There have been contrasting views on how physicians think about the adoption of AI. Karches, KE [185] argues the potential demerits of integrating AI based systems and too much of technology into healthcare. One argument point being the EHR system which aggregates all the vital information, the symptoms and problems of the patient and make it readily available to the physician. This kind of disconnects the doctor from the patient’s living body and reduces that much needed human touch. Use of technology leaves patient care to be manipulated and controlled by factors that are external to the physician-patient relationship. Karches also argues the disruptive impact AI would have on the healthcare system and that AI would consequently remove the organic human touch. Since AI systems are trained on a set of data and in the healthcare domain data can be much diverse, these systems can become biased on their decisions. For example, if an AI system is trained on data derived from academic medical centers, then such a system would not get exposed to a larger section of public who do not seek care from such medical facilities. Similarly, if an AI system is trained on data obtained from medical facility at defence sectors, then such system would be more biased towards the male population and yield less about the female population. Such bias will make AI less effective and generalizable which would not be acceptable in the healthcare domain. So, it must be ensured that AI systems for healthcare are trained on data that is representative of a much diverse target population. Moreover, AI systems since they are just trained to perform a particular task may suggest treating patients with a particular condition in similar ways without considering the fact that each person, each case, and similar conditions among population are different and the course of treatment needs to be considered differently from case to case basis. However, in contrast to the above view, physician Eric Topol in his book Deep Medicine [186] bats for the adoption of AI into healthcare and discusses about the opportunities presented by AI that will make healthcare human again.
Hospital visits these days have changed a lot as physicians can be seen spending much time looking at the computer screen either typing patient notes or looking to find a piece of information on screen. With AI and data analytics physicians now have all the relevant information available readily, they can spend more time with the patient listening to their problems and story. This enables the physicians to better engage with the patients, instill the much needed trust and belief that everything would eventually be fine. AI techs like NLP can make sense of the huge volumes of patient notes and EHRs. Deep learning can learn the hidden patterns in the voluminous data helping with accurate and quick real time diagnosis, advanced next generation genome sequencing, and many others critical analysis. These systems will also help to ease out physician burnout and eventually increase the quality of patient care. Such contrasting views and debates will continue to happen and any roadblock that stands in the way of adopting AI will also be solved with the help of technology. However, if we want to be successful in our attempt to revolutionize healthcare there needs to be an amalgamated effort from both technologists and healthcare professionals. The technologists should have or be given the domain knowledge that is very much essential to impart meaning to the end product while the healthcare professionals should have the basic technical knowledge or should be made available of the basic key terminologies to derive meaningful interpretations from the results of an AI system. The caregivers should have the knowledge to get involved in the discussions that happen in the requirement and analysis phases of the product design and transfer their clinical knowledge to the technologists. This combined effort will go a long way developing sustainable AI products that deliver meaningful results and leave an impact in healthcare. Though AI may not be completely able to replace a physician’s intuition and judgement on various cases, it will however empower healthcare professionals to become more efficient, reduce the burden on physicians, and consequently help in designing better care plan for patients thereby increasing the level of healthcare. This review paper tries to touch base on almost all the field within the domain at a higher level. However, a detailed aspect of the application prospects of AI can be taken up considering each field individually as part of future works. At the micro level, there will be various other implementation opportunities provided by AI which this paper does not include. These are a few limitations of this review paper.
V. CONCLUSION
This paper evaluated the various implementation opportunities provided by AI technologies in the healthcare and medicine domain. The major factors for a healthcare revolutionization include (a) improving the quality of care, (b) improving patient outcomes and satisfaction levels, and (c) the turnaround time from design of the care plan to patient outcome. Charles Darwin once said, “It is not the strongest


Journal of Electronics, Electromedical Engineering, and Medical Informatics Multidisciplinary: Rapid Review : Open Access Journal e-ISSN: 2656-8632
Homepage: jeeemi.org
Vol. 4, No. 1, January 2022, pp: 1-23 18
of the species that survive, nor the most intelligent, but the one most responsive to change”. Over the recent years, there has been a gradual shift in the way healthcare operates moving towards the digital health and undoubtedly the quality of care and patient satisfaction levels have risen. The covid19 pandemic has ensured that we are fast moving towards the digital health experiences by shifting from inperson healthcare consultations to tele or video consultations, usage of mobile applications for scheduling appointments, viewing reports, or getting some patient education on various health conditions. A major part of this shift towards digital health has to be attributed towards successful integration of AI systems into the domain. To adapt and implement this change requires an effort from all the parties involves – the technologists, the healthcare professionals, and the patients. Everyone needs to accept and respond positively for this change to become successful. The amount of health data being generated is huge which will help in building clinically meaningful AI systems. A major role of AI is currently revolving around the image based analysis and diagnosis where these systems have gone above and beyond the state-of-the-art model performances and have been granted clearance for various clinical diagnostics task. However, there are massive opportunities for improvement in other fields of drug discovery, genomics, and patient prognosis to name a few. AI has shown to have the potential to completely transform the state of healthcare and the way various clinical and administrative workflows operate within a healthcare facility. However, many of such methods and algorithms need to go the next step advancing from research labs and transition themselves into a fully optimized production level product. Once the algorithms are translated into clinically approved product, they can help a long way in – reducing the turnaround time for patients in the emergency departments and making the emergency processes more optimized, reducing human errors which are one of the major cause of deaths. The most important motivating factor in building AI systems should be to make the algorithms understand the underlying health problem in a way that these systems are able to learn on the go and reinforce their knowledge base. There are certain limitations in AI integration like - validation and generalizability on external datasets, the black box problem and model interpretability, gaps in clinical knowledge of the technologists. As we find ways to address these challenges, AI could be fast transforming healthcare into a data driven industry harnessing the hidden powers of the big data. The much debated risk of exposing the protected health information has to be addressed with maximum urgency either by modifying the existing data standards or by encouraging a more secured method - federated learning for building models. AI should be integrated in a way that assists the healthcare professionals and makes their job easier and supports is designing better care plan for the patients consequently increasing patient satisfaction. As discussed in the paper, Artificial Intelligence and its related technologies have the power to surge the functional efficacy of healthcare
facilities, assist medicine and healthcare by empowering the professionals, enabling them to be more effective, efficient, communicable, and reachable to the patients who can also take control of their health and play a part in deciding a better care plan. Overall, the healthcare industry has huge space for modernization and the covid pandemic situation has certainly fast-tracked the need to focus on innovation. There needs to be a continued amalgamated approach actively involving the technologists, the healthcare professionals, caregivers, and the patients to drive the data driven healthcare.
REFERENCES
[1] J. S. Maxmen, “The Post-Physician Era: Medicine in the TwentyFirst Century,” eweb:14239.
[2] P. C. Anderson, “The Post-Physician Era: Medicine in the 21st Century,” JAMA, vol. 237, no. 21, pp. 2336–2337, May 1977, doi: 10.1001/jama.1977.03270480076033. [3] J. S. Maxmen, “Long-Term Trends in Health Care: The PostPhysician Era Reconsidered BT - Indicators and Trends in Health and Health Care,” D. Schwefel, Ed. Berlin, Heidelberg: Springer Berlin Heidelberg, 1987, pp. 109–115.
[4] “Artificial Intelligence in Healthcare Market - Global Forecast to 2026.” https://www.marketsandmarkets.com/MarketReports/artificial-intelligence-healthcare-market-54679303.html (accessed Sep. 26, 2021).
[5] R. Shimonski, “AI in Healthcare,” AI in Healthcare, 2021. https://www.alliedmarketresearch.com/artificial-intelligence-inhealthcare-market.
[6] S. J. MacEachern and N. D. Forkert, “Machine learning for precision medicine,” https://doi.org/10.1139/gen-2020-0131, vol. 64, no. 4, pp. 416–425, 2020, doi: 10.1139/GEN-2020-0131.
[7] A. P, C. JM, and W. J, “Health Care Data Standards,” in Patient Safety: Achieving a New Standard for Care, Washington (DC): National Academies Press (US).
[8] L. Hood and M. Flores, “A personal view on systems medicine and the emergence of proactive P4 medicine: predictive, preventive, personalized and participatory,” N. Biotechnol., vol. 29, no. 6, pp. 613–624, 2012, doi: https://doi.org/10.1016/j.nbt.2012.03.004.
[9] Caroline Brogan, “New AI technology protects privacy in healthcare settings | Imperial News | Imperial College London.” https://www.imperial.ac.uk/news/222093/new-ai-technologyprotects-privacy-healthcare/ (accessed Sep. 30, 2021). [10] L. Na, C. Yang, C.-C. Lo, F. Zhao, Y. Fukuoka, and A. Aswani, “Feasibility of Reidentifying Individuals in Large National Physical Activity Data Sets From Which Protected Health Information Has Been Removed With Use of Machine Learning,” JAMA Netw. Open, vol. 1, no. 8, pp. e186040–e186040, 2018, doi: 10.1001/jamanetworkopen.2018.6040.
[11] A. Aswani, “Artificial intelligence advances threaten pri | EurekAlert!” https://www.eurekalert.org/news-releases/826934 (accessed Sep. 30, 2021). [12] G. A. Kaissis, M. R. Makowski, D. Rückert, and R. F. Braren, “Secure, privacy-preserving and federated machine learning in medical imaging,” Nat. Mach. Intell. 2020 26, vol. 2, no. 6, pp. 305311, Jun. 2020, doi: 10.1038/s42256-020-0186-1. [13] G. Kaissis et al., “End-to-end privacy preserving deep learning on multi-institutional medical imaging,” Nat. Mach. Intell., vol. 3, no. 6, pp. 473–484, 2021, doi: 10.1038/s42256-021-00337-8.
[14] “Future of Artificial Intelligence in Health Care | Deloitte US.” https://www2.deloitte.com/us/en/pages/life-sciences-and-healthcare/articles/future-of-artificial-intelligence-in-health-care.html (accessed Sep. 08, 2021).
[15] R. A, J. S, V. S. K, W. G, and H. JP, “Comparative performances of machine learning methods for classifying Crohn Disease patients using genome-wide genotyping data,” Sci. Rep., vol. 9, no. 1, Dec. 2019, doi: 10.1038/S41598-019-46649-Z. [16] G. Hinton, “Deep Learning—A Technology With the Potential to Transform Health Care,” JAMA, vol. 320, no. 11, pp. 1101–1102,


Journal of Electronics, Electromedical Engineering, and Medical Informatics Multidisciplinary: Rapid Review : Open Access Journal e-ISSN: 2656-8632
Homepage: jeeemi.org
Vol. 4, No. 1, January 2022, pp: 1-23 19
Sep. 2018, doi: 10.1001/jama.2018.11100.
[17] C. D. Naylor, “On the Prospects for a (Deep) Learning Health Care System,” JAMA, vol. 320, no. 11, pp. 1099–1100, Sep. 2018, doi: 10.1001/jama.2018.11103.
[18] A. Esteva et al., “A guide to deep learning in healthcare,” Nat. Med., vol. 25, no. 1, pp. 24–29, Jan. 2019, doi: 10.1038/s41591-018-0316z.
[19] M. Zahiri, “Application of computer vision in surgical training and surgical robotics,” 2017. [Online]. Available: https://digitalcommons.unl.edu/dissertations/AAI10260082.
[20] A. S. Nair, V. Naik, N. Busa, and B. K. Rayani, “Triton sponge and canister app for estimating surgical blood loss,” Saudi J. Anaesth., vol. 13, no. 4, p. 390, Oct. 2019, doi: 10.4103/SJA.SJA_38_19.
[21] X. Jia and M. Q. H. Meng, “A deep convolutional neural network for bleeding detection in Wireless Capsule Endoscopy images,” Proc. Annu. Int. Conf. IEEE Eng. Med. Biol. Soc. EMBS, vol. 2016-Octob, pp. 639–642, Oct. 2016, doi: 10.1109/EMBC.2016.7590783.
[22] A. R. Hassan and M. A. Haque, “Computer-aided gastrointestinal hemorrhage detection in wireless capsule endoscopy videos,” Comput. Methods Programs Biomed., vol. 122, no. 3, pp. 341–353, Dec. 2015, doi: 10.1016/J.CMPB.2015.09.005. [23] N. Padoy, T. Blum, S. A. Ahmadi, H. Feussner, M. O. Berger, and N. Navab, “Statistical modeling and recognition of surgical workflow,” Med. Image Anal., vol. 16, no. 3, pp. 632–641, Apr. 2012, doi: 10.1016/J.MEDIA.2010.10.001. [24] Y. Jin et al., “SV-RCNet: Workflow recognition from surgical videos using recurrent convolutional network,” IEEE Trans. Med. Imaging, vol. 37, no. 5, pp. 1114–1126, May 2018, doi: 10.1109/TMI.2017.2787657.
[25] B. A. Wormer et al., “Impact of implementing an electronic health record on surgical resident work flow, duty hours, and operative experience.,” Am. Surg., vol. 81, no. 2, pp. 172–177, Feb. 2015.
[26] B. LA, B. J, and E. AG, “The impact of electronic health record systems on clinical documentation times: A systematic review,” Health Policy, vol. 122, no. 8, pp. 827–836, Aug. 2018, doi: 10.1016/J.HEALTHPOL.2018.05.014.
[27] C. P et al., “Impact of electronic health record technology on the work and workflow of physicians in the intensive care unit,” Int. J. Med. Inform., vol. 84, no. 8, pp. 578–594, Aug. 2015, doi: 10.1016/J.IJMEDINF.2015.04.002.
[28] L. N. Dyrbye and T. D. Shanafelt, “Physician Burnout: A Potential Threat to Successful Health Care Reform,” JAMA, vol. 305, no. 19, pp. 2009–2010, May 2011, doi: 10.1001/JAMA.2011.652. [29] M. X. Chen et al., “Gmail Smart Compose: Real-Time Assisted Writing,” Proc. ACM SIGKDD Int. Conf. Knowl. Discov. Data Min., pp. 2287–2295, May 2019, Accessed: Oct. 02, 2021. [Online]. Available: https://arxiv.org/abs/1906.00080v1. [30] D. Gopinath, M. Agrawal, L. Murray, S. Horng, D. Karger, and D. Sontag, “Fast, Structured Clinical Documentation via Contextual Autocomplete Clinical Documentation with Contextual Autocomplete,” Proc. Mach. Learn. Res., vol. 106, pp. 1–26, 2020. [31] P. J. Liu, “Learning to Write Notes in Electronic Health Records,” Aug. 2018, Accessed: Oct. 02, 2021. [Online]. Available: https://arxiv.org/abs/1808.02622v1.
[32] C. Yu, J. Liu, and S. Nemati, “Reinforcement Learning in Healthcare: A Survey,” Aug. 2019, Accessed: Oct. 01, 2021. [Online]. Available: https://arxiv.org/abs/1908.08796.
[33] B. Chakraborty and S. A. Murphy, “Dynamic Treatment Regimes,” Annu. Rev. Stat. its Appl., vol. 1, p. 447, 2014, doi: 10.1146/ANNUREV-STATISTICS-022513-115553.
[34] W. EH, A. BT, D. C, H. M, S. J, and B. A, “Improving chronic illness care: translating evidence into action,” Health Aff. (Millwood)., vol. 20, no. 6, pp. 64–78, 2001, doi: 10.1377/HLTHAFF.20.6.64.
[35] K. Humphrey and K. Humphrey, “Using Reinforcement Learning to Personalize Dosing Strategies in a Simulated Cancer Trial with High Dimensional Data,” 2017, Accessed: Oct. 05, 2021. [Online]. Available: https://repository.arizona.edu/handle/10150/625341.
[36] I. Ahn, J. Park, A. I, and P. J, “Drug scheduling of cancer chemotherapy based on natural actor-critic approach,” vol. 106, no. 2–3, pp. 121–129, Nov. 2011, doi: 10.1016/J.BIOSYSTEMS.2011.07.005.
[37] P. R, M. N, and H. WM, “Reinforcement learning-based control of
drug dosing for cancer chemotherapy treatment,” Math. Biosci., vol. 293, pp. 11–20, Nov. 2017, doi: 10.1016/J.MBS.2017.08.004. [38] Y. Zhao, D. Zeng, M. A. Socinski, and M. R. Kosorok, “Reinforcement learning strategies for clinical trials in nonsmall cell lung cancer,” Biometrics, vol. 67, no. 4, pp. 1422–1433, Dec. 2011, doi: 10.1111/J.1541-0420.2011.01572.X.
[39] Z. Y, K. MR, and Z. D, “Reinforcement learning design for cancer clinical trials,” Stat. Med., vol. 28, no. 26, pp. 3294–3315, Nov. 2009, doi: 10.1002/SIM.3720.
[40] D. Bertsimas and H. Wiberg, “Machine Learning in Oncology: Methods, Applications, and Challenges,” JCO Clin. Cancer Informatics, no. 4, pp. 885–894, Oct. 2020, doi: 10.1200/CCI.20.00072. [41] J.-N. Eckardt, K. Wendt, M. Bornhäuser, and J. M. Middeke, “Reinforcement Learning for Precision Oncology,” Cancers (Basel)., vol. 13, no. 18, p. 4624, Sep. 2021, doi: 10.3390/cancers13184624. [42] P. Yazdjerdi, N. Meskin, M. Al-Naemi, A. E. Al Moustafa, and L. Kovács, “Reinforcement learning-based control of tumor growth under anti-angiogenic therapy,” Comput. Methods Programs Biomed., vol. 173, pp. 15–26, May 2019.
[43] A. Hassani and M. B. Naghibi S., “Reinforcement learning based control of tumor growth with chemotherapy,” 2010 Int. Conf. Syst. Sci. Eng. ICSSE 2010, pp. 185–189, 2010, doi: 10.1109/ICSSE.2010.5551776.
[44] T. Zhu, K. Li, L. Kuang, P. Herrero, and P. Georgiou, “An insulin bolus advisor for type 1 diabetes using deep reinforcement learning,” Sensors (Switzerland), vol. 20, no. 18, pp. 1–15, Sep. 2020. [45] D. E, D. P, and M. SG, “An Actor-Critic based controller for glucose regulation in type 1 diabetes,” Comput. Methods Programs Biomed., vol. 109, no. 2, pp. 116–125, Feb. 2013, doi: 10.1016/J.CMPB.2012.03.002.
[46] E. Daskalaki, P. Diem, and S. G. Mougiakakou, “Model-Free Machine Learning in Biomedicine: Feasibility Study in Type 1 Diabetes,” PLoS One, vol. 11, no. 7, Jul. 2016, doi: 10.1371/JOURNAL.PONE.0158722. [47] P. D. Ngo, S. Wei, A. Holubová, J. Muzik, and F. Godtliebsen, “Control of Blood Glucose for Type-1 Diabetes by Using Reinforcement Learning with Feedforward Algorithm,” Comput. Math. Methods Med., vol. 2018, 2018, doi: 10.1155/2018/4091497. [48] M. K. Bothe et al., “The use of reinforcement learning algorithms to meet the challenges of an artificial pancreas,” Expert Rev. Med. Devices, vol. 10, no. 5, pp. 661–673, 2013, doi: 10.1586/17434440.2013.827515. [49] A. E. Gaweda, M. K. Muezzinoglu, G. R. Aronoff, A. A. Jacobs, J. M. Zurada, and M. E. Brier, “Individualization of pharmacological anemia management using reinforcement learning,” Neural Networks, vol. 18, no. 5–6, pp. 826–834, Jul. 2005, doi: 10.1016/J.NEUNET.2005.06.020.
[50] G. AE, M. MK, J. AA, A. GR, and B. ME, “Model predictive control with reinforcement learning for drug delivery in renal anemia management,” Conf. Proc. ... Annu. Int. Conf. IEEE Eng. Med. Biol. Soc. IEEE Eng. Med. Biol. Soc. Annu. Conf., vol. 2006, pp. 51775180, 2006, doi: 10.1109/IEMBS.2006.260685.
[51] J. M. Malof and A. E. Gaweda, “Optimizing drug therapy with reinforcement learning: The case of anemia management,” Proc. Int. Jt. Conf. Neural Networks, pp. 2088–2092, 2011, doi: 10.1109/IJCNN.2011.6033485. [52] J. D. Martín-Guerrero, F. Gomez, E. Soria-Olivas, J. Schmidhuber, M. Climente-Martí, and N. V. Jiménez-Torres, “A reinforcement learning approach for individualizing erythropoietin dosages in hemodialysis patients,” Expert Syst. Appl., vol. 36, no. 6, pp. 97379742, Aug. 2009, doi: 10.1016/J.ESWA.2009.02.041.
[53] A. Raghu, M. Komorowski, and S. Singh, “Model-Based Reinforcement Learning for Sepsis Treatment,” Nov. 2018, Accessed: Oct. 05, 2021. [Online]. Available: https://arxiv.org/abs/1811.09602v1. [54] A. Raghu, M. Komorowski, L. A. Celi, P. Szolovits, and M. Ghassemi, “Continuous State-Space Models for Optimal Sepsis Treatment - a Deep Reinforcement Learning Approach,” May 2017, Accessed: Oct. 05, 2021. [Online]. Available: https://arxiv.org/abs/1705.08422v1.


Journal of Electronics, Electromedical Engineering, and Medical Informatics Multidisciplinary: Rapid Review : Open Access Journal e-ISSN: 2656-8632
Homepage: jeeemi.org
Vol. 4, No. 1, January 2022, pp: 1-23 20
[55] X. Peng et al., “Improving Sepsis Treatment Strategies by Combining Deep and Kernel-Based Reinforcement Learning,” AMIA ... Annu. Symp. proceedings. AMIA Symp., vol. 2018, pp. 887–896, Jan. 2019, Accessed: Oct. 05, 2021. [Online]. Available: https://arxiv.org/abs/1901.04670v1. [56] M. Lu, Z. Shahn, D. Sow, F. Doshi-Velez, and L. H. Lehman, “Is Deep Reinforcement Learning Ready for Practical Applications in Healthcare? A Sensitivity Analysis of Duel-DDQN for Hemodynamic Management in Sepsis Patients,” AMIA Annu. Symp. Proc., vol. 2020, p. 773, 2020, Accessed: Oct. 02, 2021. [Online]. Available: /pmc/articles/PMC8075511/. [57] T. N. Alotaiby, S. A. Alshebeili, T. Alshawi, I. Ahmad, and F. E. Abd El-Samie, “EEG seizure detection and prediction algorithms: a survey,” EURASIP J. Adv. Signal Process. 2014 20141, vol. 2014, no. 1, pp. 1–21, Dec. 2014, doi: 10.1186/1687-6180-2014-183.
[58] P. J. Schulte, A. A. Tsiatis, E. B. Laber, and M. Davidian, “Q- and A-learning methods for estimating optimal dynamic treatment regimes,” Stat. Sci., vol. 29, no. 4, pp. 640–661, 2014.
[59] A. Ertefaie, S. Shortreed, and B. Chakraborty, “Q-learning Residual Analysis: Application to The Effectiveness of Sequences of Antipsychotic Medications for Patients with Schizophrenia,” Stat. Med., vol. 35, no. 13, p. 2221, Jun. 2016, doi: 10.1002/SIM.6859. [60] E. P. Balogh et al., “Improving Diagnosis in Health Care,” Improv. Diagnosis Heal. Care, pp. 1–472, Dec. 2015, doi: 10.17226/21794. [61] S. J. Fakih and T. K. Das, “LEAD: A methodology for learning efficient approaches to medical diagnosis,” IEEE Trans. Inf. Technol. Biomed., vol. 10, no. 2, pp. 220–228, Apr. 2006, doi: 10.1109/TITB.2005.855538.
[62] M. Olivecrona, T. Blaschke, O. Engkvist, and H. Chen, “Molecular De Novo Design through Deep Reinforcement Learning,” J. Cheminform., vol. 9, no. 1, Apr. 2017, Accessed: Oct. 05, 2021. [Online]. Available: https://arxiv.org/abs/1704.07555v2. [63] A. Serrano, B. Imbernón, H. Pérez-Sánchez, J. M. Cecilia, A. BuenoCrespo, and J. L. Abellán, “Accelerating drugs discovery with deep reinforcement learning: An early approach,” ACM Int. Conf. Proceeding Ser., Aug. 2018, doi: 10.1145/3229710.3229731.
[64] Y.-T. E, F. G, K. M, M. S, T. M, and H. I, “Encouraging Physical Activity in Patients With Diabetes: Intervention Using a Reinforcement Learning System,” J. Med. Internet Res., vol. 19, no. 10, Oct. 2017, doi: 10.2196/JMIR.7994.
[65] F. EM et al., “Can the artificial intelligence technique of reinforcement learning use continuously-monitored digital data to optimize treatment for weight loss?,” J. Behav. Med., vol. 42, no. 2, pp. 276–290, Apr. 2019, doi: 10.1007/S10865-018-9964-1.
[66] T. McKelvey, M. Ahmad, A. Teredesai, and C. Eckert, “Interpretable Machine Learning in Healthcare,” Aug. 2018.
[67] V. K. Ankur Teredesai , Muhammad Aurangzeb Ahmad , Carly Eckert M.D., “‘ Housekeeping ’ Explainable Models for,” vol. i, 2018, [Online]. Available: https://learning.acm.org/binaries/content/assets/leaningcenter/webinarslides/2018/explanaiblemodelsforhealthcareai_webinarslides.pdf. [68] D. W. Apley and J. Zhu, “Visualizing the Effects of Predictor Variables in Black Box Supervised Learning Models,” J. R. Stat. Soc. Ser. B Stat. Methodol., vol. 82, no. 4, pp. 1059–1086, Dec. 2016, Accessed: Oct. 09, 2021. [Online]. Available: https://arxiv.org/abs/1612.08468v2.
[69] M. T. Ribeiro, S. Singh, and C. Guestrin, “‘Why Should I Trust You?’ Explaining the Predictions of Any Classifier,” doi: 10.1145/2939672.2939778. [70] S. M. Lundberg, P. G. Allen, and S.-I. Lee, “A Unified Approach to Interpreting Model Predictions,” Accessed: Oct. 09, 2021. [Online]. Available: https://github.com/slundberg/shap.
[71] A. Shrikumar, P. Greenside, and A. Kundaje, “Learning Important Features Through Propagating Activation Differences,” 34th Int. Conf. Mach. Learn. ICML 2017, vol. 7, pp. 4844–4866, Apr. 2017, Accessed: Oct. 09, 2021. [Online]. Available: https://arxiv.org/abs/1704.02685v2. [72] G. Montavon, A. Binder, S. Lapuschkin, W. Samek, and K.-R. Müller, “Layer-Wise Relevance Propagation: An Overview,” Lect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics), vol. 11700 LNCS, pp. 193–209, 2019, doi:
10.1007/978-3-030-28954-6_10. [73] R. R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, and D. Batra, “Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization,” Oct. 2016, doi: 10.1007/s11263-01901228-7. [74] A. Chattopadhyay, A. Sarkar, P. Howlader, and V. N. Balasubramanian, “Grad-CAM++: Improved Visual Explanations for Deep Convolutional Networks,” Oct. 2017, doi: 10.1109/WACV.2018.00097. [75] N. Emanuele, de S. Nandita, B. Adrian, C. Angel, Alberich Bayarri Christoph D, Becker Francesca, and J. Visser, “What the radiologist should know about artificial intelligence - an ESR white paper,” Insights Imaging, vol. 10, no. 1, Dec. 2019, doi: 10.1186/S13244019-0738-2. [76] L. Chiwome, O. M. Okojie, A. K. M. J. Rahman, F. Javed, and P. Hamid, “Artificial Intelligence: Is It Armageddon for Breast Radiologists?,” Cureus, vol. 12, no. 6, p. e8923, Jun. 2020, doi: 10.7759/cureus.8923. [77] C. Lugo-Fagundo, B. Vogelstein, A. Yuille, and E. K. Fishman, “Deep Learning in Radiology: Now the Real Work Begins,” J. Am. Coll. Radiol., vol. 15, no. 2, pp. 364–367, Feb. 2018, doi: 10.1016/J.JACR.2017.08.007.
[78] P. Lakhani and B. Sundaram, “Deep Learning at Chest Radiography: Automated Classification of Pulmonary Tuberculosis by Using Convolutional Neural Networks,” https://doi.org/10.1148/radiol.2017162326, vol. 284, no. 2, pp. 574582, Apr. 2017, doi: 10.1148/RADIOL.2017162326.
[79] T. Kooi et al., “Large scale deep learning for computer aided detection of mammographic lesions,” Med. Image Anal., vol. 35, pp. 303–312, Jan. 2017, doi: 10.1016/J.MEDIA.2016.07.007. [80] J. Pontabry, F. Rousseau, C. Studholme, M. Koob, and J. L. Dietemann, “A discriminative feature selection approach for shape analysis: Application to fetal brain cortical folding,” Med. Image Anal., vol. 35, pp. 313–326, Jan. 2017, doi: 10.1016/J.MEDIA.2016.07.005.
[81] H. Wang et al., “A hybrid CNN feature model for pulmonary nodule malignancy risk differentiation,” J. Xray. Sci. Technol., vol. 26, no. 2, pp. 171–187, Jan. 2018, doi: 10.3233/XST-17302.
[82] S. M. McKinney et al., “International evaluation of an AI system for breast cancer screening,” Nat. 2020 5777788, vol. 577, no. 7788, pp. 89–94, Jan. 2020, doi: 10.1038/s41586-019-1799-6. [83] D. Jill, “The promise of artificial intelligence in diagnosing illness | CIO.” https://www.cio.com/article/3305951/the-promise-ofartificial-intelligence-in-diagnosing-illness.html (accessed Oct. 14, 2021).
[84] “Shortage of pathologists affecting care levels in low, middle income countries - Health news, Medibulletin.” https://medibulletin.com/shortage-of-pathologists-affecting-carelevels-in-low-middle-income-countries/ (accessed Oct. 14, 2021). [85] D. P. Association, “About Digital Pathology.” https://digitalpathologyassociation.org/about-digital-pathology (accessed Oct. 14, 2021). [86] R. Singh, L. Chubb, L. Pantanowitz, and A. Parwani, “Standardization in digital pathology: Supplement 145 of the DICOM standards,” J. Pathol. Inform., vol. 2, no. 1, p. 23, 2011, doi: 10.4103/2153-3539.80719. [87] L. Pantanowitz, A. Sharma, A. B. Carter, T. Kurc, A. Sussman, and J. Saltz, “Twenty Years of Digital Pathology: An Overview of the Road Travelled, What is on the Horizon, and the Emergence of Vendor-Neutral Archives,” J. Pathol. Inform., vol. 9, p. 40, Nov. 2018, doi: 10.4103/jpi.jpi_69_18. [88] L. Y et al., “Artificial Intelligence-Based Breast Cancer Nodal Metastasis Detection: Insights Into the Black Box for Pathologists,” Arch. Pathol. Lab. Med., vol. 143, no. 7, pp. 859–868, 2019, doi: 10.5858/ARPA.2018-0147-OA. [89] D. Al Mouiee et al., “Classifying Retinal Degeneration in Histological Sections Using Deep Learning.,” Transl. Vis. Sci. Technol., vol. 10, no. 7, p. 9, Jun. 2021, doi: 10.1167/TVST.10.7.9. [90] L. Pantanowitz et al., “An artificial intelligence algorithm for prostate cancer diagnosis in whole slide images of core needle biopsies: a blinded clinical validation and deployment study,” Lancet Digit. Heal., vol. 2, no. 8, pp. e407–e416, Aug. 2020, doi:


Journal of Electronics, Electromedical Engineering, and Medical Informatics Multidisciplinary: Rapid Review : Open Access Journal e-ISSN: 2656-8632
Homepage: jeeemi.org
Vol. 4, No. 1, January 2022, pp: 1-23 21
10.1016/S2589-7500(20)30159-X.
[91] S. Mishra, “Malaria Parasite Detection using Efficient Neural Ensembles,” J. Electron. Electromed. Eng. Med. Informatics, vol. 3, no. 3, pp. 119–133, Oct. 2021, doi: 10.35882/jeeemi.v3.i3.2.
[92] L. A. J et al., “Deeply Supervised UNet for Semantic Segmentation to Assist Dermatopathological Assessment of Basal Cell Carcinoma,” J. imaging, vol. 7, no. 4, Apr. 2021, doi: 10.3390/JIMAGING7040071.
[93] L. YJ et al., “Deep Learning Fast Screening Approach on Cytological Whole Slides for Thyroid Cancer Diagnosis,” Cancers (Basel)., vol. 13, no. 15, Aug. 2021, doi: 10.3390/CANCERS13153891. [94] W. L. Yun, U. Rajendra Acharya, Y. V. Venkatesh, C. Chee, L. C. Min, and E. Y. K. Ng, “Identification of different stages of diabetic retinopathy using retinal optical images,” Inf. Sci. (Ny)., vol. 178, no. 1, pp. 106–121, Jan. 2008, doi: 10.1016/J.INS.2007.07.020.
[95] T. Schlegl et al., “Fully Automated Detection and Quantification of Macular Fluid in OCT Using Deep Learning,” Ophthalmology, vol. 125, no. 4, pp. 549–558, Apr. 2018, doi: 10.1016/J.OPHTHA.2017.10.031. [96] B. C, J. S, and S. M, “Deep Learning-Based Diabetic Retinopathy Severity Grading System Employing Quadrant Ensemble Model,” J. Digit. Imaging, vol. 34, no. 2, pp. 440–457, Apr. 2021, doi: 10.1007/S10278-021-00418-5. [97] B. MN et al., “Two-stage framework for optic disc localization and glaucoma classification in retinal fundus images using deep learning,” BMC Med. Inform. Decis. Mak., vol. 19, no. 1, Jul. 2019, doi: 10.1186/S12911-019-0842-8.
[98] W. L. Alyoubi, M. F. Abulkhair, and W. M. Shalash, “Diabetic retinopathy fundus image classification and lesions localization system using deep learning,” Sensors, vol. 21, no. 11, Jun. 2021, doi: 10.3390/S21113704.
[99] J. Redmon and A. Farhadi, “YOLOv3: An Incremental Improvement,” Apr. 2018, Accessed: Oct. 15, 2021. [Online]. Available: https://arxiv.org/abs/1804.02767.
[100] B. P, P. KD, J. N, F. DE, and B. NM, “Comparing humans and deep learning performance for grading AMD: A study in using universal deep features and transfer learning for automated AMD analysis,” Comput. Biol. Med., vol. 82, pp. 80–86, Mar. 2017, doi: 10.1016/J.COMPBIOMED.2017.01.018. [101] P. M. Burlina, N. Joshi, K. D. Pacheco, D. E. Freund, J. Kong, and N. M. Bressler, “Use of Deep Learning for Detailed Severity Characterization and Estimation of 5-Year Risk among Patients with Age-Related Macular Degeneration,” JAMA Ophthalmol., vol. 136, no. 12, pp. 1359–1366, Dec. 2018, doi: 10.1001/JAMAOPHTHALMOL.2018.4118.
[102] M. MR et al., “Local configuration pattern features for age-related macular degeneration characterization and classification,” Comput. Biol. Med., vol. 63, pp. 208–218, Aug. 2015, doi: 10.1016/J.COMPBIOMED.2015.05.019.
[103] R. Zhao, Z. Chen, and Z. Chi, “Convolutional Neural Networks for Branch Retinal Vein Occlusion recognition?,” 2015 IEEE Int. Conf. Inf. Autom. ICIA 2015 - conjunction with 2015 IEEE Int. Conf. Autom. Logist., pp. 1633–1636, Sep. 2015, doi: 10.1109/ICINFA.2015.7279547.
[104] Z. Chen, H. Zhang, Z. Chi, and H. Fu, “Hierarchical local binary pattern for branch retinal vein occlusion recognition,” Lect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics), vol. 9008, pp. 687–697, Jan. 2015, doi: 10.1007/978-3-319-16628-5_49.
[105] S. F. Weng, J. Reps, J. Kai, J. M. Garibaldi, and N. Qureshi, “Can Machine-learning improve cardiovascular risk prediction using routine clinical data?,” PLoS One, vol. 12, no. 4, p. e0174944, Apr. 2017, doi: 10.1371/JOURNAL.PONE.0174944. [106] T. J. W. Dawes et al., “Machine Learning of Three-dimensional Right Ventricular Motion Enables Outcome Prediction in Pulmonary Hypertension: A Cardiac MR Imaging Study,” https://doi.org/10.1148/radiol.2016161315, vol. 283, no. 2, pp. 381–390, Jan. 2017, doi: 10.1148/RADIOL.2016161315. [107] A. ZI et al., “An artificial intelligence-enabled ECG algorithm for the identification of patients with atrial fibrillation during sinus rhythm: a retrospective analysis of outcome prediction,” Lancet (London, England), vol. 394, no. 10201, pp. 861–867, Sep. 2019,
doi: 10.1016/S0140-6736(19)31721-0.
[108] G. CD et al., “Development and Validation of a Deep-Learning Model to Screen for Hyperkalemia From the Electrocardiogram,” JAMA Cardiol., vol. 4, no. 5, pp. 428–436, May 2019, doi: 10.1001/JAMACARDIO.2019.0640.
[109] K. C et al., “Machine learning prediction in cardiovascular diseases: a meta-analysis,” Sci. Rep., vol. 10, no. 1, Dec. 2020, doi: 10.1038/S41598-020-72685-1.
[110] J. myoung Kwon et al., “A deep learning algorithm to detect anaemia with ECGs: a retrospective, multicentre study,” Lancet Digit. Heal., vol. 2, no. 7, pp. e358–e367, Jul. 2020, doi: 10.1016/S25897500(20)30108-4.
[111] P. Hsieh, “AI In Medicine: Rise Of The Machines.” https://www.forbes.com/sites/paulhsieh/2017/04/30/ai-in-medicinerise-of-the-machines/?sh=79d133eeabb0 (accessed Oct. 17, 2021). [112] C. E. Gutierrez et al., “Optimization and validation of diffusion MRIbased fiber tracking with neural tracer data as a reference,” Sci. Reports 2020 101, vol. 10, no. 1, pp. 1–18, Dec. 2020, doi: 10.1038/s41598-020-78284-4. [113] P. Kickingereder et al., “Automated quantitative tumour response assessment of MRI in neuro-oncology with artificial neural networks: a multicentre, retrospective study,” Lancet Oncol., vol. 20, no. 5, pp. 728–740, May 2019, doi: 10.1016/S1470-2045(19)300981. [114] K. E. Emblem et al., “A generic support Vector Machine Model for Preoperative glioma survival associations 1,” Radiol. n Radiol., vol. 275, no. 1, 2015, doi: 10.1148/radiol.14140770.
[115] I. Karabayir, S. M. Goldman, S. Pappu, and O. Akbilgic, “Gradient boosting for Parkinson’s disease diagnosis from voice recordings,” BMC Med. Inform. Decis. Mak., vol. 20, no. 1, Sep. 2020, doi: 10.1186/S12911-020-01250-7.
[116] J. Xu and M. Zhang, “Use of Magnetic Resonance Imaging and Artificial Intelligence in Studies of Diagnosis of Parkinson’s Disease,” ACS Chem. Neurosci., vol. 10, no. 6, pp. 2658–2667, Jun. 2019, doi: 10.1021/ACSCHEMNEURO.9B00207.
[117] B. N et al., “Artificial intelligence in neurodegenerative disease research: use of IBM Watson to identify additional RNA-binding proteins altered in amyotrophic lateral sclerosis,” Acta Neuropathol., vol. 135, no. 2, pp. 227–247, Feb. 2018, doi: 10.1007/S00401-0171785-8. [118] Y. W. Chien, S. Y. Hong, W. T. Cheah, L. H. Yao, Y. L. Chang, and L. C. Fu, “An Automatic Assessment System for Alzheimer’s Disease Based on Speech Using Feature Sequence Generator and Recurrent Neural Network,” Sci. Rep., vol. 9, no. 1, Dec. 2019, doi: 10.1038/S41598-019-56020-X.
[119] O. Hughes, “Using AI assessment to tackle dementia in ultra-early stages.” https://www.digitalhealth.net/2019/09/using-ai-assessmenttackle-dementia-ultra-early-stages/ (accessed Oct. 19, 2021).
[120] M. Nagamine et al., “Abstract WP395: Detection of Hemorrhagic Expansion With Ai,” Stroke, vol. 51, no. Suppl_1, Feb. 2020, doi: 10.1161/str.51.suppl_1.WP395.
[121] B. P et al., “Prediction of stroke thrombolysis outcome using CT brain machine learning,” NeuroImage. Clin., vol. 4, pp. 635–640, 2014, doi: 10.1016/J.NICL.2014.02.003. [122] C. Fernandez-Lozano et al., “Random forest-based prediction of stroke outcome,” Sci. Rep., vol. 11, no. 1, Dec. 2021, doi: 10.1038/S41598-021-89434-7.
[123] M. Monteiro et al., “Multiclass semantic segmentation and quantification of traumatic brain injury lesions on head CT using deep learning: an algorithm development and multicentre validation study,” Lancet Digit. Heal., vol. 2, no. 6, pp. e314–e322, Jun. 2020, doi: 10.1016/S2589-7500(20)30085-6. [124] R. Raj et al., “Machine learning-based dynamic mortality prediction after traumatic brain injury,” Sci. Rep., vol. 9, no. 1, pp. 1–13, Dec. 2019, doi: 10.1038/S41598-019-53889-6.
[125] “With Hopes of Helping Paralyzed Patients Regain Movement, Intel and Brown University Deploy AI | Intel Newsroom.” https://newsroom.intel.com/news/hopes-helping-paralyzed-patientsregain-movement-intel-brown-university-deploy-ai/#gs.dj6uhx (accessed Oct. 20, 2021).
[126] “Neurodata Without Borders – The Kavli Foundation.” https://www.nwb.org/ (accessed Oct. 18, 2021).


Journal of Electronics, Electromedical Engineering, and Medical Informatics Multidisciplinary: Rapid Review : Open Access Journal e-ISSN: 2656-8632
Homepage: jeeemi.org
Vol. 4, No. 1, January 2022, pp: 1-23 22
[127] S. MA et al., “A new approach for locating the minor apical foramen using an artificial neural network,” Int. Endod. J., vol. 45, no. 3, pp. 257–265, Mar. 2012, doi: 10.1111/J.1365-2591.2011.01970.X. [128] M. A. Saghiri, F. Garcia-Godoy, J. L. Gutmann, M. Lotfi, and K. Asgar, “The Reliability of Artificial Neural Network in Locating Minor Apical Foramen: A Cadaver Study,” J. Endod., vol. 38, no. 8, pp. 1130–1134, Aug. 2012, doi: 10.1016/j.joen.2012.05.004.
[129] M. C. Kılıc et al., “Artificial intelligence system for automatic deciduous tooth detection and numbering in panoramic radiographs,” Dentomaxillofacial Radiol., vol. 50, no. 6, Sep. 2021, doi: 10.1259/DMFR.20200172.
[130] S. K. Jung and T. W. Kim, “New approach for the diagnosis of extractions with neural network machine learning,” Am. J. Orthod. Dentofac. Orthop., vol. 149, no. 1, pp. 127–133, Jan. 2016, doi: 10.1016/J.AJODO.2015.07.030. [131] M. Johari, F. Esmaeili, A. Andalib, S. Garjani, and H. Saberkari, “Detection of vertical root fractures in intact and endodontically treated premolar teeth by designing a probabilistic neural network: an ex vivo study,” http://dx.doi.org/10.1259/dmfr.20160107, vol. 46, no. 2, Jan. 2017, doi: 10.1259/DMFR.20160107.
[132] J. De Tobel, P. Radesh, D. Vandermeulen, and P. W. Thevissen, “An automated technique to stage lower third molar development on panoramic radiographs for age estimation: a pilot study.,” J. Forensic Odontostomatol., vol. 35, no. 2, p. 42, Dec. 2017, Accessed: Oct. 20, 2021. [Online]. Available: /pmc/articles/PMC6100230/.
[133] M. Aubreville et al., “Automatic Classification of Cancerous Tissue in Laserendomicroscopy Images of the Oral Cavity using Deep Learning,” Sci. Reports 2017 71, vol. 7, no. 1, pp. 1–10, Sep. 2017, doi: 10.1038/s41598-017-12320-8. [134] S. Imangaliyev, M. H. van der Veen, C. M. C. Volgenant, B. J. F. Keijser, W. Crielaard, and E. Levin, “Deep Learning for Classification of Dental Plaque Images,” Lect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics), vol. 10122 LNCS, pp. 407–410, 2016, doi: 10.1007/978-3-319-51469-7_34. [135] J.-H. Lee, D. Kim, S.-N. Jeong, and S.-H. Choi, “Diagnosis and prediction of periodontally compromised teeth using a deep learningbased convolutional neural network algorithm,” J. Periodontal Implant Sci., vol. 48, no. 2, pp. 114–123, Apr. 2018, doi: 10.5051/JPIS.2018.48.2.114.
[136] F. Casalegno et al., “Caries Detection with Near-Infrared Transillumination Using Deep Learning:,” https://doi.org/10.1177/0022034519871884, vol. 98, no. 11, pp. 1227–1233, Aug. 2019, doi: 10.1177/0022034519871884. [137] T. Hiraiwa et al., “A deep-learning artificial intelligence system for assessment of root morphology of the mandibular first molar on panoramic radiography,” https://doi.org/10.1259/dmfr.20180218, vol. 48, no. 3, Nov. 2018, doi: 10.1259/DMFR.20180218.
[138] Y. Ariji et al., “CT evaluation of extranodal extension of cervical lymph node metastases in patients with oral squamous cell carcinoma using deep learning classification,” Oral Radiol. 2019 362, vol. 36, no. 2, pp. 148–155, Jun. 2019, doi: 10.1007/S11282-019-00391-4. [139] Y. Ariji et al., “Contrast-enhanced computed tomography image assessment of cervical lymph node metastasis in patients with oral cancer by using a deep learning system of artificial intelligence,” Oral Surg. Oral Med. Oral Pathol. Oral Radiol., vol. 127, no. 5, pp. 458–463, May 2019, doi: 10.1016/J.OOOO.2018.10.002.
[140] J. Krois et al., “Deep Learning for the Radiographic Detection of Periodontal Bone Loss,” Sci. Reports 2019 91, vol. 9, no. 1, pp. 1–6, Jun. 2019, doi: 10.1038/s41598-019-44839-3. [141] P. Basilio, “AI behind potential blood test for ovarian cancer | MDLinx,” MDLinx, 2017. https://www.mdlinx.com/article/aibehind-potential-blood-test-for-ovarian-cancer/lfc-1230 (accessed Oct. 22, 2021).
[142] E. A, R. CN, and E. RJ, “Artificial Intelligence Systems as Prognostic and Predictive Tools in Ovarian Cancer,” Ann. Surg. Oncol., vol. 22, no. 12, pp. 3970–3975, Nov. 2015, doi: 10.1245/S10434-015-4475-6.
[143] E. Kawakami et al., “Application of artificial intelligence for preoperative diagnostic and prognostic prediction in epithelial ovarian cancer based on blood biomarkers,” Clin. Cancer Res., vol. 25, no. 10, pp. 3006–3015, 2019, doi: 10.1158/1078-0432.CCR-18
3378.
[144] A. M and H. K, “Artificial Intelligence in Ovarian Cancer Diagnosis,” Anticancer Res., vol. 40, no. 8, pp. 4795–4800, Aug. 2020, doi: 10.21873/ANTICANRES.14482. [145] O. Holmström et al., “Point-of-Care Digital Cytology With Artificial Intelligence for Cervical Cancer Screening in a Resource-Limited Setting,” JAMA Netw. Open, vol. 4, no. 3, p. e211740, Mar. 2021, doi: 10.1001/jamanetworkopen.2021.1740.
[146] S. P B, F. Faruqi, H. K S, and R. Kudva, “Deep Convolution Neural Network for Malignancy Detection and Classification in Microscopic Uterine Cervix Cell Images,” Asian Pacific J. Cancer Prev., vol. 20, no. 11, pp. 3447–3456, Nov. 2019, doi: 10.31557/APJCP.2019.20.11.3447.
[147] F. H. D. Araújo et al., “Deep learning for cell image segmentation and ranking,” Comput. Med. Imaging Graph., vol. 72, pp. 13–21, Mar. 2019, doi: 10.1016/J.COMPMEDIMAG.2019.01.003. [148] C.-W. Wang et al., “Artificial intelligence-assisted fast screening cervical high grade squamous intraepithelial lesion and squamous cell carcinoma diagnosis and treatment planning,” Sci. Reports 2021 111, vol. 11, no. 1, pp. 1–14, Aug. 2021, doi: 10.1038/s41598-02195545-y. [149] M. O. Ajao, N. V. Clark, T. Kelil, S. L. Cohen, and J. I. Einarsson, “Case Report: Three-Dimensional Printed Model for Deep Infiltrating Endometriosis,” J. Minim. Invasive Gynecol., vol. 24, no. 7, pp. 1239–1242, Nov. 2017, doi: 10.1016/J.JMIG.2017.06.006.
[150] P. Vávra et al., “Recent Development of Augmented Reality in Surgery: A Review,” J. Healthc. Eng., vol. 2017, 2017, doi: 10.1155/2017/4574172. [151] Z. Zhao, Y. Deng, Y. Zhang, Y. Zhang, X. Zhang, and L. Shao, “DeepFHR: intelligent prediction of fetal Acidemia using fetal heart rate signals based on convolutional neural network,” BMC Med. Informatics Decis. Mak. 2019 191, vol. 19, no. 1, pp. 1–15, Dec. 2019, doi: 10.1186/S12911-019-1007-5.
[152] J. Li et al., “Automatic classification of fetal heart rate based on convolutional neural network,” IEEE Internet Things J., vol. 6, no. 2, pp. 1394–1401, Apr. 2019, doi: 10.1109/JIOT.2018.2845128. [153] A. Kazantsev, J. Ponomareva, P. Kazantsev, R. Digilov, and P. Huang, “Development of e-health network for in-home pregnancy surveillance based on artificial intelligence,” Proc. - IEEE-EMBS Int. Conf. Biomed. Heal. Informatics Glob. Gd. Chall. Heal. Informatics, BHI 2012, pp. 82–84, 2012, doi: 10.1109/BHI.2012.6211511.
[154] L. H et al., “Machine learning risk score for prediction of gestational diabetes in early pregnancy in Tianjin, China,” Diabetes. Metab. Res. Rev., vol. 37, no. 5, Jul. 2021, doi: 10.1002/DMRR.3397. [155] Jiayi et al., “An Innovative Artificial Intelligence–Based App for the Diagnosis of Gestational Diabetes Mellitus (GDM-AI): Development Study,” J Med Internet Res 2020;22(9)e21573 https//www.jmir.org/2020/9/e21573, vol. 22, no. 9, p. e21573, Sep. 2020, doi: 10.2196/21573.
[156] Y. T. Wu et al., “Early Prediction of Gestational Diabetes Mellitus in the Chinese Population via Advanced Machine Learning,” J. Clin. Endocrinol. Metab., vol. 106, no. 3, pp. E1191–E1205, Mar. 2021, doi: 10.1210/CLINEM/DGAA899.
[157] K.-S. Lee and K. H. Ahn, “Artificial Neural Network Analysis of Spontaneous Preterm Labor and Birth and Its Major Determinants,” J. Korean Med. Sci., vol. 34, no. 16, Apr. 2019, doi: 10.3346/JKMS.2019.34.E128.
[158] R. Raja, I. Mukherjee, and B. K. Sarkar, “A Machine Learning-Based Prediction Model for Preterm Birth in Rural India,” J. Healthc. Eng., vol. 2021, 2021, doi: 10.1155/2021/6665573.
[159] B. CL et al., “Performance of a deep learning based neural network in the selection of human blastocysts for implantation,” Elife, vol. 9, pp. 1–14, Sep. 2020, doi: 10.7554/ELIFE.55301.
[160] V. M et al., “Development of an artificial intelligence-based assessment model for prediction of embryo viability using static images captured by optical light microscopy during IVF,” Hum. Reprod., vol. 35, no. 4, pp. 770–784, 2020, doi: 10.1093/HUMREP/DEAA013.
[161] P. Khosravi et al., “Deep learning enables robust assessment and selection of human blastocysts after in vitro fertilization,” npj Digit. Med., vol. 2, no. 1, Dec. 2019, doi: 10.1038/S41746-019-0096-Y. [162] S. Rodriguez et al., “Machine learning identifies candidates for drug


Journal of Electronics, Electromedical Engineering, and Medical Informatics Multidisciplinary: Rapid Review : Open Access Journal e-ISSN: 2656-8632
Homepage: jeeemi.org
Vol. 4, No. 1, January 2022, pp: 1-23 23
repurposing in Alzheimer’s disease,” Nat. Commun. 2021 121, vol. 12, no. 1, pp. 1–13, Feb. 2021, doi: 10.1038/s41467-021-21330-0. [163] R. Poplin et al., “A universal SNP and small-indel variant caller using deep neural networks,” Nat. Biotechnol. 2018 3610, vol. 36, no. 10, pp. 983–987, Sep. 2018, doi: 10.1038/nbt.4235.
[164] Q. D, C. Y, and X. X, “DANN: a deep learning approach for annotating the pathogenicity of genetic variants,” Bioinformatics, vol. 31, no. 5, pp. 761–763, Mar. 2015, doi: 10.1093/BIOINFORMATICS/BTU703. [165] P. Rentzsch, D. Witten, G. M. Cooper, J. Shendure, and M. Kircher, “CADD: Predicting the deleteriousness of variants throughout the human genome,” Nucleic Acids Res., vol. 47, no. D1, pp. D886D894, Jan. 2019, doi: 10.1093/NAR/GKY1016.
[166] S. L et al., “Predicting the clinical impact of human mutation with deep neural networks,” Nat. Genet., vol. 50, no. 8, pp. 1161–1170, Aug. 2018, doi: 10.1038/S41588-018-0167-Z.
[167] K. DR, R. YA, B. M, B. D, M. CY, and S. J, “Sequential regulatory activity prediction across chromosomes with convolutional neural networks,” Genome Res., vol. 28, no. 5, pp. 739–750, May 2018, doi: 10.1101/GR.227819.117.
[168] A. B, D. A, W. MT, and F. BJ, “Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning,” Nat. Biotechnol., vol. 33, no. 8, pp. 831–838, Aug. 2015, doi: 10.1038/NBT.3300.
[169] -Kenneth C Frazier, “Biopharmaceutical Research & Development: The Process Behind New Medicines.” Accessed: Nov. 02, 2021. [Online]. Available: http://phrmadocs.phrma.org/sites/default/files/pdf/rd_brochure_022307.pdf.
[170] M. KK and P. MR, “Artificial intelligence in drug development: present status and future prospects,” Drug Discov. Today, vol. 24, no. 3, pp. 773–780, Mar. 2019, doi: 10.1016/J.DRUDIS.2018.11.014.
[171] G. Hessler and K. H. Baringhaus, “Artificial intelligence in drug design,” Molecules, vol. 23, no. 10, Oct. 2018, doi: 10.3390/MOLECULES23102520.
[172] R. Gómez-Bombarelli et al., “Automatic chemical design using a data-driven continuous representation of molecules,” ACS Cent. Sci., vol. 4, no. 2, pp. 268–276, Oct. 2016, doi: 10.1021/acscentsci.7b00572.
[173] A. Kadurin et al., “The cornucopia of meaningful leads: Applying deep adversarial autoencoders for new molecule development in oncology,” Oncotarget, vol. 8, no. 7, pp. 10883–10890, Dec. 2016, doi: 10.18632/ONCOTARGET.14073.
[174] M. A. Kayala and P. Baldi, “ReactionPredictor: Prediction of Complex Chemical Reactions at the Mechanistic Level Using Machine Learning,” J. Chem. Inf. Model., vol. 52, no. 10, pp. 25262540, Oct. 2012, doi: 10.1021/CI3003039.
[175] M. H. S. Segler and M. P. Waller, “Neural-Symbolic Machine Learning for Retrosynthesis and Reaction Prediction,” Chem. – A Eur. J., vol. 23, no. 25, pp. 5966–5971, May 2017, doi: 10.1002/CHEM.201605499.
[176] E. E et al., “Use of a Novel Artificial Intelligence Platform on Mobile Devices to Assess Dosing Compliance in a Phase 2 Clinical Trial in Subjects With Schizophrenia,” JMIR Mhealth Uhealth 2017;5(2)e18 https//mhealth.jmir.org/2017/2/e18, vol. 5, no. 2, p. e7030, Feb. 2017, doi: 10.2196/MHEALTH.7030.
[177] W. D. Heaven, “AI could help with the next pandemic—but not with this one | MIT Technology Review,” 2020. https://www.technologyreview.com/2020/03/12/905352/ai-couldhelp-with-the-next-pandemicbut-not-with-this-one/ (accessed Nov. 07, 2021).
[178] S. K. Tamang, P. D. Singh, and B. Datta, “Forecasting of Covid-19 cases based on prediction using artificial neural network curve fitting technique,” Glob. J. Environ. Sci. Manag., vol. 6, no. Special Issue (Covid-19), pp. 53–64, Aug. 2020, doi: 10.22034/GJESM.2019.06.SI.06.
[179] T. Chakraborty and I. Ghosh, “Real-time forecasts and risk assessment of novel coronavirus (COVID-19) cases: A data-driven analysis,” Chaos, Solitons & Fractals, vol. 135, p. 109850, Jun. 2020, doi: 10.1016/J.CHAOS.2020.109850.
[180] S. Deng, S. Wang, H. Rangwala, L. Wang, and Y. Ning, “Cola-GNN: Cross-location Attention based Graph Neural Networks for Long
term ILI Prediction,” in Proceedings of the 29th ACM International Conference on Information & Knowledge Management, Oct. 2020, pp. 245–254, doi: 10.1145/3340531.3411975.
[181] A. S. Ahuja, “The impact of artificial intelligence in medicine on the future role of the physician.,” PeerJ, vol. 7, p. e7702, 2019, doi: 10.7717/peerj.7702.
[182] E. Korot et al., “Will AI Replace Ophthalmologists?,” Transl. Vis. Sci. Technol., vol. 9, no. 2, 2020, doi: 10.1167/TVST.9.2.2.
[183] K. E. Karches, “Against the iDoctor: why artificial intelligence should not replace physician judgment,” Theor. Med. Bioeth. 2018 392, vol. 39, no. 2, pp. 91–110, Jul. 2018, doi: 10.1007/S11017-0189442-3.
[184] D. S, D. S, J. SS, B. CM, and A. MJ, “Machine Learning in Drug Discovery: A Review,” Artif. Intell. Rev., 2021, doi: 10.1007/S10462-021-10058-4.
[185] K. E. Karches, “Against the iDoctor: why artificial intelligence should not replace physician judgment.,” Theor. Med. Bioeth., vol. 39, no. 2, pp. 91–110, Apr. 2018, doi: 10.1007/s11017-018-9442-3. [186] E. J. Topol, Deep medicine : how artificial intelligence can make healthcare human again. Basic Books, Inc., 2019.
Saurav Mishra was born in India in 1987. He received the Bachelor in Technology degree in Computer Science & Engineering in 2009, M.S. degree in Wireless Embedded Technology from the Manipal University, India in 2012, and a Master’s degree in Artificial Intelligence & Machine Learning from the Liverpool John Moore’s University, U.K., in 2020 .He is currently working as a software developer in the healthcare domain and aims to contribute towards the research and development space in the adoption of Artificial Intelligence in healthcare domain. His research interests include the adoption of Deep Learning and Computer Vision in the medical diagnostics and human biology space.