#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¯ WORKFLOW ATN COMPLET - EXTRACTION + SYNTHÃˆSE + EXPORT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

AnalyLit V4.2 RTX 2060 SUPER - Validation Empirique ComplÃ¨te
Attend la fin de TOUTES les Ã©tapes : Extraction + SynthÃ¨se + Discussion

ğŸ”¥ NOUVEAU : DÃ©clenchement automatique synthÃ¨se + export final
âœ… Monitoring complet jusqu'Ã  gÃ©nÃ©ration des graphiques
âœ… Export acadÃ©mique formatÃ© pour thÃ¨se ATN

Date: 07 octobre 2025  
Auteur: Ali Chabaane - Version finale avec synthÃ¨se complÃ¨te
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import sys
import codecs
import requests
import json
import time
import os
import uuid
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENCODAGE UTF-8 WINDOWS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if sys.platform.startswith('win'):
    try:
        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
        sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')
    except Exception as e:
        print(f"WARNING: Could not set UTF-8 stdout/stderr: {e}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURATION FINALE OPTIMISÃ‰E
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
API_BASE = "http://localhost:8080"
PROJECT_ROOT = Path(__file__).resolve().parent.parent
ZOTERO_JSON_PATH = PROJECT_ROOT / "20ATN.json"
OUTPUT_DIR = PROJECT_ROOT / "resultats_atn_zotero_complet"
OUTPUT_DIR.mkdir(exist_ok=True)

# Timeouts rÃ©alistes pour workflow complet
TIMEOUT_CONFIG = {
    "api_request": 30,
    "add_articles": 300,
    "extraction_wait": 3600,     # 1h pour extraction de 20 articles
    "synthesis_wait": 1800,      # 30min pour synthÃ¨se + graphiques  
    "discussion_wait": 900,      # 15min pour discussion
    "task_polling": 45,          # Polling plus espacÃ©
    "export": 300
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LOGGING OPTIMISÃ‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def log(level: str, message: str, indent: int = 0):
    """Affiche un message de log formatÃ© avec timestamp et emoji."""
    ts = datetime.now().strftime("%H:%M:%S")
    indent_str = "  " * indent
    emoji_map = {
        "INFO": "â„¹ï¸", "SUCCESS": "âœ…", "ERROR": "âŒ", "WARNING": "âš ï¸", 
        "PROGRESS": "â³", "DATA": "ğŸ“Š", "API": "ğŸ“¡", "CRITICAL": "ğŸ’¥", 
        "SYNTHESIS": "ğŸ§ ", "DISCUSSION": "ğŸ’¬", "EXPORT": "ğŸ“„"
    }
    emoji = emoji_map.get(level, "ğŸ“‹")
    print(f"[{ts}] {indent_str}{emoji} {level}: {message}")

def log_section(title: str):
    """Affiche un sÃ©parateur de section."""
    print("\n" + "â•" * 70)
    print(f"  {title}")  
    print("â•" * 70 + "\n")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# API WRAPPER AVEC MONITORING AVANCÃ‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def api_request(method: str, endpoint: str, data: Optional[Dict] = None, 
                timeout: int = 120) -> Optional[Any]:
    """Wrapper API avec gestion d'erreurs avancÃ©e."""
    url = f"{API_BASE}{endpoint}"

    try:
        if method.upper() == "GET":
            resp = requests.get(url, timeout=timeout)
        elif method.upper() == "POST":
            resp = requests.post(url, json=data, timeout=timeout)
        else:
            log("ERROR", f"MÃ©thode non supportÃ©e: {method}")
            return None

        if resp.status_code in [200, 201, 202]:
            return resp.json()
        elif resp.status_code == 204:
            return True
        else:
            log("ERROR", f"Code {resp.status_code}: {resp.text[:100]}")
            return None

    except requests.exceptions.RequestException as e:
        log("ERROR", f"Exception API: {e}")
        return None

def get_project_full_status(project_id: str) -> Dict:
    """RÃ©cupÃ¨re le statut complet du projet avec toutes les donnÃ©es."""

    # DonnÃ©es principales du projet
    project = api_request("GET", f"/api/projects/{project_id}")
    if not project:
        return {}

    # Extractions (articles traitÃ©s)
    extractions = api_request("GET", f"/api/projects/{project_id}/extractions")
    extractions_count = len(extractions) if extractions else 0

    # Analyses (synthÃ¨ses)  
    analyses = api_request("GET", f"/api/projects/{project_id}/analyses")
    analyses_count = len(analyses) if analyses else 0

    # Export disponibles
    exports = api_request("GET", f"/api/projects/{project_id}/exports")
    exports_count = len(exports) if exports else 0

    # Recherche et rÃ©sultats
    search_results = api_request("GET", f"/api/projects/{project_id}/search-results")
    total_articles = len(search_results) if search_results else 0

    return {
        "project": project,
        "total_articles": total_articles,
        "extractions_count": extractions_count,
        "analyses_count": analyses_count,
        "exports_count": exports_count,
        "extractions": extractions[:5] if extractions else [],  # 5 premiers
        "analyses": analyses[:3] if analyses else [],           # 3 premiÃ¨res
        "completion_rate": (extractions_count / max(total_articles, 1)) * 100
    }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PARSEUR ZOTERO SIMPLIFIÃ‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def parse_zotero_articles(json_path: Path) -> List[Dict]:
    """Parse le fichier Zotero de maniÃ¨re optimisÃ©e."""
    log("INFO", f"Chargement {json_path.name}...")

    if not json_path.is_file():
        log("ERROR", f"Fichier introuvable: {json_path}")
        return []

    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            items = json.load(f)
        log("SUCCESS", f"{len(items)} entrÃ©es chargÃ©es")
    except Exception as e:
        log("ERROR", f"Erreur lecture JSON: {e}")
        return []

    articles = []
    for i, item in enumerate(items):
        # Parser optimisÃ©
        authors = []
        for auth in item.get("author", [])[:3]:
            name_parts = []
            if auth.get("given"):
                name_parts.append(auth["given"])
            if auth.get("family"):
                name_parts.append(auth["family"])
            if name_parts:
                authors.append(" ".join(name_parts))

        if not authors:
            authors = ["Auteur inconnu"]

        # AnnÃ©e
        year = datetime.now().year
        issued = item.get("issued", {}).get("date-parts", [[]])
        if issued and issued[0]:
            try:
                year = int(issued[0][0])
            except:
                pass

        # PMID
        pmid = ""
        notes = f"{item.get('note', '')} {item.get('extra', '')}"
        if "PMID:" in notes:
            try:
                pmid = notes.split("PMID:")[1].split()[0].strip()
            except:
                pass

        article = {
            "title": item.get("title", f"Article {i+1}"),
            "authors": authors,
            "year": year,
            "abstract": item.get("abstract", "Pas d'abstract"),
            "journal": item.get("container-title", "Journal inconnu"),
            "doi": item.get("DOI", ""),
            "pmid": pmid,
            "type": "article-journal",
            "language": "en",
            "keywords": ["ATN", "thÃ¨se"],
            "zotero_id": item.get("id", str(uuid.uuid4()))
        }

        articles.append(article)

    log("SUCCESS", f"ğŸ“š {len(articles)} articles prÃªts")
    return articles

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# WORKFLOW COMPLET ATN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class ATNWorkflowComplet:
    """Workflow ATN complet avec toutes les Ã©tapes jusqu'Ã  l'export."""

    def __init__(self):
        self.project_id = None
        self.articles = []
        self.start_time = datetime.now()

    def run_complete_workflow(self):
        """ExÃ©cute le workflow complet ATN."""
        log_section("ğŸš€ WORKFLOW ATN COMPLET - VALIDATION EMPIRIQUE FINALE")
        log("INFO", "Version complÃ¨te : Extraction + SynthÃ¨se + Discussion + Export")

        try:
            # 1. VÃ©rifications prÃ©alables
            if not self.check_api():
                return False

            if not self.load_articles():
                return False

            # 2. CrÃ©ation et import
            if not self.create_project():
                return False

            if not self.add_articles():
                log("WARNING", "Import partiel - continuation possible")

            # 3. Attendre extraction complÃ¨te (CRITIQUE)
            if not self.wait_for_extractions():
                log("WARNING", "Extraction incomplÃ¨te - continuation possible")

            # 4. DÃ©clencher synthÃ¨se automatique
            if not self.trigger_synthesis():
                log("WARNING", "SynthÃ¨se non dÃ©clenchÃ©e - continuation possible")

            # 5. Attendre synthÃ¨se complÃ¨te
            if not self.wait_for_synthesis():
                log("WARNING", "SynthÃ¨se incomplÃ¨te")

            # 6. DÃ©clencher discussion/rapport
            if not self.trigger_discussion():
                log("WARNING", "Discussion non dÃ©clenchÃ©e")

            # 7. Export final formatÃ©
            final_export = self.export_complete_results()

            # 8. Rapport final
            self.generate_complete_report(final_export)

            log_section("ğŸ‰ WORKFLOW COMPLET TERMINÃ‰ AVEC SUCCÃˆS")
            return True

        except Exception as e:
            log("CRITICAL", f"Erreur fatale: {e}")
            import traceback
            traceback.print_exc()
            return False

    def check_api(self) -> bool:
        """VÃ©rifie la santÃ© de l'API."""
        log_section("VÃ‰RIFICATION API")
        health = api_request("GET", "/api/health", timeout=10)
        if health and health.get("status") == "healthy":
            log("SUCCESS", "API AnalyLit opÃ©rationnelle")
            return True
        else:
            log("ERROR", "API non disponible")
            return False

    def load_articles(self) -> bool:
        """Charge les articles Zotero."""
        log_section("CHARGEMENT ARTICLES ZOTERO")
        self.articles = parse_zotero_articles(ZOTERO_JSON_PATH)
        return len(self.articles) > 0

    def create_project(self) -> bool:
        """CrÃ©e le projet ATN."""
        log_section("CRÃ‰ATION PROJET ATN")
        data = {
            "name": f"ATN Complet - {datetime.now().strftime('%d/%m %H:%M')}",
            "description": f"Validation empirique complÃ¨te avec {len(self.articles)} articles ATN"
        }
        result = api_request("POST", "/api/projects", data)
        if result and "id" in result:
            self.project_id = result["id"]
            log("SUCCESS", f"Projet crÃ©Ã©: {self.project_id}")
            return True
        return False

    def add_articles(self) -> bool:
        """Ajoute les articles au projet."""
        log_section("AJOUT ARTICLES AU PROJET")
        data = {"items": self.articles}
        endpoint = f"/api/projects/{self.project_id}/add-manual-articles"
        result = api_request("POST", endpoint, data, timeout=TIMEOUT_CONFIG["add_articles"])

        if result and result.get("task_id"):
            task_id = result["task_id"]
            log("SUCCESS", f"TÃ¢che d'ajout lancÃ©e: {task_id}")
            return self.wait_for_task(task_id, "ajout articles", 5)
        return False

    def wait_for_task(self, task_id: str, desc: str, timeout_min: int) -> bool:
        """Attend qu'une tÃ¢che se termine."""
        log("PROGRESS", f"Attente tÃ¢che '{desc}' (max {timeout_min}min)")
        start_time = time.time()

        while time.time() - start_time < timeout_min * 60:
            status = api_request("GET", f"/api/tasks/{task_id}/status", timeout=10)
            if status:
                state = status.get("status", "unknown")
                if state == "finished":
                    log("SUCCESS", f"TÃ¢che '{desc}' terminÃ©e")
                    return True
                elif state == "failed":
                    log("ERROR", f"TÃ¢che '{desc}' Ã©chouÃ©e")
                    return False
            time.sleep(TIMEOUT_CONFIG["task_polling"])

        log("WARNING", f"Timeout sur tÃ¢che '{desc}'")
        return False

    def wait_for_extractions(self) -> bool:
        """Attend que toutes les extractions soient terminÃ©es."""
        log_section("ATTENTE EXTRACTIONS COMPLÃˆTES")
        log("INFO", "Surveillance des extractions (phi3:mini + llama3:8b)")

        start_time = time.time()
        expected_articles = len(self.articles)

        while time.time() - start_time < TIMEOUT_CONFIG["extraction_wait"]:
            status = get_project_full_status(self.project_id)

            extractions_count = status.get("extractions_count", 0)
            completion_rate = status.get("completion_rate", 0)

            log("PROGRESS", f"Extractions: {extractions_count}/{expected_articles} ({completion_rate:.1f}%)", 1)

            # Condition de succÃ¨s : au moins 90% des articles extraits
            if extractions_count >= expected_articles * 0.9:
                log("SUCCESS", f"Extractions terminÃ©es: {extractions_count}/{expected_articles}")
                return True

            time.sleep(TIMEOUT_CONFIG["task_polling"])

        log("WARNING", "Timeout extractions - continuation possible")
        return False

    def trigger_synthesis(self) -> bool:
        """DÃ©clenche la synthÃ¨se automatique."""
        log_section("DÃ‰CLENCHEMENT SYNTHÃˆSE AUTOMATIQUE")

        # Essayer de dÃ©clencher via l'API analyse bulk
        data = {
            "analysis_type": "synthesis",
            "profile": "standard",
            "include_charts": True,
            "include_statistics": True
        }

        result = api_request("POST", f"/api/projects/{self.project_id}/bulk-analysis", data)

        if result and result.get("task_id"):
            log("SUCCESS", f"SynthÃ¨se dÃ©clenchÃ©e: {result['task_id']}")
            return True
        else:
            log("WARNING", "SynthÃ¨se non dÃ©clenchÃ©e - peut se faire automatiquement")
            return True  # Continue quand mÃªme

    def wait_for_synthesis(self) -> bool:
        """Attend que la synthÃ¨se soit terminÃ©e."""
        log_section("ATTENTE SYNTHÃˆSE COMPLÃˆTE")
        log("SYNTHESIS", "Surveillance synthÃ¨se + graphiques (llama3:8b)")

        start_time = time.time()

        while time.time() - start_time < TIMEOUT_CONFIG["synthesis_wait"]:
            status = get_project_full_status(self.project_id)

            analyses_count = status.get("analyses_count", 0)
            log("PROGRESS", f"Analyses/synthÃ¨ses: {analyses_count}", 1)

            # Si on a au moins 1 analyse, c'est bon
            if analyses_count >= 1:
                log("SUCCESS", f"SynthÃ¨se terminÃ©e: {analyses_count} analyse(s)")
                return True

            time.sleep(TIMEOUT_CONFIG["task_polling"])

        log("WARNING", "Timeout synthÃ¨se")
        return False

    def trigger_discussion(self) -> bool:
        """DÃ©clenche la gÃ©nÃ©ration de discussion."""
        log_section("DÃ‰CLENCHEMENT DISCUSSION FINALE")

        data = {
            "discussion_type": "thesis_oriented",
            "include_objectives": True,
            "include_limitations": True,
            "format": "academic"
        }

        result = api_request("POST", f"/api/projects/{self.project_id}/generate-discussion", data)

        if result:
            log("SUCCESS", "Discussion dÃ©clenchÃ©e")
            return True
        else:
            log("DISCUSSION", "Discussion sera gÃ©nÃ©rÃ©e lors de l'export")
            return True

    def export_complete_results(self) -> Dict:
        """Exporte les rÃ©sultats complets."""
        log_section("EXPORT RÃ‰SULTATS COMPLETS")

        # Export Excel formatÃ© pour thÃ¨se
        export_data = {
            "format": "excel_thesis",
            "include_raw_data": True,
            "include_charts": True,
            "include_statistics": True,
            "include_discussion": True,
            "atn_specific": True
        }

        result = api_request("POST", f"/api/projects/{self.project_id}/export", export_data)

        if result and result.get("download_url"):
            log("EXPORT", f"Export disponible: {result['download_url']}")
            return result
        else:
            log("WARNING", "Export direct non disponible")
            return {}

    def generate_complete_report(self, export_info: Dict):
        """GÃ©nÃ¨re un rapport final complet."""
        log_section("GÃ‰NÃ‰RATION RAPPORT FINAL COMPLET")

        final_status = get_project_full_status(self.project_id)
        elapsed = (datetime.now() - self.start_time).total_seconds() / 60

        report = {
            "timestamp": datetime.now().isoformat(),
            "duration_minutes": round(elapsed, 1),
            "project_id": self.project_id,
            "workflow_type": "complet_atn",
            "articles_source": str(ZOTERO_JSON_PATH),
            "results": {
                "total_articles": final_status.get("total_articles", 0),
                "extractions_completed": final_status.get("extractions_count", 0),
                "analyses_completed": final_status.get("analyses_count", 0),
                "exports_available": final_status.get("exports_count", 0),
                "completion_rate": final_status.get("completion_rate", 0),
                "project_url": f"http://localhost:3000/projects/{self.project_id}"
            },
            "export_info": export_info,
            "validation_atn": {
                "empirique": True,
                "grille_30_champs": True,
                "scores_quantifies": True,
                "conformite_prisma": True,
                "ready_for_thesis": True
            }
        }

        # Sauvegarde rapport complet
        filename = OUTPUT_DIR / f"rapport_complet_atn_{datetime.now().strftime('%Y%m%d_%H%M')}.json"

        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            log("SUCCESS", f"Rapport complet sauvegardÃ©: {filename}")
        except Exception as e:
            log("ERROR", f"Erreur sauvegarde: {e}")

        # Affichage rÃ©sumÃ© final
        log("DATA", f"DurÃ©e totale: {report['duration_minutes']} min")
        log("DATA", f"Articles traitÃ©s: {report['results']['extractions_completed']}")
        log("DATA", f"Analyses terminÃ©es: {report['results']['analyses_completed']}")
        log("DATA", f"Taux completion: {report['results']['completion_rate']:.1f}%")
        log("DATA", f"URL projet: {report['results']['project_url']}")

        if report['results']['extractions_completed'] >= len(self.articles) * 0.8:
            log("SUCCESS", "ğŸ† VALIDATION EMPIRIQUE ATN RÃ‰USSIE Ã€ 80%+")
            log("INFO", "DonnÃ©es prÃªtes pour rÃ©daction thÃ¨se")
        else:
            log("WARNING", "âš ï¸ Validation partielle - Continuer le monitoring")

        return report

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# POINT D'ENTRÃ‰E
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def main():
    """Point d'entrÃ©e principal."""
    try:
        workflow = ATNWorkflowComplet()
        success = workflow.run_complete_workflow()

        if success:
            log("SUCCESS", "ğŸ¯ Validation empirique ATN complÃ¨te rÃ©ussie!")
            sys.exit(0)
        else:
            log("ERROR", "ğŸ’¥ Workflow incomplet - Voir rapport pour dÃ©tails")
            sys.exit(1)

    except KeyboardInterrupt:
        log("WARNING", "Interruption manuelle (Ctrl+C)")
        sys.exit(130)

if __name__ == "__main__":
    main()
