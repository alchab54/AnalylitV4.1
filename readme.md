# **AnalyLit v4.1**

**Un outil de recherche IA robuste et performant pour les revues de littÃ©rature systÃ©matiques et exploratoires (scoping reviews).**

<p align="center">
  <img src="https://raw.githubusercontent.com/alichabaux/AnalyLit/main/assets/dashboard.png" alt="Tableau de bord AnalyLit" width="700">
</p>

AnalyLit v4.1 est une application web complÃ¨te conÃ§ue pour automatiser et rationaliser le processus complexe des revues de littÃ©rature. DÃ©veloppÃ©e pour rÃ©pondre aux exigences de la recherche acadÃ©mique, elle intÃ¨gre une suite d'outils basÃ©s sur l'IA (via Ollama) pour accompagner le chercheur de la collecte des articles Ã  la synthÃ¨se finale. Le code a Ã©tÃ© entiÃ¨rement refactorisÃ© pour garantir une **robustesse**, une **sÃ©curitÃ©** et une **performance** de niveau professionnel.

## **âœ¨ FonctionnalitÃ©s Principales**

* **Gestion de Projets :** Isolez chaque revue de littÃ©rature dans un projet dÃ©diÃ© avec son propre corpus et ses analyses.  
* **Recherche Multi-Bases :** Lancez des recherches fÃ©dÃ©rÃ©es sur des bases de donnÃ©es acadÃ©miques majeures comme PubMed, arXiv, CrossRef et IEEE Xplore.  


### Mode de Recherche Hybride : Simple et Experte

AnalyLit combine deux modes de recherche pour s'adapter Ã  vos besoins :

1.  **Recherche Simple (par dÃ©faut)**
    * IdÃ©ale pour des recherches rapides et exploratoires.
    * Entrez simplement vos mots-clÃ©s (ex: `cancer AND treatment`).
    * AnalyLit se charge de traduire cette requÃªte simple pour chaque base de donnÃ©es sÃ©lectionnÃ©e (PubMed, Scopus, etc.) en utilisant leurs champs de recherche par dÃ©faut.

2.  **Recherche Experte (AvancÃ©e)**
    * ConÃ§ue pour les revues systÃ©matiques et les recherches de haute prÃ©cision.
    * Activez le mode "Recherche Experte" pour rÃ©vÃ©ler des champs de saisie distincts pour chaque base de donnÃ©es.
    * Vous pouvez alors coller votre Ã©quation de recherche complÃ¨te et optimisÃ©e, en utilisant la syntaxe spÃ©cifique de chaque base (ex: `(cancer[MeSH Terms] OR cancer[Title/Abstract])` pour PubMed et `TITLE-ABS-KEY(cancer) AND ...` pour Scopus).
    * AnalyLit exÃ©cute votre Ã©quation exacte sans aucune traduction, garantissant une
  
* **Pipeline d'Analyse IA :**   

  * **Screening AutomatisÃ© :** L'IA Ã©value la pertinence des articles sur la base des titres et rÃ©sumÃ©s.  
  * **Extraction DÃ©taillÃ©e :** L'IA remplit des grilles d'extraction personnalisables Ã  partir du texte intÃ©gral des PDF.  

* **Module de Double Codage :** ImplÃ©mentez un processus de validation par un pair avec un cycle Export CSV \-\> Import CSV et calculez automatiquement le **coefficient Kappa de Cohen** pour mesurer la fiabilitÃ© de l'accord.  

* **SynthÃ¨se Intelligente :** GÃ©nÃ©rez des brouillons de sections "Discussion" et des synthÃ¨ses des conclusions clÃ©s.

* **Analyses AvancÃ©es :**  
  * GÃ©nÃ©rez un diagramme de flux **PRISMA** en un clic.  
  * Effectuez des **mÃ©ta-analyses** et des **statistiques descriptives** sur vos donnÃ©es.  
  * CrÃ©ez un **graphe de connaissances** pour visualiser les relations entre les concepts et les articles.  
  * **Analyse ATN multipartite** : Une analyse spÃ©cialisÃ©e pour l'Alliance ThÃ©rapeutique NumÃ©rique.

* **Chat RAG avec vos Documents :** AprÃ¨s avoir indexÃ© vos PDF, dialoguez avec votre corpus pour poser des questions prÃ©cises et obtenir des rÃ©ponses synthÃ©tiques basÃ©es sur vos documents.  

* **Gestion des Prompts et Profils IA :** Personnalisez les prompts et les modÃ¨les de langage (LLM) utilisÃ©s pour chaque Ã©tape via l'interface, ou revenez aux versions par dÃ©faut robustes codÃ©es en dur.  

* **IntÃ©gration Zotero & RÃ©cupÃ©ration de PDF :** Importez des rÃ©fÃ©rences depuis Zotero et lancez une recherche automatisÃ©e des PDF en libre accÃ¨s via Unpaywall.

## **âœ… AmÃ©liorations de QualitÃ© et de Robustesse**

Le projet a bÃ©nÃ©ficiÃ© d'une refactorisation complÃ¨te pour amÃ©liorer sa fiabilitÃ© et sa maintenabilitÃ© :

*   **Backend Robuste :**
    *   **SÃ©curitÃ© RenforcÃ©e :** Validation systÃ©matique des entrÃ©es (UUIDs) et protection contre les attaques de type *Path Traversal*.
    *   **Gestion d'Erreurs Fiable :** Gestion centralisÃ©e des sessions de base de donnÃ©es et logging dÃ©taillÃ© avec stack traces pour un dÃ©bogage rapide.
    *   **Performances OptimisÃ©es :** Utilisation de traitement par lots (*batch processing*) pour les insertions massives en base de donnÃ©es et optimisation des requÃªtes SQL.
    *   **Appels RÃ©seau RÃ©silients :** StratÃ©gie de nouvel essai (*retry*) automatique pour les appels aux API externes (Ollama, etc.).
*   **Frontend Modulaire :**
    *   **Code OrganisÃ© :** Le code JavaScript a Ã©tÃ© entiÃ¨rement modularisÃ© pour une meilleure lisibilitÃ© et maintenabilitÃ©.
    *   **Gestion d'Ã‰tat PrÃ©visible :** Un gestionnaire d'Ã©tat centralisÃ© garantit que l'interface utilisateur est toujours synchronisÃ©e avec les donnÃ©es.
    *   **Gestion d'Ã‰vÃ©nements Moderne :** Suppression des `onclick` au profit d'un systÃ¨me de dÃ©lÃ©gation d'Ã©vÃ©nements performant et propre.

## **ğŸ›ï¸ Architecture**

AnalyLit v4.1 est construit sur une architecture microservices robuste et scalable, orchestrÃ©e par Docker Compose.

* **nginx** : Reverse proxy qui sert le frontend statique et route les requÃªtes /api et /socket.io vers le backend.  
* **web** : Le serveur principal en **Flask** et **Gunicorn**, qui expose l'API RESTful et gÃ¨re les connexions **Socket.IO** pour la communication en temps rÃ©el.  
* **worker** : Un ou plusieurs workers **RQ (Redis Queue)** qui exÃ©cutent toutes les tÃ¢ches longues en arriÃ¨re-plan (recherches, analyses IA, imports) pour garantir une interface utilisateur toujours rÃ©active.  
* **db** : Une base de donnÃ©es **PostgreSQL** pour un stockage des donnÃ©es fiable et performant.  
* **redis** : Agit comme *message broker* pour les files d'attente RQ et pour la communication Socket.IO.  
* **ollama** : Le service qui fait tourner les modÃ¨les de langage locaux (LLMs), avec support GPU.

```mermaid
graph TD
    subgraph "Utilisateur"
        U[ğŸŒ Navigateur Client]
    end

    subgraph "Infrastructure Docker"
        N[/"nginx (Reverse Proxy)"/]
        W[ğŸš€ web (Flask/Gunicorn)]
        WK[ğŸ› ï¸ worker (RQ)]
        R[ğŸ“¦ redis (Broker)]
        DB[(ğŸ˜ db (PostgreSQL))]
        O[ğŸ§  ollama (LLM)]
    end

    U -- HTTPS --> N
    N -- /api, /socket.io --> W
    N -- / (fichiers statiques) --> W
    W -- CrÃ©e TÃ¢ches --> R
    W <--> DB
    WK -- Lit TÃ¢ches --> R
    WK -- Appelle IA --> O
    WK <--> DB
```

## **ğŸ› ï¸ Stack Technique**

* **Backend :** Python 3.11, Flask, SQLAlchemy, Gunicorn  
* **Frontend :** JavaScript (ES6+ Modules), HTML5, CSS3  
* **TÃ¢ches Asynchrones :** Redis, RQ (Redis Queue)  
* **Base de DonnÃ©es :** PostgreSQL  
* **Communication Temps RÃ©el :** Flask-SocketIO  
* **IA :** Ollama  
* **DÃ©ploiement :** Docker, Docker Compose, Nginx, Gunicorn

## **ğŸš€ Installation & Lancement**

### **PrÃ©requis**

* [Docker](https://www.docker.com/products/docker-desktop/)  
* [Docker Compose](https://docs.docker.com/compose/install/)  
* (Optionnel mais recommandÃ©) Un GPU NVIDIA avec les drivers Ã  jour et le [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html) pour l'accÃ©lÃ©ration matÃ©rielle des modÃ¨les IA.

### **Ã‰tapes d'Installation**

1.  **Clonez le dÃ©pÃ´t :**
    ```bash
    git clone https://github.com/alichabaux/AnalyLit.git
    cd [NOM_DU_DOSSIER]
    ```

2.  **Configurez votre environnement :**
    *   Copiez le fichier d'exemple `env.example` vers un nouveau fichier nommÃ© `.env`.
        ```bash
        cp env.example .env
        ```

    *   Ouvrez le fichier `.env` et remplissez les variables, notamment :
        *   `SECRET_KEY` : GÃ©nÃ©rez une clÃ© secrÃ¨te alÃ©atoire (ex: `openssl rand -hex 32`).
        *   `POSTGRES_USER`, `POSTGRES_PASSWORD`, `POSTGRES_DB` : Vos identifiants pour la base de donnÃ©es.

3.  **Construisez et lancez les conteneurs :**
    *   Cette commande va construire les images Docker et dÃ©marrer tous les services en arriÃ¨re-plan.
        ```bash
        docker-compose -f docker-compose-local.yml up -d --build
        ```

    *   Pour scaler les workers (par exemple, pour en avoir 3) :
        ```bash
        docker-compose -f docker-compose-local.yml up -d --build --scale worker=3
        ```

4.  **AccÃ©dez Ã  l'application :**
    *   Ouvrez votre navigateur et allez Ã  l'adresse : **http://localhost:8080**

5.  **Surveillez les logs :**
    *   Pour voir les logs de tous les services en temps rÃ©el :
        ```bash
        docker-compose -f docker-compose-local.yml logs -f
        ```

    *   Pour voir les logs d'un service spÃ©cifique (ex: le serveur web) :
        ```bash
        docker-compose -f docker-compose-local.yml logs -f web
        ```

## **ğŸ“– Commandes Utiles**

Le projet inclut un `Makefile` pour simplifier la gestion des commandes Docker.

*   **DÃ©marrer l'application :**
    ```bash
    make start
    ```
*   **ArrÃªter l'application :**
    ```bash
    make stop
    ```
*   **Voir les logs en temps rÃ©el :**
    ```bash
    make logs-follow
    ```
*   **TÃ©lÃ©charger les modÃ¨les IA de base (Ollama) :**
    ```bash
    make models
    ```
*   **Lancer la suite de tests :**
    ```bash
    make test
    ```

Pour la liste complÃ¨te des raccourcis, utilisez `make help`.

## **ğŸ“ Structure du Projet**

```
.  
â”œâ”€â”€ Dockerfile-nginx  
â”œâ”€â”€ Dockerfile.base              # Image de base pour web et worker
â”œâ”€â”€ Dockerfile-web-complete  
â”œâ”€â”€ Dockerfile-worker-complete  
â”œâ”€â”€ Makefile.mk                  # Commandes de gestion du projet
â”œâ”€â”€ README.md                    # Ce fichier
â”œâ”€â”€ analylit.sh                  # Script de gestion pour les systÃ¨mes non-Make
â”œâ”€â”€ config_v4.py                 # Configuration centrale de l'application
â”œâ”€â”€ docker-compose-local.yml     # Orchestration des services Docker
â”œâ”€â”€ env.example                  # ModÃ¨le pour les variables d'environnement
â”œâ”€â”€ requirements.txt             # DÃ©pendances Python
â”œâ”€â”€ pytest.ini                   # Configuration pour Pytest
â”œâ”€â”€ profiles.json                # Configuration externalisÃ©e des profils IA
â”œâ”€â”€ server_v4_complete.py        # Serveur principal Flask (API & Socket.IO)
â”œâ”€â”€ tasks_v4_complete.py         # Logique des tÃ¢ches asynchrones RQ
â”œâ”€â”€ utils/                       # Modules utilitaires partagÃ©s
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ai_processors.py
â”‚   â”œâ”€â”€ analysis.py
â”‚   â”œâ”€â”€ fetchers.py
â”‚   â”œâ”€â”€ file_handlers.py
â”‚   â”œâ”€â”€ helpers.py
â”‚   â”œâ”€â”€ importers.py
â”‚   â”œâ”€â”€ notifications.py
â”‚   â”œâ”€â”€ prisma_scr.py
â”‚   â”œâ”€â”€ prompt_templates.py
â”‚   â””â”€â”€ reporting.py
â””â”€â”€ web/                         # Frontend modulaire de l'application
    â”œâ”€â”€ app.js  
    â”œâ”€â”€ js/                      # Modules JavaScript
    â”œâ”€â”€ index.html  
    â””â”€â”€ style.css
```

## **ğŸ’¾ Gestion des DonnÃ©es & Persistance**

La persistance des donnÃ©es est gÃ©rÃ©e par des **volumes Docker**, ce qui garantit que vos donnÃ©es ne sont pas perdues lorsque les conteneurs sont arrÃªtÃ©s ou recrÃ©Ã©s.

*   **`postgres_data_v4`** : Stocke toutes les donnÃ©es de la base de donnÃ©es PostgreSQL (projets, articles, extractions, etc.).
*   **`ollama_data_v4`** : Met en cache les modÃ¨les de langage tÃ©lÃ©chargÃ©s pour Ã©viter de devoir les retÃ©lÃ©charger Ã  chaque redÃ©marrage.
*   **`./projects` (dossier local)** : Ce dossier est montÃ© directement dans les conteneurs `web` et `worker`. Il contient tous les fichiers spÃ©cifiques aux projets, comme les PDF importÃ©s, les images gÃ©nÃ©rÃ©es (PRISMA, graphes) et les bases de donnÃ©es vectorielles ChromaDB pour le RAG.

**Pour sauvegarder votre application**, il vous suffit de copier le contenu du volume `postgres_data_v4` et le dossier local `projects/`.

## **ğŸ› DÃ©pannage**

*   **Erreur de mÃ©moire Ollama (`out of memory`)** : Si vous rencontrez cette erreur dans les logs d'Ollama, cela signifie que votre GPU n'a pas assez de VRAM pour charger le modÃ¨le demandÃ©. Essayez d'utiliser des modÃ¨les plus petits (ex: `phi3:mini` au lieu de `llama3.1:8b`).
*   **Le worker ne dÃ©marre pas ou boucle** : VÃ©rifiez les logs du worker (`make logs-worker`). Une erreur frÃ©quente est une mauvaise configuration dans `.env` (ex: `REDIS_URL` incorrect) ou une dÃ©pendance manquante.
*   **L'interface web ne se charge pas (`502 Bad Gateway`)** : Cela signifie gÃ©nÃ©ralement que le service `web` n'a pas dÃ©marrÃ© correctement. VÃ©rifiez ses logs (`make logs-web`) pour identifier la cause (souvent une erreur de syntaxe en Python ou un problÃ¨me de connexion Ã  la base de donnÃ©es).

## **ğŸ“œ Licence**

Ce projet est sous licence MIT.