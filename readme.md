# **AnalyLit v4.1**

**Un outil de recherche IA robuste et performant pour les revues de litt√©rature syst√©matiques et exploratoires (scoping reviews).**

<p align="center">
  <img src="https://raw.githubusercontent.com/alichabaux/AnalyLit/main/assets/dashboard.png" alt="Tableau de bord AnalyLit" width="700">
</p>

AnalyLit v4.1 est une application web compl√®te con√ßue pour automatiser et rationaliser le processus complexe des revues de litt√©rature. D√©velopp√©e pour r√©pondre aux exigences de la recherche acad√©mique, elle int√®gre une suite d'outils bas√©s sur l'IA (via Ollama) pour accompagner le chercheur de la collecte des articles √† la synth√®se finale. Le code a √©t√© enti√®rement refactoris√© pour garantir une **robustesse**, une **s√©curit√©** et une **performance** de niveau professionnel.

## **‚ú® Fonctionnalit√©s Principales**

* **Gestion de Projets :** Isolez chaque revue de litt√©rature dans un projet d√©di√© avec son propre corpus et ses analyses.  
* **Recherche Multi-Bases :** Lancez des recherches f√©d√©r√©es sur des bases de donn√©es acad√©miques majeures comme PubMed, arXiv, CrossRef et IEEE Xplore.  


### Mode de Recherche Hybride : Simple et Experte

AnalyLit combine deux modes de recherche pour s'adapter √† vos besoins :

1.  **Recherche Simple (par d√©faut)**
    * Id√©ale pour des recherches rapides et exploratoires.
    * Entrez simplement vos mots-cl√©s (ex: `cancer AND treatment`).
    * AnalyLit se charge de traduire cette requ√™te simple pour chaque base de donn√©es s√©lectionn√©e (PubMed, Scopus, etc.) en utilisant leurs champs de recherche par d√©faut.

2.  **Recherche Experte (Avanc√©e)**
    * Con√ßue pour les revues syst√©matiques et les recherches de haute pr√©cision.
    * Activez le mode "Recherche Experte" pour r√©v√©ler des champs de saisie distincts pour chaque base de donn√©es.
    * Vous pouvez alors coller votre √©quation de recherche compl√®te et optimis√©e, en utilisant la syntaxe sp√©cifique de chaque base (ex: `(cancer[MeSH Terms] OR cancer[Title/Abstract])` pour PubMed et `TITLE-ABS-KEY(cancer) AND ...` pour Scopus).
    * AnalyLit ex√©cute votre √©quation exacte sans aucune traduction, garantissant une
  
* **Pipeline d'Analyse IA :**   

  * **Screening Automatis√© :** L'IA √©value la pertinence des articles sur la base des titres et r√©sum√©s.  
  * **Extraction D√©taill√©e :** L'IA remplit des grilles d'extraction personnalisables √† partir du texte int√©gral des PDF.  

* **Module de Double Codage :** Impl√©mentez un processus de validation par un pair avec un cycle Export CSV \-\> Import CSV et calculez automatiquement le **coefficient Kappa de Cohen** pour mesurer la fiabilit√© de l'accord.  

* **Synth√®se Intelligente :** G√©n√©rez des brouillons de sections "Discussion" et des synth√®ses des conclusions cl√©s.

* **Analyses Avanc√©es :**  
  * G√©n√©rez un diagramme de flux **PRISMA** en un clic.  
  * Effectuez des **m√©ta-analyses** et des **statistiques descriptives** sur vos donn√©es.  
  * Cr√©ez un **graphe de connaissances** pour visualiser les relations entre les concepts et les articles.  
  * **Analyse ATN multipartite** : Une analyse sp√©cialis√©e pour l'Alliance Th√©rapeutique Num√©rique.

* **Chat RAG avec vos Documents :** Apr√®s avoir index√© vos PDF, dialoguez avec votre corpus pour poser des questions pr√©cises et obtenir des r√©ponses synth√©tiques bas√©es sur vos documents.  

* **Gestion des Prompts et Profils IA :** Personnalisez les prompts et les mod√®les de langage (LLM) utilis√©s pour chaque √©tape via l'interface, ou revenez aux versions par d√©faut robustes cod√©es en dur.  

* **Int√©gration Zotero & R√©cup√©ration de PDF :** Importez des r√©f√©rences depuis Zotero et lancez une recherche automatis√©e des PDF en libre acc√®s via Unpaywall.

## **‚úÖ Am√©liorations de Qualit√© et de Robustesse**

Le projet a b√©n√©fici√© d'une refactorisation compl√®te pour am√©liorer sa fiabilit√© et sa maintenabilit√© :

*   **Backend Robuste :**
    *   **S√©curit√© Renforc√©e :** Validation syst√©matique des entr√©es (UUIDs) et protection contre les attaques de type *Path Traversal*.
    *   **Gestion d'Erreurs Fiable :** Gestion centralis√©e des sessions de base de donn√©es et logging d√©taill√© avec stack traces pour un d√©bogage rapide.
    *   **Performances Optimis√©es :** Utilisation de traitement par lots (*batch processing*) pour les insertions massives en base de donn√©es et optimisation des requ√™tes SQL.
    *   **Appels R√©seau R√©silients :** Strat√©gie de nouvel essai (*retry*) automatique pour les appels aux API externes (Ollama, etc.).
*   **Frontend Modulaire :**
    *   **Code Organis√© :** Le code JavaScript a √©t√© enti√®rement modularis√© pour une meilleure lisibilit√© et maintenabilit√©.
    *   **Gestion d'√âtat Pr√©visible :** Un gestionnaire d'√©tat centralis√© garantit que l'interface utilisateur est toujours synchronis√©e avec les donn√©es.
    *   **Gestion d'√âv√©nements Moderne :** Suppression des `onclick` au profit d'un syst√®me de d√©l√©gation d'√©v√©nements performant et propre.

## **üèõÔ∏è Architecture**

AnalyLit v4.1 est construit sur une architecture microservices robuste et scalable, orchestr√©e par Docker Compose.

* **nginx** : Reverse proxy qui sert le frontend statique et route les requ√™tes /api et /socket.io vers le backend.  
* **web** : Le serveur principal en **Flask** et **Gunicorn**, qui expose l'API RESTful et g√®re les connexions **Socket.IO** pour la communication en temps r√©el.  
* **worker** : Un ou plusieurs workers **RQ (Redis Queue)** qui ex√©cutent toutes les t√¢ches longues en arri√®re-plan (recherches, analyses IA, imports) pour garantir une interface utilisateur toujours r√©active.  
* **db** : Une base de donn√©es **PostgreSQL** pour un stockage des donn√©es fiable et performant.  
* **redis** : Agit comme *message broker* pour les files d'attente RQ et pour la communication Socket.IO.  
* **ollama** : Le service qui fait tourner les mod√®les de langage locaux (LLMs), avec support GPU.

```mermaid
graph TD
    subgraph "Utilisateur"
        U[üåê Navigateur Client]
    end

    subgraph "Infrastructure Docker"
        N[/"nginx (Reverse Proxy)"/]
        W[üöÄ web (Flask/Gunicorn)]
        WK[üõ†Ô∏è worker (RQ)]
        R[üì¶ redis (Broker)]
        DB[(üêò db (PostgreSQL))]
        O[üß† ollama (LLM)]
    end

    U -- HTTPS --> N
    N -- /api, /socket.io --> W
    N -- / (fichiers statiques) --> W
    W -- Cr√©e T√¢ches --> R
    W <--> DB
    WK -- Lit T√¢ches --> R
    WK -- Appelle IA --> O
    WK <--> DB
```

## **üõ†Ô∏è Stack Technique**

* **Backend :** Python 3.11, Flask, SQLAlchemy, Gunicorn  
* **Frontend :** JavaScript (ES6+ Modules), HTML5, CSS3  
* **T√¢ches Asynchrones :** Redis, RQ (Redis Queue)  
* **Base de Donn√©es :** PostgreSQL  
* **Communication Temps R√©el :** Flask-SocketIO  
* **IA :** Ollama  
* **D√©ploiement :** Docker, Docker Compose, Nginx, Gunicorn

## **üöÄ Installation & Lancement**

### **Pr√©requis**

* [Docker](https://www.docker.com/products/docker-desktop/)  
* [Docker Compose](https://docs.docker.com/compose/install/)  
* (Optionnel mais recommand√©) Un GPU NVIDIA avec les drivers √† jour et le [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html) pour l'acc√©l√©ration mat√©rielle des mod√®les IA.

### **√âtapes d'Installation**

1.  **Clonez le d√©p√¥t :**
    ```bash
    git clone https://github.com/alichabaux/AnalyLit.git
    cd [NOM_DU_DOSSIER]
    ```

2.  **Configurez votre environnement :**
    *   Copiez le fichier d'exemple `env.example` vers un nouveau fichier nomm√© `.env`.
        ```bash
        cp env.example .env
        ```

    *   Ouvrez le fichier `.env` et remplissez les variables, notamment :
        *   `SECRET_KEY` : G√©n√©rez une cl√© secr√®te al√©atoire (ex: `openssl rand -hex 32`).
        *   `POSTGRES_USER`, `POSTGRES_PASSWORD`, `POSTGRES_DB` : Vos identifiants pour la base de donn√©es.

3.  **Construisez et lancez les conteneurs :**
    *   Cette commande va construire les images Docker et d√©marrer tous les services en arri√®re-plan.
        ```bash
        docker-compose -f docker-compose-local.yml up -d --build
        ```

    *   Pour scaler les workers (par exemple, pour en avoir 3) :
        ```bash
        docker-compose -f docker-compose-local.yml up -d --build --scale worker=3
        ```

4.  **Acc√©dez √† l'application :**
    *   Ouvrez votre navigateur et allez √† l'adresse : **http://localhost:8080**

5.  **Surveillez les logs :**
    *   Pour voir les logs de tous les services en temps r√©el :
        ```bash
        docker-compose -f docker-compose-local.yml logs -f
        ```

    *   Pour voir les logs d'un service sp√©cifique (ex: le serveur web) :
        ```bash
        docker-compose -f docker-compose-local.yml logs -f web
        ```

## **üìñ Commandes Utiles**

Le projet inclut un `Makefile` pour simplifier la gestion des commandes Docker.

*   **D√©marrer l'application :**
    ```bash
    make start
    ```
*   **Arr√™ter l'application :**
    ```bash
    make stop
    ```
*   **Voir les logs en temps r√©el :**
    ```bash
    make logs-follow
    ```
*   **T√©l√©charger les mod√®les IA de base (Ollama) :**
    ```bash
    make models
    ```
*   **Lancer la suite de tests :**
    ```bash
    make test
    ```

Pour la liste compl√®te des raccourcis, utilisez `make help`.

## **üìÅ Structure du Projet**

```
.  
‚îú‚îÄ‚îÄ Dockerfile-nginx  
‚îú‚îÄ‚îÄ Dockerfile.base              # Image de base pour web et worker
‚îú‚îÄ‚îÄ Dockerfile-web-complete  
‚îú‚îÄ‚îÄ Dockerfile-worker-complete  
‚îú‚îÄ‚îÄ Makefile.mk                  # Commandes de gestion du projet
‚îú‚îÄ‚îÄ README.md                    # Ce fichier
‚îú‚îÄ‚îÄ analylit.sh                  # Script de gestion pour les syst√®mes non-Make
‚îú‚îÄ‚îÄ config_v4.py                 # Configuration centrale de l'application
‚îú‚îÄ‚îÄ docker-compose-local.yml     # Orchestration des services Docker
‚îú‚îÄ‚îÄ env.example                  # Mod√®le pour les variables d'environnement
‚îú‚îÄ‚îÄ requirements.txt             # D√©pendances Python
‚îú‚îÄ‚îÄ pytest.ini                   # Configuration pour Pytest
‚îú‚îÄ‚îÄ profiles.json                # Configuration externalis√©e des profils IA
‚îú‚îÄ‚îÄ server_v4_complete.py        # Serveur principal Flask (API & Socket.IO)
‚îú‚îÄ‚îÄ tasks_v4_complete.py         # Logique des t√¢ches asynchrones RQ
‚îú‚îÄ‚îÄ utils/                       # Modules utilitaires partag√©s
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ ai_processors.py
‚îÇ   ‚îú‚îÄ‚îÄ analysis.py
‚îÇ   ‚îú‚îÄ‚îÄ fetchers.py
‚îÇ   ‚îú‚îÄ‚îÄ file_handlers.py
‚îÇ   ‚îú‚îÄ‚îÄ helpers.py
‚îÇ   ‚îú‚îÄ‚îÄ importers.py
‚îÇ   ‚îú‚îÄ‚îÄ notifications.py
‚îÇ   ‚îú‚îÄ‚îÄ prisma_scr.py
‚îÇ   ‚îú‚îÄ‚îÄ prompt_templates.py
‚îÇ   ‚îî‚îÄ‚îÄ reporting.py
‚îî‚îÄ‚îÄ web/                         # Frontend modulaire de l'application
    ‚îú‚îÄ‚îÄ app.js  
    ‚îú‚îÄ‚îÄ js/                      # Modules JavaScript
    ‚îú‚îÄ‚îÄ index.html  
    ‚îî‚îÄ‚îÄ style.css
```

## **üíæ Gestion des Donn√©es & Persistance**

La persistance des donn√©es est g√©r√©e par des **volumes Docker**, ce qui garantit que vos donn√©es ne sont pas perdues lorsque les conteneurs sont arr√™t√©s ou recr√©√©s.

*   **`postgres_data_v4`** : Stocke toutes les donn√©es de la base de donn√©es PostgreSQL (projets, articles, extractions, etc.).
*   **`ollama_data_v4`** : Met en cache les mod√®les de langage t√©l√©charg√©s pour √©viter de devoir les ret√©l√©charger √† chaque red√©marrage.
*   **`./projects` (dossier local)** : Ce dossier est mont√© directement dans les conteneurs `web` et `worker`. Il contient tous les fichiers sp√©cifiques aux projets, comme les PDF import√©s, les images g√©n√©r√©es (PRISMA, graphes) et les bases de donn√©es vectorielles ChromaDB pour le RAG.

**Pour sauvegarder votre application**, il vous suffit de copier le contenu du volume `postgres_data_v4` et le dossier local `projects/`.

## **üêõ D√©pannage**

*   **Erreur de m√©moire Ollama (`out of memory`)** : Si vous rencontrez cette erreur dans les logs d'Ollama, cela signifie que votre GPU n'a pas assez de VRAM pour charger le mod√®le demand√©. Essayez d'utiliser des mod√®les plus petits (ex: `phi3:mini` au lieu de `llama3.1:8b`).
*   **Le worker ne d√©marre pas ou boucle** : V√©rifiez les logs du worker (`make logs-worker`). Une erreur fr√©quente est une mauvaise configuration dans `.env` (ex: `REDIS_URL` incorrect) ou une d√©pendance manquante.
*   **L'interface web ne se charge pas (`502 Bad Gateway`)** : Cela signifie g√©n√©ralement que le service `web` n'a pas d√©marr√© correctement. V√©rifiez ses logs (`make logs-web`) pour identifier la cause (souvent une erreur de syntaxe en Python ou un probl√®me de connexion √† la base de donn√©es).

## **üìú Licence**

Ce projet est sous licence MIT.